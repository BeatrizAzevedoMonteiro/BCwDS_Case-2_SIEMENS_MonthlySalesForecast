{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"header.png\" width=\"100%\">\n",
    "</p>\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <strong style=\"display: block; margin-bottom: 10px;\">Group P</strong> \n",
    "    <table style=\"margin: 0 auto; border-collapse: collapse; border: 1px solid black;\">\n",
    "        <tr>\n",
    "            <th style=\"border: 1px solid white; padding: 8px;\">Name</th>\n",
    "            <th style=\"border: 1px solid white; padding: 8px;\">Student ID</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">Beatriz Monteiro</td>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">20240591</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">Catarina Nunes</td>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">20230083</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">Margarida Raposo</td>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">20241020</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">Teresa Menezes</td>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">20240333</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔗 Table of Contents <a id='table-of-contents'></a>\n",
    "1. [Introduction](#introduction)  \n",
    "2. [Macro's Prediction](#business-understanding)  \n",
    "3. [Conclusion](#conclusion)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy.stats import norm\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import shap\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded P11 from product_dfs_folder/P11.pkl\n",
      "Loaded P13 from product_dfs_folder/P13.pkl\n",
      "Loaded P12 from product_dfs_folder/P12.pkl\n",
      "Loaded P16 from product_dfs_folder/P16.pkl\n",
      "Loaded P14 from product_dfs_folder/P14.pkl\n",
      "Loaded P8 from product_dfs_folder/P8.pkl\n",
      "Loaded P9 from product_dfs_folder/P9.pkl\n",
      "Loaded Sales_CPI from product_dfs_folder/Sales_CPI.pkl\n",
      "Loaded P1 from product_dfs_folder/P1.pkl\n",
      "Loaded P3 from product_dfs_folder/P3.pkl\n",
      "Loaded P6 from product_dfs_folder/P6.pkl\n",
      "Loaded P4 from product_dfs_folder/P4.pkl\n",
      "Loaded P5 from product_dfs_folder/P5.pkl\n",
      "Loaded P36 from product_dfs_folder/P36.pkl\n",
      "Loaded P20 from product_dfs_folder/P20.pkl\n",
      "Loaded P11 from lagged_product_dfs_folder/P11.pkl\n",
      "Loaded P13 from lagged_product_dfs_folder/P13.pkl\n",
      "Loaded P12 from lagged_product_dfs_folder/P12.pkl\n",
      "Loaded P16 from lagged_product_dfs_folder/P16.pkl\n",
      "Loaded P8 from lagged_product_dfs_folder/P8.pkl\n",
      "Loaded P9 from lagged_product_dfs_folder/P9.pkl\n",
      "Loaded P1 from lagged_product_dfs_folder/P1.pkl\n",
      "Loaded P3 from lagged_product_dfs_folder/P3.pkl\n",
      "Loaded P4 from lagged_product_dfs_folder/P4.pkl\n",
      "Loaded P5 from lagged_product_dfs_folder/P5.pkl\n",
      "Loaded P36 from lagged_product_dfs_folder/P36.pkl\n",
      "Loaded P20 from lagged_product_dfs_folder/P20.pkl\n"
     ]
    }
   ],
   "source": [
    "def load_dfs_from_folder(folder_path):\n",
    "    \"\"\"Loads DataFrames from files in a specified folder and returns a dictionary.\"\"\"\n",
    "    dfs = {}\n",
    "    # List all files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".pkl\"):\n",
    "            key = file_name.replace(\".pkl\", \"\")  # Extract key from the file name\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            \n",
    "            # Load the dataframe from the pickle file\n",
    "            with open(file_path, 'rb') as f:\n",
    "                dfs[key] = pickle.load(f)\n",
    "            print(f\"Loaded {key} from {file_path}\")\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "# Load both product_dfs and lagged_product_dfs from their respective folders\n",
    "product_dfs = load_dfs_from_folder(\"product_dfs_folder\")\n",
    "lagged_product_dfs = load_dfs_from_folder(\"lagged_product_dfs_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product_id in product_dfs.keys():\n",
    "    product_dfs[product_id] = product_dfs[product_id].rename(columns={product_id: \"Sales\"})\n",
    "\n",
    "for product_id in lagged_product_dfs.keys():\n",
    "    lagged_product_dfs[product_id] = lagged_product_dfs[product_id].rename(columns={product_id: \"Sales\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>MAB_ELE_SHP840</th>\n",
       "      <th>PRI27276_org</th>\n",
       "      <th>PRO27826_org</th>\n",
       "      <th>MAB_ELE_PRO276</th>\n",
       "      <th>MAB_ELE_SHP1100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>3.577403e+07</td>\n",
       "      <td>127.808839</td>\n",
       "      <td>109.119614</td>\n",
       "      <td>118.670791</td>\n",
       "      <td>124.227879</td>\n",
       "      <td>130.989253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-01</th>\n",
       "      <td>5.063649e+06</td>\n",
       "      <td>117.675874</td>\n",
       "      <td>109.224838</td>\n",
       "      <td>120.467019</td>\n",
       "      <td>127.404132</td>\n",
       "      <td>132.934130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01</th>\n",
       "      <td>3.732127e+07</td>\n",
       "      <td>123.280134</td>\n",
       "      <td>109.330063</td>\n",
       "      <td>105.378705</td>\n",
       "      <td>120.518565</td>\n",
       "      <td>131.261348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>2.709040e+07</td>\n",
       "      <td>111.043755</td>\n",
       "      <td>109.750961</td>\n",
       "      <td>107.174933</td>\n",
       "      <td>104.776326</td>\n",
       "      <td>113.057565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01</th>\n",
       "      <td>3.413209e+07</td>\n",
       "      <td>116.736921</td>\n",
       "      <td>109.856194</td>\n",
       "      <td>110.647640</td>\n",
       "      <td>109.597012</td>\n",
       "      <td>117.704727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Sales  MAB_ELE_SHP840  PRI27276_org  PRO27826_org  \\\n",
       "month_year                                                             \n",
       "2018-10-01  3.577403e+07      127.808839    109.119614    118.670791   \n",
       "2018-11-01  5.063649e+06      117.675874    109.224838    120.467019   \n",
       "2018-12-01  3.732127e+07      123.280134    109.330063    105.378705   \n",
       "2019-01-01  2.709040e+07      111.043755    109.750961    107.174933   \n",
       "2019-02-01  3.413209e+07      116.736921    109.856194    110.647640   \n",
       "\n",
       "            MAB_ELE_PRO276  MAB_ELE_SHP1100  \n",
       "month_year                                   \n",
       "2018-10-01      124.227879       130.989253  \n",
       "2018-11-01      127.404132       132.934130  \n",
       "2018-12-01      120.518565       131.261348  \n",
       "2019-01-01      104.776326       113.057565  \n",
       "2019-02-01      109.597012       117.704727  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_dfs['P1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAB_ELE_SHP840</th>\n",
       "      <th>PRI27276_org</th>\n",
       "      <th>PRO27826_org</th>\n",
       "      <th>MAB_ELE_PRO276</th>\n",
       "      <th>MAB_ELE_SHP1100</th>\n",
       "      <th>PRO271000_org</th>\n",
       "      <th>PRI27840_org</th>\n",
       "      <th>PRO27380_org</th>\n",
       "      <th>WKLWEUR840_org</th>\n",
       "      <th>PRO27276_org</th>\n",
       "      <th>...</th>\n",
       "      <th>MAB_ELE_SHP276</th>\n",
       "      <th>MAB_ELE_PRO756</th>\n",
       "      <th>PRO27756_org</th>\n",
       "      <th>PRO27392_org</th>\n",
       "      <th>PRO28380_org</th>\n",
       "      <th>PRO28276_org</th>\n",
       "      <th>PRO28826_org</th>\n",
       "      <th>MAB_ELE_SHP250</th>\n",
       "      <th>PRO27250_org</th>\n",
       "      <th>PRO28392_org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127.808839</td>\n",
       "      <td>109.119614</td>\n",
       "      <td>118.670791</td>\n",
       "      <td>124.227879</td>\n",
       "      <td>130.989253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117.675874</td>\n",
       "      <td>109.224838</td>\n",
       "      <td>120.467019</td>\n",
       "      <td>127.404132</td>\n",
       "      <td>132.934130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123.280134</td>\n",
       "      <td>109.330063</td>\n",
       "      <td>105.378705</td>\n",
       "      <td>120.518565</td>\n",
       "      <td>131.261348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111.043755</td>\n",
       "      <td>109.750961</td>\n",
       "      <td>107.174933</td>\n",
       "      <td>104.776326</td>\n",
       "      <td>113.057565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.736921</td>\n",
       "      <td>109.856194</td>\n",
       "      <td>110.647640</td>\n",
       "      <td>109.597012</td>\n",
       "      <td>117.704727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.704029</td>\n",
       "      <td>114.326241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.499260</td>\n",
       "      <td>108.999212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.294492</td>\n",
       "      <td>103.672183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.089723</td>\n",
       "      <td>98.345154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.871570</td>\n",
       "      <td>98.150484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>602 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAB_ELE_SHP840  PRI27276_org  PRO27826_org  MAB_ELE_PRO276  \\\n",
       "0        127.808839    109.119614    118.670791      124.227879   \n",
       "1        117.675874    109.224838    120.467019      127.404132   \n",
       "2        123.280134    109.330063    105.378705      120.518565   \n",
       "3        111.043755    109.750961    107.174933      104.776326   \n",
       "4        116.736921    109.856194    110.647640      109.597012   \n",
       "..              ...           ...           ...             ...   \n",
       "597             NaN           NaN           NaN             NaN   \n",
       "598             NaN           NaN           NaN             NaN   \n",
       "599             NaN           NaN           NaN             NaN   \n",
       "600             NaN           NaN           NaN             NaN   \n",
       "601             NaN           NaN           NaN             NaN   \n",
       "\n",
       "     MAB_ELE_SHP1100  PRO271000_org  PRI27840_org  PRO27380_org  \\\n",
       "0         130.989253            NaN           NaN           NaN   \n",
       "1         132.934130            NaN           NaN           NaN   \n",
       "2         131.261348            NaN           NaN           NaN   \n",
       "3         113.057565            NaN           NaN           NaN   \n",
       "4         117.704727            NaN           NaN           NaN   \n",
       "..               ...            ...           ...           ...   \n",
       "597              NaN            NaN           NaN           NaN   \n",
       "598              NaN            NaN           NaN           NaN   \n",
       "599              NaN            NaN           NaN           NaN   \n",
       "600              NaN            NaN           NaN           NaN   \n",
       "601              NaN            NaN           NaN           NaN   \n",
       "\n",
       "     WKLWEUR840_org  PRO27276_org  ...  MAB_ELE_SHP276  MAB_ELE_PRO756  \\\n",
       "0               NaN           NaN  ...             NaN             NaN   \n",
       "1               NaN           NaN  ...             NaN             NaN   \n",
       "2               NaN           NaN  ...             NaN             NaN   \n",
       "3               NaN           NaN  ...             NaN             NaN   \n",
       "4               NaN           NaN  ...             NaN             NaN   \n",
       "..              ...           ...  ...             ...             ...   \n",
       "597             NaN           NaN  ...             NaN      106.704029   \n",
       "598             NaN           NaN  ...             NaN      103.499260   \n",
       "599             NaN           NaN  ...             NaN      100.294492   \n",
       "600             NaN           NaN  ...             NaN       97.089723   \n",
       "601             NaN           NaN  ...             NaN       96.871570   \n",
       "\n",
       "     PRO27756_org  PRO27392_org  PRO28380_org  PRO28276_org  PRO28826_org  \\\n",
       "0             NaN           NaN           NaN           NaN           NaN   \n",
       "1             NaN           NaN           NaN           NaN           NaN   \n",
       "2             NaN           NaN           NaN           NaN           NaN   \n",
       "3             NaN           NaN           NaN           NaN           NaN   \n",
       "4             NaN           NaN           NaN           NaN           NaN   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "597    114.326241           NaN           NaN           NaN           NaN   \n",
       "598    108.999212           NaN           NaN           NaN           NaN   \n",
       "599    103.672183           NaN           NaN           NaN           NaN   \n",
       "600     98.345154           NaN           NaN           NaN           NaN   \n",
       "601     98.150484           NaN           NaN           NaN           NaN   \n",
       "\n",
       "     MAB_ELE_SHP250  PRO27250_org  PRO28392_org  \n",
       "0               NaN           NaN           NaN  \n",
       "1               NaN           NaN           NaN  \n",
       "2               NaN           NaN           NaN  \n",
       "3               NaN           NaN           NaN  \n",
       "4               NaN           NaN           NaN  \n",
       "..              ...           ...           ...  \n",
       "597             NaN           NaN           NaN  \n",
       "598             NaN           NaN           NaN  \n",
       "599             NaN           NaN           NaN  \n",
       "600             NaN           NaN           NaN  \n",
       "601             NaN           NaN           NaN  \n",
       "\n",
       "[602 rows x 27 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_ids = [1, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 20, 36]\n",
    "macros_list = []\n",
    "\n",
    "# Iterando sobre os IDs de produtos que você forneceu\n",
    "for prod_id in product_ids:\n",
    "    key = f'P{prod_id}'  # Construindo a chave do produto (ex: 'P1', 'P3', etc.)\n",
    "    \n",
    "    # Verificando se a chave do produto existe no dicionário\n",
    "    if key in product_dfs:\n",
    "        df = product_dfs[key]\n",
    "        \n",
    "        # Excluindo a coluna 'sales'\n",
    "        df_without_sales = df.drop(columns=['Sales'])\n",
    "        \n",
    "        # Adicionando os dados de macros à lista\n",
    "        macros_list.append(df_without_sales)\n",
    "\n",
    "# Concatenando todos os DataFrames em uma única tabela\n",
    "macros_combinations = pd.concat(macros_list, ignore_index=True)\n",
    "\n",
    "# Obtendo todas as combinações únicas de macros\n",
    "unique_combinations = macros_combinations.drop_duplicates()\n",
    "\n",
    "# Exibindo as combinações únicas\n",
    "unique_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAB_ELE_SHP840</th>\n",
       "      <th>PRI27276_org</th>\n",
       "      <th>PRO27826_org</th>\n",
       "      <th>MAB_ELE_PRO276</th>\n",
       "      <th>MAB_ELE_SHP1100</th>\n",
       "      <th>PRO271000_org</th>\n",
       "      <th>PRI27840_org</th>\n",
       "      <th>PRO27380_org</th>\n",
       "      <th>WKLWEUR840_org</th>\n",
       "      <th>PRO27276_org</th>\n",
       "      <th>...</th>\n",
       "      <th>MAB_ELE_SHP276</th>\n",
       "      <th>MAB_ELE_PRO756</th>\n",
       "      <th>PRO27756_org</th>\n",
       "      <th>PRO27392_org</th>\n",
       "      <th>PRO28380_org</th>\n",
       "      <th>PRO28276_org</th>\n",
       "      <th>PRO28826_org</th>\n",
       "      <th>MAB_ELE_SHP250</th>\n",
       "      <th>PRO27250_org</th>\n",
       "      <th>PRO28392_org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127.808839</td>\n",
       "      <td>109.119614</td>\n",
       "      <td>118.670791</td>\n",
       "      <td>124.227879</td>\n",
       "      <td>130.989253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117.675874</td>\n",
       "      <td>109.224838</td>\n",
       "      <td>120.467019</td>\n",
       "      <td>127.404132</td>\n",
       "      <td>132.934130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123.280134</td>\n",
       "      <td>109.330063</td>\n",
       "      <td>105.378705</td>\n",
       "      <td>120.518565</td>\n",
       "      <td>131.261348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111.043755</td>\n",
       "      <td>109.750961</td>\n",
       "      <td>107.174933</td>\n",
       "      <td>104.776326</td>\n",
       "      <td>113.057565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.736921</td>\n",
       "      <td>109.856194</td>\n",
       "      <td>110.647640</td>\n",
       "      <td>109.597012</td>\n",
       "      <td>117.704727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.704029</td>\n",
       "      <td>114.326241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.499260</td>\n",
       "      <td>108.999212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.294492</td>\n",
       "      <td>103.672183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.089723</td>\n",
       "      <td>98.345154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.871570</td>\n",
       "      <td>98.150484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>602 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAB_ELE_SHP840  PRI27276_org  PRO27826_org  MAB_ELE_PRO276  \\\n",
       "0        127.808839    109.119614    118.670791      124.227879   \n",
       "1        117.675874    109.224838    120.467019      127.404132   \n",
       "2        123.280134    109.330063    105.378705      120.518565   \n",
       "3        111.043755    109.750961    107.174933      104.776326   \n",
       "4        116.736921    109.856194    110.647640      109.597012   \n",
       "..              ...           ...           ...             ...   \n",
       "597             NaN           NaN           NaN             NaN   \n",
       "598             NaN           NaN           NaN             NaN   \n",
       "599             NaN           NaN           NaN             NaN   \n",
       "600             NaN           NaN           NaN             NaN   \n",
       "601             NaN           NaN           NaN             NaN   \n",
       "\n",
       "     MAB_ELE_SHP1100  PRO271000_org  PRI27840_org  PRO27380_org  \\\n",
       "0         130.989253            NaN           NaN           NaN   \n",
       "1         132.934130            NaN           NaN           NaN   \n",
       "2         131.261348            NaN           NaN           NaN   \n",
       "3         113.057565            NaN           NaN           NaN   \n",
       "4         117.704727            NaN           NaN           NaN   \n",
       "..               ...            ...           ...           ...   \n",
       "597              NaN            NaN           NaN           NaN   \n",
       "598              NaN            NaN           NaN           NaN   \n",
       "599              NaN            NaN           NaN           NaN   \n",
       "600              NaN            NaN           NaN           NaN   \n",
       "601              NaN            NaN           NaN           NaN   \n",
       "\n",
       "     WKLWEUR840_org  PRO27276_org  ...  MAB_ELE_SHP276  MAB_ELE_PRO756  \\\n",
       "0               NaN           NaN  ...             NaN             NaN   \n",
       "1               NaN           NaN  ...             NaN             NaN   \n",
       "2               NaN           NaN  ...             NaN             NaN   \n",
       "3               NaN           NaN  ...             NaN             NaN   \n",
       "4               NaN           NaN  ...             NaN             NaN   \n",
       "..              ...           ...  ...             ...             ...   \n",
       "597             NaN           NaN  ...             NaN      106.704029   \n",
       "598             NaN           NaN  ...             NaN      103.499260   \n",
       "599             NaN           NaN  ...             NaN      100.294492   \n",
       "600             NaN           NaN  ...             NaN       97.089723   \n",
       "601             NaN           NaN  ...             NaN       96.871570   \n",
       "\n",
       "     PRO27756_org  PRO27392_org  PRO28380_org  PRO28276_org  PRO28826_org  \\\n",
       "0             NaN           NaN           NaN           NaN           NaN   \n",
       "1             NaN           NaN           NaN           NaN           NaN   \n",
       "2             NaN           NaN           NaN           NaN           NaN   \n",
       "3             NaN           NaN           NaN           NaN           NaN   \n",
       "4             NaN           NaN           NaN           NaN           NaN   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "597    114.326241           NaN           NaN           NaN           NaN   \n",
       "598    108.999212           NaN           NaN           NaN           NaN   \n",
       "599    103.672183           NaN           NaN           NaN           NaN   \n",
       "600     98.345154           NaN           NaN           NaN           NaN   \n",
       "601     98.150484           NaN           NaN           NaN           NaN   \n",
       "\n",
       "     MAB_ELE_SHP250  PRO27250_org  PRO28392_org  \n",
       "0               NaN           NaN           NaN  \n",
       "1               NaN           NaN           NaN  \n",
       "2               NaN           NaN           NaN  \n",
       "3               NaN           NaN           NaN  \n",
       "4               NaN           NaN           NaN  \n",
       "..              ...           ...           ...  \n",
       "597             NaN           NaN           NaN  \n",
       "598             NaN           NaN           NaN  \n",
       "599             NaN           NaN           NaN  \n",
       "600             NaN           NaN           NaN  \n",
       "601             NaN           NaN           NaN  \n",
       "\n",
       "[602 rows x 27 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista dos números dos produtos que você mencionou\n",
    "product_ids = [1, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 20, 36]\n",
    "\n",
    "# Lista para armazenar os dados de macros de todos os produtos\n",
    "macros_list = []\n",
    "\n",
    "# Iterando sobre os IDs de produtos que você forneceu\n",
    "for prod_id in product_ids:\n",
    "    key = f'P{prod_id}'  # Construindo a chave do produto (ex: 'P1', 'P3', etc.)\n",
    "    \n",
    "    # Verificando se a chave do produto existe no dicionário\n",
    "    if key in product_dfs:\n",
    "        df = product_dfs[key]\n",
    "        \n",
    "        # Excluindo a coluna 'sales'\n",
    "        df_sem_sales = df.drop(columns=['Sales'])\n",
    "        \n",
    "        # Adicionando os dados de macros à lista\n",
    "        macros_list.append(df_sem_sales)\n",
    "\n",
    "# Concatenando todos os DataFrames em uma única tabela\n",
    "macros_combinados = pd.concat(macros_list, ignore_index=True)\n",
    "\n",
    "# Obtendo todas as combinações únicas de macros\n",
    "combinacoes_unicas = macros_combinados.drop_duplicates()\n",
    "\n",
    "# Exibindo as combinações únicas\n",
    "combinacoes_unicas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combinação de Macros</th>\n",
       "      <th>Produtos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(127.80883943812468, 109.1196136474609, 118.67...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(117.67587388309826, 109.2248382568359, 120.46...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(123.28013378640512, 109.3300628662109, 105.37...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(111.04375462185241, 109.7509613037109, 107.17...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(116.73692110885848, 109.8561935424805, 110.64...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>(106.70402895817061, 114.32624113475178, 310.7...</td>\n",
       "      <td>P36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>(103.49926026575272, 108.99921197793539, 235.9...</td>\n",
       "      <td>P36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>(100.29449157333487, 103.672182821119, 235.956...</td>\n",
       "      <td>P36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>(97.08972288091698, 98.3451536643026, 329.4133...</td>\n",
       "      <td>P36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>(96.87156966928907, 98.15048386266902, 267.373...</td>\n",
       "      <td>P36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>602 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Combinação de Macros Produtos\n",
       "0    (127.80883943812468, 109.1196136474609, 118.67...       P1\n",
       "1    (117.67587388309826, 109.2248382568359, 120.46...       P1\n",
       "2    (123.28013378640512, 109.3300628662109, 105.37...       P1\n",
       "3    (111.04375462185241, 109.7509613037109, 107.17...       P1\n",
       "4    (116.73692110885848, 109.8561935424805, 110.64...       P1\n",
       "..                                                 ...      ...\n",
       "597  (106.70402895817061, 114.32624113475178, 310.7...      P36\n",
       "598  (103.49926026575272, 108.99921197793539, 235.9...      P36\n",
       "599  (100.29449157333487, 103.672182821119, 235.956...      P36\n",
       "600  (97.08972288091698, 98.3451536643026, 329.4133...      P36\n",
       "601  (96.87156966928907, 98.15048386266902, 267.373...      P36\n",
       "\n",
       "[602 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista dos números dos produtos que você mencionou\n",
    "product_ids = [1, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 20, 36]\n",
    "\n",
    "# Dicionário para armazenar as combinações únicas de macros e os produtos onde aparecem\n",
    "combinacoes_produtos = {}\n",
    "\n",
    "# Iterando sobre os IDs de produtos que você forneceu\n",
    "for prod_id in product_ids:\n",
    "    key = f'P{prod_id}'  # Construindo a chave do produto (ex: 'P1', 'P3', etc.)\n",
    "    \n",
    "    # Verificando se a chave do produto existe no dicionário\n",
    "    if key in product_dfs:\n",
    "        df = product_dfs[key]\n",
    "        \n",
    "        # Iterando sobre cada linha do DataFrame, considerando todas as colunas, exceto 'Sales'\n",
    "        for idx, row in df.iterrows():\n",
    "            # Excluindo a coluna 'Sales' apenas para a combinação de macros\n",
    "            combinacao_macros = tuple(row.drop('Sales', errors='ignore'))  # Usando 'errors=ignore' para evitar erro se 'Sales' não existir\n",
    "            \n",
    "            # Adicionando o produto à lista de produtos para essa combinação de macros\n",
    "            if combinacao_macros not in combinacoes_produtos:\n",
    "                combinacoes_produtos[combinacao_macros] = []\n",
    "            \n",
    "            combinacoes_produtos[combinacao_macros].append(key)\n",
    "\n",
    "# Convertendo o dicionário em um DataFrame para visualização\n",
    "combinacoes_df = pd.DataFrame(list(combinacoes_produtos.items()), columns=['Combinação de Macros', 'Produtos'])\n",
    "combinacoes_df['Produtos'] = combinacoes_df['Produtos'].apply(lambda x: ', '.join(x))  # Lista de produtos como string\n",
    "\n",
    "# Exibindo o DataFrame final\n",
    "combinacoes_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Macro, Produtos]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "product_ids = [1, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 20, 36]\n",
    "\n",
    "\n",
    "# Dicionário para armazenar as macros e os produtos onde elas aparecem\n",
    "macros_produtos = {}\n",
    "\n",
    "# Iterando sobre os IDs de produtos que você forneceu\n",
    "for prod_id in product_ids:\n",
    "    key = f'P{prod_id}'  # Construindo a chave do produto (ex: 'P1', 'P3', etc.)\n",
    "    \n",
    "    # Verificando se a chave do produto existe no dicionário\n",
    "    if key in product_dfs:\n",
    "        df = product_dfs[key]\n",
    "        \n",
    "        # Iterando sobre cada coluna de macros\n",
    "        for macro in ['proteinas', 'carboidratos', 'gorduras']:\n",
    "            # Se a macro estiver no DataFrame, vamos verificar se o valor existe\n",
    "            if macro in df.columns:\n",
    "                # Adicionando o produto à lista de produtos para essa macro\n",
    "                for value in df[macro]:\n",
    "                    if key not in macros_produtos[macro]:\n",
    "                        macros_produtos[macro].append(key)\n",
    "\n",
    "# Convertendo o dicionário em um DataFrame para visualização\n",
    "macros_df = pd.DataFrame(list(macros_produtos.items()), columns=['Macro', 'Produtos'])\n",
    "macros_df['Produtos'] = macros_df['Produtos'].apply(lambda x: ', '.join(x))  # Lista de produtos como string\n",
    "\n",
    "# Exibindo o DataFrame final\n",
    "print(macros_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas do DataFrame P11:\n",
      "Index(['Sales', 'PRO27826_org', 'MAB_ELE_SHP392', 'MAB_ELE_SHP840',\n",
      "       'MAB_ELE_SHP276'],\n",
      "      dtype='object')\n",
      "\n",
      "Colunas do DataFrame P13:\n",
      "Index(['Sales', 'MAB_ELE_PRO756', 'PRO27756_org', 'MAB_ELE_PRO276',\n",
      "       'PRI27840_org'],\n",
      "      dtype='object')\n",
      "\n",
      "Colunas do DataFrame P12:\n",
      "Index(['Sales', 'PRI27840_org', 'RohCOPPER1000_org', 'MAB_ELE_PRO156'], dtype='object')\n",
      "\n",
      "Colunas do DataFrame P16:\n",
      "Index(['Sales', 'MAB_ELE_PRO756', 'PRO28276_org', 'PRI27276_org',\n",
      "       'PRO28826_org'],\n",
      "      dtype='object')\n",
      "\n",
      "Colunas do DataFrame P14:\n",
      "Index(['Sales', 'PRO27392_org', 'PRO28380_org', 'PRO27756_org'], dtype='object')\n",
      "\n",
      "Colunas do DataFrame P8:\n",
      "Index(['Sales', 'PRI27840_org', 'RohCOPPER1000_org'], dtype='object')\n",
      "\n",
      "Colunas do DataFrame P9:\n",
      "Index(['Sales', 'PRO27826_org', 'PRO271000_org', 'PRO28250_org',\n",
      "       'MAB_ELE_PRO156'],\n",
      "      dtype='object')\n",
      "\n",
      "Colunas do DataFrame Sales_CPI:\n",
      "Index(['Sales', 'MAB_ELE_SHP840', 'PRI27276_org', 'PRO271000_org',\n",
      "       'PRO27826_org'],\n",
      "      dtype='object')\n",
      "\n",
      "Colunas do DataFrame P1:\n",
      "Index(['Sales', 'MAB_ELE_SHP840', 'PRI27276_org', 'PRO27826_org',\n",
      "       'MAB_ELE_PRO276', 'MAB_ELE_SHP1100'],\n",
      "      dtype='object')\n",
      "\n",
      "Colunas do DataFrame P3:\n",
      "Index(['Sales', 'PRO27826_org', 'PRO271000_org', 'PRI27840_org'], dtype='object')\n",
      "\n",
      "Colunas do DataFrame P6:\n",
      "Index(['Sales', 'PRO27840_org', 'PRO27276_org', 'RohCRUDE_PETRO1000_org'], dtype='object')\n",
      "\n",
      "Colunas do DataFrame P4:\n",
      "Index(['Sales', 'PRO27380_org', 'WKLWEUR840_org', 'PRO27276_org',\n",
      "       'MAB_ELE_SHP380'],\n",
      "      dtype='object')\n",
      "\n",
      "Colunas do DataFrame P5:\n",
      "Index(['Sales', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org',\n",
      "       'MAB_ELE_PRO156'],\n",
      "      dtype='object')\n",
      "\n",
      "Colunas do DataFrame P36:\n",
      "Index(['Sales', 'MAB_ELE_PRO756', 'PRO27756_org', 'MAB_ELE_PRO156'], dtype='object')\n",
      "\n",
      "Colunas do DataFrame P20:\n",
      "Index(['Sales', 'MAB_ELE_SHP250', 'PRO271000_org', 'PRO27250_org',\n",
      "       'PRO28392_org'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre todos os DataFrames no dicionário `product_dfs` e exibir as colunas\n",
    "for key, df in product_dfs.items():\n",
    "    print(f\"Colunas do DataFrame {key}:\")\n",
    "    print(df.columns)\n",
    "    print()  # Apenas para separar as saídas de cada DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Macro</th>\n",
       "      <th>Produtos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAB_ELE_SHP840</td>\n",
       "      <td>P1, P5, P11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRI27276_org</td>\n",
       "      <td>P1, P16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRO27826_org</td>\n",
       "      <td>P1, P3, P5, P9, P11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAB_ELE_PRO276</td>\n",
       "      <td>P1, P13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAB_ELE_SHP1100</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PRO271000_org</td>\n",
       "      <td>P3, P5, P9, P20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRI27840_org</td>\n",
       "      <td>P3, P8, P12, P13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PRO27380_org</td>\n",
       "      <td>P4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WKLWEUR840_org</td>\n",
       "      <td>P4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PRO27276_org</td>\n",
       "      <td>P4, P6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MAB_ELE_SHP380</td>\n",
       "      <td>P4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MAB_ELE_PRO156</td>\n",
       "      <td>P5, P9, P12, P36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PRO27840_org</td>\n",
       "      <td>P6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RohCRUDE_PETRO1000_org</td>\n",
       "      <td>P6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RohCOPPER1000_org</td>\n",
       "      <td>P8, P12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PRO28250_org</td>\n",
       "      <td>P9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MAB_ELE_SHP392</td>\n",
       "      <td>P11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MAB_ELE_SHP276</td>\n",
       "      <td>P11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MAB_ELE_PRO756</td>\n",
       "      <td>P13, P16, P36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PRO27756_org</td>\n",
       "      <td>P13, P14, P36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PRO27392_org</td>\n",
       "      <td>P14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PRO28380_org</td>\n",
       "      <td>P14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PRO28276_org</td>\n",
       "      <td>P16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PRO28826_org</td>\n",
       "      <td>P16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MAB_ELE_SHP250</td>\n",
       "      <td>P20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PRO27250_org</td>\n",
       "      <td>P20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PRO28392_org</td>\n",
       "      <td>P20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Macro             Produtos\n",
       "0           MAB_ELE_SHP840          P1, P5, P11\n",
       "1             PRI27276_org              P1, P16\n",
       "2             PRO27826_org  P1, P3, P5, P9, P11\n",
       "3           MAB_ELE_PRO276              P1, P13\n",
       "4          MAB_ELE_SHP1100                   P1\n",
       "5            PRO271000_org      P3, P5, P9, P20\n",
       "6             PRI27840_org     P3, P8, P12, P13\n",
       "7             PRO27380_org                   P4\n",
       "8           WKLWEUR840_org                   P4\n",
       "9             PRO27276_org               P4, P6\n",
       "10          MAB_ELE_SHP380                   P4\n",
       "11          MAB_ELE_PRO156     P5, P9, P12, P36\n",
       "12            PRO27840_org                   P6\n",
       "13  RohCRUDE_PETRO1000_org                   P6\n",
       "14       RohCOPPER1000_org              P8, P12\n",
       "15            PRO28250_org                   P9\n",
       "16          MAB_ELE_SHP392                  P11\n",
       "17          MAB_ELE_SHP276                  P11\n",
       "18          MAB_ELE_PRO756        P13, P16, P36\n",
       "19            PRO27756_org        P13, P14, P36\n",
       "20            PRO27392_org                  P14\n",
       "21            PRO28380_org                  P14\n",
       "22            PRO28276_org                  P16\n",
       "23            PRO28826_org                  P16\n",
       "24          MAB_ELE_SHP250                  P20\n",
       "25            PRO27250_org                  P20\n",
       "26            PRO28392_org                  P20"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista de produtos para evitar na coluna 'Macro'\n",
    "produtos = {\"P1\", \"P3\", \"P4\", \"P5\", \"P6\", \"P8\", \"P9\", \"P11\", \"P12\", \"P13\", \"P14\", \"P16\", \"P20\", \"P36\"}\n",
    "\n",
    "# Dicionário de DataFrames com os dados dos produtos\n",
    "product_dfs = {\n",
    "    'P1': pd.read_pickle('product_dfs_folder/P1.pkl'),\n",
    "    'P3': pd.read_pickle('product_dfs_folder/P3.pkl'),\n",
    "    'P4': pd.read_pickle('product_dfs_folder/P4.pkl'),\n",
    "    'P5': pd.read_pickle('product_dfs_folder/P5.pkl'),\n",
    "    'P6': pd.read_pickle('product_dfs_folder/P6.pkl'),\n",
    "    'P8': pd.read_pickle('product_dfs_folder/P8.pkl'),\n",
    "    'P9': pd.read_pickle('product_dfs_folder/P9.pkl'),\n",
    "    'P11': pd.read_pickle('product_dfs_folder/P11.pkl'),\n",
    "    'P12': pd.read_pickle('product_dfs_folder/P12.pkl'),\n",
    "    'P13': pd.read_pickle('product_dfs_folder/P13.pkl'),\n",
    "    'P14': pd.read_pickle('product_dfs_folder/P14.pkl'),\n",
    "    'P16': pd.read_pickle('product_dfs_folder/P16.pkl'),\n",
    "    'P20': pd.read_pickle('product_dfs_folder/P20.pkl'),\n",
    "    'P36': pd.read_pickle('product_dfs_folder/P36.pkl'),\n",
    "}\n",
    "\n",
    "# Dicionário para armazenar as macros e os produtos correspondentes\n",
    "identificadores_produtos = {}\n",
    "\n",
    "# Iterando sobre os DataFrames\n",
    "for key, df in product_dfs.items():\n",
    "    # Iterando sobre as colunas (exceto 'Sales')\n",
    "    for col in df.columns:\n",
    "        if col != 'Sales' and col not in produtos:  # Ignora 'Sales' e produtos na coluna 'Macro'\n",
    "            if col not in identificadores_produtos:\n",
    "                identificadores_produtos[col] = []\n",
    "            identificadores_produtos[col].append(key)\n",
    "\n",
    "# Convertendo o dicionário em um DataFrame para visualização\n",
    "identificadores_df = pd.DataFrame(list(identificadores_produtos.items()), columns=['Macro', 'Produtos'])\n",
    "identificadores_df['Produtos'] = identificadores_df['Produtos'].apply(lambda x: ', '.join(x))  # Lista de produtos como string\n",
    "\n",
    "# Exibindo o DataFrame final\n",
    "identificadores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <span style=\"background-color:#000027; padding:5px; border-radius:5px;\">**Analyze Stationarity / Non-Stationarity per Macro**</span> <a id='Stationarity'></a>  \n",
    "\n",
    "Click [here](#table-of-contents) ⬆️ to return to the Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Macro: MAB_ELE_SHP840\n",
      "Testando estacionariedade da macro 'MAB_ELE_SHP840'...\n",
      "A série precisa ser unidimensional para o teste ADF.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x is required to have ndim 1 but has ndim 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stationarity_df\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Exemplo de execução:\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m stationarity_df \u001b[38;5;241m=\u001b[39m check_stationarity_for_macros(identificadores_df, product_dfs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Exibir os resultados\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResultados da Estacionariedade por Macro:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[82], line 57\u001b[0m, in \u001b[0;36mcheck_stationarity_for_macros\u001b[0;34m(identificadores_df, product_dfs)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTestando estacionariedade da macro \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmacro\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m         adf_test(final_series)  \u001b[38;5;66;03m# Aplicar o teste ADF na série concatenada\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m         stationarity_results\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMacro\u001b[39m\u001b[38;5;124m\"\u001b[39m: macro, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADF P-Value\u001b[39m\u001b[38;5;124m\"\u001b[39m: adfuller(final_series)[\u001b[38;5;241m1\u001b[39m]})\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Criar um DataFrame com os resultados das análises\u001b[39;00m\n\u001b[1;32m     60\u001b[0m stationarity_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(stationarity_results)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:263\u001b[0m, in \u001b[0;36madfuller\u001b[0;34m(x, maxlag, regression, autolag, store, regresults)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madfuller\u001b[39m(\n\u001b[1;32m    169\u001b[0m     x,\n\u001b[1;32m    170\u001b[0m     maxlag: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m     regresults\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    175\u001b[0m ):\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    Augmented Dickey-Fuller unit root test.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m        http://ideas.repec.org/p/qed/wpaper/1227.html\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m     x \u001b[38;5;241m=\u001b[39m array_like(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    264\u001b[0m     maxlag \u001b[38;5;241m=\u001b[39m int_like(maxlag, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxlag\u001b[39m\u001b[38;5;124m\"\u001b[39m, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    265\u001b[0m     regression \u001b[38;5;241m=\u001b[39m string_like(\n\u001b[1;32m    266\u001b[0m         regression, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mct\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mctt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    267\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/statsmodels/tools/validation/validation.py:155\u001b[0m, in \u001b[0;36marray_like\u001b[0;34m(obj, name, dtype, ndim, maxdim, shape, order, contiguous, optional, writeable)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m ndim:\n\u001b[1;32m    154\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is required to have ndim \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m but has ndim \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(name, ndim, arr\u001b[38;5;241m.\u001b[39mndim))\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m actual, req \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(arr\u001b[38;5;241m.\u001b[39mshape, shape):\n",
      "\u001b[0;31mValueError\u001b[0m: x is required to have ndim 1 but has ndim 2"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "import pandas as pd\n",
    "\n",
    "# Função para aplicar o teste Dickey-Fuller (ADF) em uma série\n",
    "def adf_test(series):\n",
    "    \"\"\"Realiza o teste Augmented Dickey-Fuller (ADF) para estacionariedade.\"\"\"\n",
    "    if isinstance(series, pd.Series):  # Verificar se a série é uma pd.Series\n",
    "        series = series.dropna()  # Remover NaNs antes de realizar o teste\n",
    "    if series.ndim == 1:  # Verificar se a série é unidimensional\n",
    "        result = adfuller(series)  # Realiza o teste ADF\n",
    "        print(\"Dickey-Fuller Test Results:\")\n",
    "        df_results = pd.Series(result[:4], index=[\"Test Statistic\", \"p-value\", \"# Lags Used\", \"# Observations Used\"])\n",
    "        for key, value in result[4].items():\n",
    "            df_results[f\"Critical Value ({key})\"] = value\n",
    "        print(df_results)\n",
    "        \n",
    "        # Interpretação\n",
    "        if result[1] <= 0.05:\n",
    "            print(\"✅ A série é estacionária (p-valor < 0.05).\")\n",
    "        else:\n",
    "            print(\"❌ A série NÃO é estacionária (p-valor > 0.05). Considere transformar a série.\")\n",
    "    else:\n",
    "        print(\"A série precisa ser unidimensional para o teste ADF.\")\n",
    "\n",
    "# Função para verificar a estacionariedade por macro\n",
    "def check_stationarity_for_macros(identificadores_df, product_dfs):\n",
    "    \"\"\"Verifica a estacionariedade das variáveis macro combinando as séries dos produtos.\"\"\"\n",
    "    \n",
    "    # Criar lista para armazenar os resultados\n",
    "    stationarity_results = []\n",
    "\n",
    "    # Iterar pelas macross de produtos\n",
    "    for macro in identificadores_df[\"Macro\"]:\n",
    "        print(f\"\\nMacro: {macro}\")\n",
    "        \n",
    "        # Identificar os produtos da macro\n",
    "        produtos_macro = identificadores_df.loc[identificadores_df[\"Macro\"] == macro, \"Produtos\"].values[0]\n",
    "        produtos_lista = produtos_macro.split(\", \")\n",
    "\n",
    "        # Criar uma lista para as séries dos produtos\n",
    "        combined_series = []\n",
    "\n",
    "        # Iterar sobre os produtos e coletar as séries correspondentes\n",
    "        for produto in produtos_lista:\n",
    "            if produto in product_dfs:\n",
    "                # Coletar a série temporal de cada produto, sem depender da coluna 'Sales'\n",
    "                series = product_dfs[produto].dropna()  # Remover NaNs\n",
    "                combined_series.append(series)\n",
    "\n",
    "        # Concatenar as séries de todos os produtos da macro\n",
    "        if combined_series:\n",
    "            final_series = pd.concat(combined_series, axis=0)  # Concatenar todas as séries em uma única\n",
    "            final_series = final_series.dropna()  # Remover NaNs da série concatenada\n",
    "            final_series = final_series.squeeze()  # Garantir que a série seja unidimensional (squeeze)\n",
    "            print(f\"Testando estacionariedade da macro '{macro}'...\")\n",
    "            adf_test(final_series)  # Aplicar o teste ADF na série concatenada\n",
    "            stationarity_results.append({\"Macro\": macro, \"ADF P-Value\": adfuller(final_series)[1]})\n",
    "\n",
    "    # Criar um DataFrame com os resultados das análises\n",
    "    stationarity_df = pd.DataFrame(stationarity_results)\n",
    "    return stationarity_df\n",
    "\n",
    "# Exemplo de execução:\n",
    "stationarity_df = check_stationarity_for_macros(identificadores_df, product_dfs)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"\\nResultados da Estacionariedade por Macro:\")\n",
    "print(stationarity_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Macro: MAB_ELE_SHP840\n",
      "❌ Coluna 'Sales' não encontrada no produto: P1\n",
      "❌ Coluna 'Sales' não encontrada no produto: P5\n",
      "❌ Coluna 'Sales' não encontrada no produto: P11\n",
      "\n",
      "Macro: PRI27276_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P1\n",
      "❌ Coluna 'Sales' não encontrada no produto: P16\n",
      "\n",
      "Macro: PRO27826_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P1\n",
      "❌ Coluna 'Sales' não encontrada no produto: P3\n",
      "❌ Coluna 'Sales' não encontrada no produto: P5\n",
      "❌ Coluna 'Sales' não encontrada no produto: P9\n",
      "❌ Coluna 'Sales' não encontrada no produto: P11\n",
      "\n",
      "Macro: MAB_ELE_PRO276\n",
      "❌ Coluna 'Sales' não encontrada no produto: P1\n",
      "❌ Coluna 'Sales' não encontrada no produto: P13\n",
      "\n",
      "Macro: MAB_ELE_SHP1100\n",
      "❌ Coluna 'Sales' não encontrada no produto: P1\n",
      "\n",
      "Macro: PRO271000_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P3\n",
      "❌ Coluna 'Sales' não encontrada no produto: P5\n",
      "❌ Coluna 'Sales' não encontrada no produto: P9\n",
      "❌ Coluna 'Sales' não encontrada no produto: P20\n",
      "\n",
      "Macro: PRI27840_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P3\n",
      "❌ Coluna 'Sales' não encontrada no produto: P8\n",
      "❌ Coluna 'Sales' não encontrada no produto: P12\n",
      "❌ Coluna 'Sales' não encontrada no produto: P13\n",
      "\n",
      "Macro: PRO27380_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P4\n",
      "\n",
      "Macro: WKLWEUR840_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P4\n",
      "\n",
      "Macro: PRO27276_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P4\n",
      "❌ Coluna 'Sales' não encontrada no produto: P6\n",
      "\n",
      "Macro: MAB_ELE_SHP380\n",
      "❌ Coluna 'Sales' não encontrada no produto: P4\n",
      "\n",
      "Macro: MAB_ELE_PRO156\n",
      "❌ Coluna 'Sales' não encontrada no produto: P5\n",
      "❌ Coluna 'Sales' não encontrada no produto: P9\n",
      "❌ Coluna 'Sales' não encontrada no produto: P12\n",
      "❌ Coluna 'Sales' não encontrada no produto: P36\n",
      "\n",
      "Macro: PRO27840_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P6\n",
      "\n",
      "Macro: RohCRUDE_PETRO1000_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P6\n",
      "\n",
      "Macro: RohCOPPER1000_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P8\n",
      "❌ Coluna 'Sales' não encontrada no produto: P12\n",
      "\n",
      "Macro: PRO28250_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P9\n",
      "\n",
      "Macro: MAB_ELE_SHP392\n",
      "❌ Coluna 'Sales' não encontrada no produto: P11\n",
      "\n",
      "Macro: MAB_ELE_SHP276\n",
      "❌ Coluna 'Sales' não encontrada no produto: P11\n",
      "\n",
      "Macro: MAB_ELE_PRO756\n",
      "❌ Coluna 'Sales' não encontrada no produto: P13\n",
      "❌ Coluna 'Sales' não encontrada no produto: P16\n",
      "❌ Coluna 'Sales' não encontrada no produto: P36\n",
      "\n",
      "Macro: PRO27756_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P13\n",
      "❌ Coluna 'Sales' não encontrada no produto: P14\n",
      "❌ Coluna 'Sales' não encontrada no produto: P36\n",
      "\n",
      "Macro: PRO27392_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P14\n",
      "\n",
      "Macro: PRO28380_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P14\n",
      "\n",
      "Macro: PRO28276_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P16\n",
      "\n",
      "Macro: PRO28826_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P16\n",
      "\n",
      "Macro: MAB_ELE_SHP250\n",
      "❌ Coluna 'Sales' não encontrada no produto: P20\n",
      "\n",
      "Macro: PRO27250_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P20\n",
      "\n",
      "Macro: PRO28392_org\n",
      "❌ Coluna 'Sales' não encontrada no produto: P20\n",
      "\n",
      "Resultados da Estacionariedade por Macro:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Função para aplicar o teste Dickey-Fuller (ADF) em uma série\n",
    "def adf_test(series):\n",
    "    \"\"\"Realiza o teste Augmented Dickey-Fuller (ADF) para estacionariedade.\"\"\"\n",
    "    result = adfuller(series.dropna())  # Remover NaNs antes de realizar o teste\n",
    "    print(\"Dickey-Fuller Test Results:\")\n",
    "    df_results = pd.Series(result[:4], index=[\"Test Statistic\", \"p-value\", \"# Lags Used\", \"# Observations Used\"])\n",
    "    for key, value in result[4].items():\n",
    "        df_results[f\"Critical Value ({key})\"] = value\n",
    "    print(df_results)\n",
    "    \n",
    "    # Interpretação\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"✅ A série é estacionária (p-valor < 0.05).\")\n",
    "    else:\n",
    "        print(\"❌ A série NÃO é estacionária (p-valor > 0.05). Considere transformar a série.\")\n",
    "\n",
    "# Função para verificar a estacionariedade por macro\n",
    "def check_stationarity_for_macros(identificadores_df, product_dfs):\n",
    "    \"\"\"Verifica a estacionariedade das variáveis macro combinando as séries dos produtos.\"\"\"\n",
    "    \n",
    "    # Criar lista para armazenar os resultados\n",
    "    stationarity_results = []\n",
    "\n",
    "    # Iterar pelas macross de produtos\n",
    "    for macro in identificadores_df[\"Macro\"]:\n",
    "        print(f\"\\nMacro: {macro}\")\n",
    "        \n",
    "        # Identificar os produtos da macro\n",
    "        produtos_macro = identificadores_df.loc[identificadores_df[\"Macro\"] == macro, \"Produtos\"].values[0]\n",
    "        produtos_lista = produtos_macro.split(\", \")\n",
    "\n",
    "        # Criar uma lista para as séries dos produtos\n",
    "        combined_series = []\n",
    "\n",
    "        # Iterar sobre os produtos e coletar as séries correspondentes\n",
    "        for produto in produtos_lista:\n",
    "            if produto in product_dfs:\n",
    "                # Verificar se a coluna 'Sales' existe no DataFrame do produto\n",
    "                if 'Sales' in product_dfs[produto].columns:\n",
    "                    series = product_dfs[produto][\"Sales\"].dropna()\n",
    "                    combined_series.append(series)\n",
    "                else:\n",
    "                    print(f\"❌ Coluna 'Sales' não encontrada no produto: {produto}\")\n",
    "                    continue  # Ignorar o produto se não tiver a coluna 'Sales'\n",
    "\n",
    "        # Concatenar as séries de todos os produtos da macro\n",
    "        if combined_series:\n",
    "            final_series = pd.concat(combined_series)\n",
    "            print(f\"Testando estacionariedade da macro '{macro}'...\")\n",
    "            adf_test(final_series)  # Aplicar o teste ADF na série concatenada\n",
    "            stationarity_results.append({\"Macro\": macro, \"ADF P-Value\": adfuller(final_series)[1]})\n",
    "\n",
    "    # Criar um DataFrame com os resultados das análises\n",
    "    stationarity_df = pd.DataFrame(stationarity_results)\n",
    "    return stationarity_df\n",
    "\n",
    "# Exemplo de execução:\n",
    "stationarity_df = check_stationarity_for_macros(identificadores_df, product_dfs)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"\\nResultados da Estacionariedade por Macro:\")\n",
    "print(stationarity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Macro: MAB_ELE_SHP840\n",
      "Testando estacionariedade da macro 'MAB_ELE_SHP840'...\n",
      "A série precisa ser unidimensional para o teste ADF.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x is required to have ndim 1 but has ndim 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stationarity_df\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Exemplo de execução:\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m stationarity_df \u001b[38;5;241m=\u001b[39m check_stationarity_for_macros(identificadores_df, product_dfs)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Exibir os resultados\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResultados da Estacionariedade por Macro:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[67], line 51\u001b[0m, in \u001b[0;36mcheck_stationarity_for_macros\u001b[0;34m(identificadores_df, product_dfs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTestando estacionariedade da macro \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmacro\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m         adf_test(final_series)  \u001b[38;5;66;03m# Aplicar o teste ADF na série concatenada\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m         stationarity_results\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMacro\u001b[39m\u001b[38;5;124m\"\u001b[39m: macro, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADF P-Value\u001b[39m\u001b[38;5;124m\"\u001b[39m: adfuller(final_series)[\u001b[38;5;241m1\u001b[39m]})\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Criar um DataFrame com os resultados das análises\u001b[39;00m\n\u001b[1;32m     54\u001b[0m stationarity_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(stationarity_results)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:263\u001b[0m, in \u001b[0;36madfuller\u001b[0;34m(x, maxlag, regression, autolag, store, regresults)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madfuller\u001b[39m(\n\u001b[1;32m    169\u001b[0m     x,\n\u001b[1;32m    170\u001b[0m     maxlag: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m     regresults\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    175\u001b[0m ):\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    Augmented Dickey-Fuller unit root test.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m        http://ideas.repec.org/p/qed/wpaper/1227.html\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m     x \u001b[38;5;241m=\u001b[39m array_like(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    264\u001b[0m     maxlag \u001b[38;5;241m=\u001b[39m int_like(maxlag, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxlag\u001b[39m\u001b[38;5;124m\"\u001b[39m, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    265\u001b[0m     regression \u001b[38;5;241m=\u001b[39m string_like(\n\u001b[1;32m    266\u001b[0m         regression, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mct\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mctt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    267\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/statsmodels/tools/validation/validation.py:155\u001b[0m, in \u001b[0;36marray_like\u001b[0;34m(obj, name, dtype, ndim, maxdim, shape, order, contiguous, optional, writeable)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m ndim:\n\u001b[1;32m    154\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is required to have ndim \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m but has ndim \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(name, ndim, arr\u001b[38;5;241m.\u001b[39mndim))\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m actual, req \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(arr\u001b[38;5;241m.\u001b[39mshape, shape):\n",
      "\u001b[0;31mValueError\u001b[0m: x is required to have ndim 1 but has ndim 2"
     ]
    }
   ],
   "source": [
    "# Função para aplicar o teste Dickey-Fuller (ADF) em uma série\n",
    "def adf_test(series):\n",
    "    \"\"\"Realiza o teste Augmented Dickey-Fuller (ADF) para estacionariedade.\"\"\"\n",
    "    series = series.dropna()  # Remover NaNs antes de realizar o teste\n",
    "    if series.ndim == 1:  # Verificar se a série é unidimensional\n",
    "        result = adfuller(series)  # Realiza o teste ADF\n",
    "        print(\"Dickey-Fuller Test Results:\")\n",
    "        df_results = pd.Series(result[:4], index=[\"Test Statistic\", \"p-value\", \"# Lags Used\", \"# Observations Used\"])\n",
    "        for key, value in result[4].items():\n",
    "            df_results[f\"Critical Value ({key})\"] = value\n",
    "        print(df_results)\n",
    "        \n",
    "        # Interpretação\n",
    "        if result[1] <= 0.05:\n",
    "            print(\"✅ A série é estacionária (p-valor < 0.05).\")\n",
    "        else:\n",
    "            print(\"❌ A série NÃO é estacionária (p-valor > 0.05). Considere transformar a série.\")\n",
    "    else:\n",
    "        print(\"A série precisa ser unidimensional para o teste ADF.\")\n",
    "\n",
    "# Função para verificar a estacionariedade por macro\n",
    "def check_stationarity_for_macros(identificadores_df, product_dfs):\n",
    "    \"\"\"Verifica a estacionariedade das variáveis macro combinando as séries dos produtos.\"\"\"\n",
    "    \n",
    "    # Criar lista para armazenar os resultados\n",
    "    stationarity_results = []\n",
    "\n",
    "    # Iterar pelas macross de produtos\n",
    "    for macro in identificadores_df[\"Macro\"]:\n",
    "        print(f\"\\nMacro: {macro}\")\n",
    "        \n",
    "        # Identificar os produtos da macro\n",
    "        produtos_macro = identificadores_df.loc[identificadores_df[\"Macro\"] == macro, \"Produtos\"].values[0]\n",
    "        produtos_lista = produtos_macro.split(\", \")\n",
    "\n",
    "        # Criar uma lista para as séries dos produtos\n",
    "        combined_series = []\n",
    "\n",
    "        # Iterar sobre os produtos e coletar as séries correspondentes\n",
    "        for produto in produtos_lista:\n",
    "            if produto in product_dfs:\n",
    "                # Coletar a série temporal de cada produto, sem depender da coluna 'Sales'\n",
    "                series = product_dfs[produto].dropna()  # Remover NaNs\n",
    "                combined_series.append(series)\n",
    "\n",
    "        # Concatenar as séries de todos os produtos da macro\n",
    "        if combined_series:\n",
    "            final_series = pd.concat(combined_series, axis=0)  # Concatenar todas as séries em uma única (unidimensional)\n",
    "            print(f\"Testando estacionariedade da macro '{macro}'...\")\n",
    "            adf_test(final_series)  # Aplicar o teste ADF na série concatenada\n",
    "            stationarity_results.append({\"Macro\": macro, \"ADF P-Value\": adfuller(final_series)[1]})\n",
    "\n",
    "    # Criar um DataFrame com os resultados das análises\n",
    "    stationarity_df = pd.DataFrame(stationarity_results)\n",
    "    return stationarity_df\n",
    "\n",
    "# Exemplo de execução:\n",
    "stationarity_df = check_stationarity_for_macros(identificadores_df, product_dfs)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"\\nResultados da Estacionariedade por Macro:\")\n",
    "print(stationarity_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <span style=\"background-color:#000027; padding:5px; border-radius:5px;font-size:13pt\">**Autocorrelation Function (ACF)**</span> <a id='Autocorrelation'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analisando a macro: MAB_ELE_SHP840\n",
      "\n",
      "Analisando a macro: PRI27276_org\n",
      "\n",
      "Analisando a macro: PRO27826_org\n",
      "\n",
      "Analisando a macro: MAB_ELE_PRO276\n",
      "\n",
      "Analisando a macro: MAB_ELE_SHP1100\n",
      "Testando estacionariedade da macro 'MAB_ELE_SHP1100'...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x is required to have ndim 1 but has ndim 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 113\u001b[0m\n\u001b[1;32m    109\u001b[0m     fig\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Exemplo de execução:\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Assumindo que 'identificadores_df' e 'product_dfs' já estão definidos, podemos chamar a função para plotar as correlações.\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m plot_correlation_for_macros(identificadores_df, product_dfs, lags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, plot_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[83], line 60\u001b[0m, in \u001b[0;36mplot_correlation_for_macros\u001b[0;34m(identificadores_df, product_dfs, lags, plot_type)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTestando estacionariedade da macro \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmacro\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plot_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 60\u001b[0m     corr_values \u001b[38;5;241m=\u001b[39m acf(final_series, nlags\u001b[38;5;241m=\u001b[39mlags, fft\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Erro padrão para ACF (fórmula de Bartlett)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     se \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.24\u001b[39m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mlen\u001b[39m(final_series))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:686\u001b[0m, in \u001b[0;36macf\u001b[0;34m(x, adjusted, nlags, qstat, fft, alpha, bartlett_confint, missing)\u001b[0m\n\u001b[1;32m    682\u001b[0m alpha \u001b[38;5;241m=\u001b[39m float_like(alpha, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    683\u001b[0m missing \u001b[38;5;241m=\u001b[39m string_like(\n\u001b[1;32m    684\u001b[0m     missing, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconservative\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    685\u001b[0m )\n\u001b[0;32m--> 686\u001b[0m x \u001b[38;5;241m=\u001b[39m array_like(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    687\u001b[0m \u001b[38;5;66;03m# TODO: should this shrink for missing=\"drop\" and NaNs in x?\u001b[39;00m\n\u001b[1;32m    688\u001b[0m nobs \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/statsmodels/tools/validation/validation.py:155\u001b[0m, in \u001b[0;36marray_like\u001b[0;34m(obj, name, dtype, ndim, maxdim, shape, order, contiguous, optional, writeable)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m ndim:\n\u001b[1;32m    154\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is required to have ndim \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m but has ndim \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(name, ndim, arr\u001b[38;5;241m.\u001b[39mndim))\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m actual, req \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(arr\u001b[38;5;241m.\u001b[39mshape, shape):\n",
      "\u001b[0;31mValueError\u001b[0m: x is required to have ndim 1 but has ndim 2"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "# Função para plotar a correlação para produtos, adaptado para previsão estacionária das macros\n",
    "def plot_correlation_for_macros(identificadores_df, product_dfs, lags=30, plot_type='acf'):\n",
    "    \"\"\"\n",
    "    Plots ACF or PACF for the combination of product series in each macro.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    identificadores_df : pd.DataFrame\n",
    "        DataFrame contendo a relação de produtos e suas macros.\n",
    "    product_dfs : dict\n",
    "        Dicionário onde as chaves são os produtos e os valores são os DataFrames das séries temporais de cada produto.\n",
    "    lags : int\n",
    "        Número de lags para computar\n",
    "    plot_type : str ('acf' ou 'pacf')\n",
    "        Tipo de gráfico de correlação a ser exibido\n",
    "    \"\"\"\n",
    "    # Validação do tipo de gráfico\n",
    "    plot_type = plot_type.lower()\n",
    "    if plot_type not in ['acf', 'pacf']:\n",
    "        raise ValueError(\"plot_type must be either 'acf' or 'pacf'\")\n",
    "\n",
    "    # Inicializa o gráfico de subplots\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=len(identificadores_df[\"Macro\"].unique()),  # Número de colunas igual ao número de macros únicas\n",
    "        subplot_titles=[f\"{plot_type.upper()}: {macro}\" for macro in identificadores_df[\"Macro\"].unique()],\n",
    "        horizontal_spacing=0.01)\n",
    "\n",
    "    # Itera sobre cada macro\n",
    "    for i, macro in enumerate(identificadores_df[\"Macro\"].unique()):\n",
    "        print(f\"\\nAnalisando a macro: {macro}\")\n",
    "        \n",
    "        # Identifica os produtos da macro\n",
    "        produtos_macro = identificadores_df.loc[identificadores_df[\"Macro\"] == macro, \"Produtos\"].values[0]\n",
    "        produtos_lista = produtos_macro.split(\", \")\n",
    "\n",
    "        # Criar uma lista para as séries dos produtos\n",
    "        combined_series = []\n",
    "\n",
    "        # Itera sobre os produtos e coleta as séries temporais correspondentes\n",
    "        for produto in produtos_lista:\n",
    "            if produto in product_dfs:\n",
    "                series = product_dfs[produto].dropna()  # Remove NaNs\n",
    "                combined_series.append(series)\n",
    "\n",
    "        # Concatenar as séries de todos os produtos da macro\n",
    "        if combined_series:\n",
    "            final_series = pd.concat(combined_series, axis=0)  # Concatena todas as séries em uma única série\n",
    "            final_series = final_series.dropna()  # Remove NaNs da série concatenada\n",
    "            \n",
    "            if len(final_series) > 1:  # Garante que a série tenha mais de um ponto\n",
    "                print(f\"Testando estacionariedade da macro '{macro}'...\")\n",
    "                if plot_type == 'acf':\n",
    "                    corr_values = acf(final_series, nlags=lags, fft=True)\n",
    "                    # Erro padrão para ACF (fórmula de Bartlett)\n",
    "                    se = 2.24 / np.sqrt(len(final_series))\n",
    "                else:\n",
    "                    corr_values = pacf(final_series, nlags=lags)\n",
    "                    # Erro padrão para PACF (1/sqrt(n))\n",
    "                    se = 2.24 / np.sqrt(len(final_series))\n",
    "                \n",
    "                lags_range = list(range(lags+1))\n",
    "                \n",
    "                # Cria o efeito \"stem\" (linha + marcador no topo)\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=lags_range, y=corr_values, mode='lines+markers', line=dict(color='blue', width=1),\n",
    "                        marker=dict(color='blue', size=5), name=macro,\n",
    "                        hovertemplate=f\"Lag %{{x}}<br>{plot_type.upper()}: %{{y:.2f}}<extra></extra>\"),\n",
    "                    row=1, col=i+1)\n",
    "                \n",
    "                # Adiciona linhas verticais finas de 0 até o valor da correlação (efeito stem)\n",
    "                for lag, val in zip(lags_range, corr_values):\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=[lag, lag], y=[0, val], mode='lines', line=dict(color='blue', width=1),\n",
    "                            showlegend=False, hoverinfo='skip'), row=1, col=i+1)\n",
    "                \n",
    "                # Adiciona intervalos de confiança constantes\n",
    "                fig.add_hline(y=se, line=dict(color='red', width=1, dash='dash'), \n",
    "                             row=1, col=i+1, opacity=0.7)\n",
    "                fig.add_hline(y=-se, line=dict(color='red', width=1, dash='dash'), \n",
    "                             row=1, col=i+1, opacity=0.7)\n",
    "                \n",
    "                # Área sombreada para o intervalo de confiança\n",
    "                fig.add_hrect(y0=-se, y1=se, \n",
    "                             line_width=0, fillcolor='rgba(100,100,100,0.2)', \n",
    "                             row=1, col=i+1)\n",
    "\n",
    "    # Atualiza o layout do gráfico\n",
    "    fig.update_layout(\n",
    "        title_text=f\"{plot_type.upper()} por Macro (97.5% Confidence)\",\n",
    "        height=500,\n",
    "        width=500*len(identificadores_df[\"Macro\"].unique()),  # Ajusta o tamanho com base no número de macros\n",
    "        showlegend=False,\n",
    "        margin=dict(l=20, r=20))\n",
    "    \n",
    "    # Configurações uniformes dos eixos\n",
    "    fig.update_yaxes(range=[-1.1, 1.1], title_text=plot_type.upper())\n",
    "    fig.update_xaxes(title_text=\"Lag\")\n",
    "    \n",
    "    # Exibe o gráfico\n",
    "    fig.show()\n",
    "\n",
    "# Exemplo de execução:\n",
    "# Assumindo que 'identificadores_df' e 'product_dfs' já estão definidos, podemos chamar a função para plotar as correlações.\n",
    "plot_correlation_for_macros(identificadores_df, product_dfs, lags=30, plot_type='acf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_for_products(df_sales, plot_type='acf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <span style=\"background-color:#000027; padding:5px; border-radius:5px;font-size:13pt\">**Partial Autocorrelation Function (PACF)**</span> <a id='PACF'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sales'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Sales'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m produto \u001b[38;5;129;01min\u001b[39;00m produtos_lista:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m produto \u001b[38;5;129;01min\u001b[39;00m product_dfs:\n\u001b[0;32m---> 30\u001b[0m         series \u001b[38;5;241m=\u001b[39m product_dfs[produto][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m     31\u001b[0m         combined_series\u001b[38;5;241m.\u001b[39mappend(series)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Concatenar todas as séries da macro\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Sales'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Função para classificar as variáveis\n",
    "def classify_variable(series):\n",
    "    \"\"\"Classifica a variável com base em testes de normalidade e estacionariedade.\"\"\"\n",
    "    \n",
    "    clean_series = series.dropna()\n",
    "    if len(clean_series) > 3:\n",
    "        stat, p_value = shapiro(clean_series)\n",
    "        is_normal = p_value > 0.05  # p-value > 0.05 significa normal\n",
    "        \n",
    "        adf_stat, adf_p_value, _, _, _, _ = adfuller(clean_series)\n",
    "        is_stationary = adf_p_value < 0.05  # p-value < 0.05 significa estacionária\n",
    "    else:\n",
    "        is_normal = False\n",
    "        is_stationary = False\n",
    "\n",
    "    return is_normal, is_stationary, adf_p_value\n",
    "\n",
    "# Aplicar análise de estacionariedade por macro\n",
    "stationarity_results = []\n",
    "\n",
    "for macro in identificadores_df[\"Macro\"]:\n",
    "    # Criar uma série temporal composta por produtos da macro\n",
    "    produtos_macro = identificadores_df.loc[identificadores_df[\"Macro\"] == macro, \"Produtos\"].values[0]\n",
    "    produtos_lista = produtos_macro.split(\", \")\n",
    "\n",
    "    combined_series = []\n",
    "    \n",
    "    for produto in produtos_lista:\n",
    "        if produto in product_dfs:\n",
    "            series = product_dfs[produto][\"Sales\"].dropna()\n",
    "            combined_series.append(series)\n",
    "\n",
    "    # Concatenar todas as séries da macro\n",
    "    if combined_series:\n",
    "        final_series = pd.concat(combined_series)\n",
    "        _, _, adf_p_value = classify_variable(final_series)\n",
    "        stationarity_results.append({\"Macro\": macro, \"ADF P-Value\": adf_p_value})\n",
    "\n",
    "# Criar DataFrame com os resultados da análise de estacionariedade\n",
    "stationarity_df = pd.DataFrame(stationarity_results)\n",
    "\n",
    "# Função de imputação automática\n",
    "def auto_impute_missing_values(df_train, df_test):\n",
    "    \"\"\"Preenche valores ausentes automaticamente usando métodos adequados.\"\"\"\n",
    "\n",
    "    missing_columns = df_test.columns[df_test.isnull().any()]\n",
    "    \n",
    "    for col in missing_columns:\n",
    "        print(f\"Processando: {col}\")\n",
    "        series = df_train[col]  # Usar dados de treino para imputação\n",
    "\n",
    "        is_normal, is_stationary, _ = classify_variable(series)\n",
    "\n",
    "        if is_normal:\n",
    "            print(f\" - {col} é normal → Usando Média & Desvio Padrão\")\n",
    "            mean_value, std_value = series.mean(), series.std()\n",
    "            num_missing = df_test[col].isnull().sum()\n",
    "            predictions = norm.rvs(loc=mean_value, scale=std_value, size=num_missing)\n",
    "        \n",
    "        elif is_stationary:\n",
    "            print(f\" - {col} é estacionária → Usando Suavização Exponencial Simples\")\n",
    "            model = SimpleExpSmoothing(series.dropna()).fit()\n",
    "            predictions = model.forecast(steps=df_test[col].isnull().sum())\n",
    "\n",
    "        else:\n",
    "            print(f\" - {col} é não-estacionária → Usando ARIMA\")\n",
    "            model = ARIMA(series.dropna(), order=(1, 1, 1))\n",
    "            fitted_model = model.fit()\n",
    "            predictions = fitted_model.forecast(steps=df_test[col].isnull().sum())\n",
    "\n",
    "        missing_indexes = df_test[df_test[col].isnull()].index\n",
    "        df_test.loc[missing_indexes, col] = predictions\n",
    "\n",
    "    return df_test\n",
    "\n",
    "# Aplicando imputação automática no conjunto de teste\n",
    "df_train = remerged_data[1]  \n",
    "df_test = test_1.copy()\n",
    "df_test_filled = auto_impute_missing_values(df_train, df_test)\n",
    "\n",
    "# Exibir resultados finais\n",
    "print(\"Análise de Estacionariedade por Macro:\")\n",
    "print(stationarity_df)\n",
    "print(\"\\nAmostra do Conjunto de Teste após Imputação:\")\n",
    "print(df_test_filled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remerged_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 101\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_test\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Aplicando imputação automática no conjunto de teste\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m df_train \u001b[38;5;241m=\u001b[39m remerged_data[\u001b[38;5;241m1\u001b[39m]  \n\u001b[1;32m    102\u001b[0m df_test \u001b[38;5;241m=\u001b[39m test_1\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    103\u001b[0m df_test_filled \u001b[38;5;241m=\u001b[39m auto_impute_missing_values(df_train, df_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'remerged_data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Função para classificar as variáveis\n",
    "def classify_variable(series):\n",
    "    \"\"\"Classifica a variável com base em testes de normalidade e estacionariedade.\"\"\"\n",
    "    \n",
    "    clean_series = series.dropna()\n",
    "    if len(clean_series) > 3:\n",
    "        stat, p_value = shapiro(clean_series)\n",
    "        is_normal = p_value > 0.05  # p-value > 0.05 significa normal\n",
    "        \n",
    "        adf_stat, adf_p_value, _, _, _, _ = adfuller(clean_series)\n",
    "        is_stationary = adf_p_value < 0.05  # p-value < 0.05 significa estacionária\n",
    "    else:\n",
    "        is_normal = False\n",
    "        is_stationary = False\n",
    "        adf_p_value = None  # Valor nulo se não houver dados suficientes\n",
    "\n",
    "    return is_normal, is_stationary, adf_p_value\n",
    "\n",
    "# Aplicar análise de estacionariedade por macro\n",
    "stationarity_results = []\n",
    "\n",
    "for macro in identificadores_df[\"Macro\"]:\n",
    "    # Criar uma série temporal composta por produtos da macro\n",
    "    produtos_macro = identificadores_df.loc[identificadores_df[\"Macro\"] == macro, \"Produtos\"].values[0]\n",
    "    produtos_lista = produtos_macro.split(\", \")\n",
    "\n",
    "    combined_series = []\n",
    "    \n",
    "    for produto in produtos_lista:\n",
    "        if produto in product_dfs:\n",
    "            df = product_dfs[produto]\n",
    "\n",
    "            # Escolher a primeira coluna numérica disponível para análise\n",
    "            numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "            if not numeric_cols.empty:\n",
    "                series = df[numeric_cols[0]].dropna()\n",
    "                combined_series.append(series)\n",
    "\n",
    "    # Concatenar todas as séries da macro\n",
    "    if combined_series:\n",
    "        final_series = pd.concat(combined_series)\n",
    "        _, _, adf_p_value = classify_variable(final_series)\n",
    "        stationarity_results.append({\"Macro\": macro, \"ADF P-Value\": adf_p_value})\n",
    "\n",
    "# Criar DataFrame com os resultados da análise de estacionariedade\n",
    "stationarity_df = pd.DataFrame(stationarity_results)\n",
    "\n",
    "# Função de imputação automática\n",
    "def auto_impute_missing_values(df_train, df_test):\n",
    "    \"\"\"Preenche valores ausentes automaticamente usando métodos adequados.\"\"\"\n",
    "\n",
    "    missing_columns = df_test.columns[df_test.isnull().any()]\n",
    "    \n",
    "    for col in missing_columns:\n",
    "        print(f\"Processando: {col}\")\n",
    "        \n",
    "        # Verifica se a coluna existe no conjunto de treino\n",
    "        if col not in df_train.columns:\n",
    "            print(f\" - {col} não está presente no conjunto de treino. Pulando...\")\n",
    "            continue\n",
    "\n",
    "        series = df_train[col].dropna()  # Remover valores ausentes\n",
    "\n",
    "        if len(series) < 3:\n",
    "            print(f\" - {col} tem poucos dados para análise. Pulando...\")\n",
    "            continue\n",
    "\n",
    "        is_normal, is_stationary, _ = classify_variable(series)\n",
    "\n",
    "        if is_normal:\n",
    "            print(f\" - {col} é normal → Usando Média & Desvio Padrão\")\n",
    "            mean_value, std_value = series.mean(), series.std()\n",
    "            num_missing = df_test[col].isnull().sum()\n",
    "            predictions = norm.rvs(loc=mean_value, scale=std_value, size=num_missing)\n",
    "        \n",
    "        elif is_stationary:\n",
    "            print(f\" - {col} é estacionária → Usando Suavização Exponencial Simples\")\n",
    "            model = SimpleExpSmoothing(series).fit()\n",
    "            predictions = model.forecast(steps=df_test[col].isnull().sum())\n",
    "\n",
    "        else:\n",
    "            print(f\" - {col} é não-estacionária → Usando ARIMA\")\n",
    "            model = ARIMA(series, order=(1, 1, 1))\n",
    "            fitted_model = model.fit()\n",
    "            predictions = fitted_model.forecast(steps=df_test[col].isnull().sum())\n",
    "\n",
    "        # Preencher valores ausentes\n",
    "        missing_indexes = df_test[df_test[col].isnull()].index\n",
    "        df_test.loc[missing_indexes, col] = predictions\n",
    "\n",
    "    return df_test\n",
    "\n",
    "# Aplicando imputação automática no conjunto de teste\n",
    "df_train = remerged_data[1]  \n",
    "df_test = test_1.copy()\n",
    "df_test_filled = auto_impute_missing_values(df_train, df_test)\n",
    "\n",
    "# Exibir resultados finais\n",
    "print(\"Análise de Estacionariedade por Macro:\")\n",
    "print(stationarity_df)\n",
    "print(\"\\nAmostra do Conjunto de Teste após Imputação:\")\n",
    "print(df_test_filled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"background-color:#000027; padding:5px; border-radius:5px;\"> 📌 Prediction for the Macro Features used <a id='business-understanding'></a>\n",
    "\n",
    "##### Click [here](#table-of-contents) ⬆️ to return to the Index.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to classify variables\n",
    "def classify_variable(series):\n",
    "    \"\"\"Classifies variable based on normality and stationarity tests.\"\"\"\n",
    "    \n",
    "    # Remove NaN values for testing\n",
    "    clean_series = series.dropna()\n",
    "\n",
    "    # Check for normality\n",
    "    if len(clean_series) > 3:\n",
    "        stat, p_value = shapiro(clean_series)\n",
    "        is_normal = p_value > 0.05  # p-value > 0.05 means normal\n",
    "    else:\n",
    "        is_normal = False  # Not enough data to test normality\n",
    "\n",
    "    # Check for stationarity\n",
    "    if len(clean_series) > 3:\n",
    "        adf_stat, adf_p_value, _, _, _, _ = adfuller(clean_series)\n",
    "        is_stationary = adf_p_value < 0.05  # p-value < 0.05 means stationary\n",
    "    else:\n",
    "        is_stationary = False  # Not enough data\n",
    "\n",
    "    return is_normal, is_stationary\n",
    "\n",
    "# Function to automatically fill missing values\n",
    "def auto_impute_missing_values(df_train, df_test):\n",
    "    \"\"\"Automatically selects the best imputation method for each missing variable.\"\"\"\n",
    "    \n",
    "    # Identify missing columns in test set\n",
    "    missing_columns = df_test.columns[df_test.isnull().any()]\n",
    "    \n",
    "    # Iterate through missing columns\n",
    "    for col in missing_columns:\n",
    "        print(f\"Processing: {col}\")\n",
    "\n",
    "        series = df_train[col]  # Use train data for imputation\n",
    "        is_normal, is_stationary = classify_variable(series)\n",
    "\n",
    "        if is_normal:\n",
    "            # Case 1: Normally distributed → Sample from normal distribution\n",
    "            print(f\" - {col} is normal → Using Mean & Std Sampling\")\n",
    "            mean_value, std_value = series.mean(), series.std()\n",
    "            num_missing = df_test[col].isnull().sum()\n",
    "            predictions = norm.rvs(loc=mean_value, scale=std_value, size=num_missing)\n",
    "        \n",
    "        elif is_stationary:\n",
    "            # Case 2: Stationary but non-normal → Simple Exponential Smoothing\n",
    "            print(f\" - {col} is stationary → Using Simple Exponential Smoothing\")\n",
    "            model = SimpleExpSmoothing(series.dropna()).fit()\n",
    "            predictions = model.forecast(steps=df_test[col].isnull().sum())\n",
    "\n",
    "        elif not is_stationary:\n",
    "            # Case 3: Non-Stationary → ARIMA\n",
    "            print(f\" - {col} is non-stationary → Using ARIMA\")\n",
    "            model = ARIMA(series.dropna(), order=(1, 1, 1))  # (p,d,q) chosen based on domain knowledge\n",
    "            fitted_model = model.fit()\n",
    "            predictions = fitted_model.forecast(steps=df_test[col].isnull().sum())\n",
    "\n",
    "        else:\n",
    "            # Case 4: If nothing works → Use XGBoost Regression\n",
    "            print(f\" - {col} is complex → Using XGBoost Regression\")\n",
    "            train_data = df_train.dropna(subset=[col])  # Drop missing values for training\n",
    "            X_train = train_data.drop(columns=[col])  # Exclude target column\n",
    "            y_train = train_data[col]  # Target column\n",
    "\n",
    "            X_test = df_test.loc[df_test[col].isnull(), X_train.columns]  # Only missing values\n",
    "\n",
    "            model = XGBRegressor(n_estimators=100, learning_rate=0.1)\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X_test)\n",
    "\n",
    "        # Assign predictions\n",
    "        missing_indexes = df_test[df_test[col].isnull()].index\n",
    "        df_test.loc[missing_indexes, col] = predictions\n",
    "\n",
    "    return df_test\n",
    "\n",
    "# Example usage\n",
    "df_train = remerged_data[1]  # Use remerged train data\n",
    "df_test = test_1.copy()  # Copy test set\n",
    "\n",
    "# Apply automatic imputation\n",
    "df_test_filled = auto_impute_missing_values(df_train, df_test)\n",
    "\n",
    "# Check results\n",
    "print(df_test_filled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
