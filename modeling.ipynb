{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"header.png\" width=\"100%\">\n",
    "</p>\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <strong style=\"display: block; margin-bottom: 10px;\">Group P</strong> \n",
    "    <table style=\"margin: 0 auto; border-collapse: collapse; border: 1px solid black;\">\n",
    "        <tr>\n",
    "            <th style=\"border: 1px solid white; padding: 8px;\">Name</th>\n",
    "            <th style=\"border: 1px solid white; padding: 8px;\">Student ID</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">Beatriz Monteiro</td>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">20240591</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">Catarina Nunes</td>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">20230083</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">Margarida Raposo</td>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">20241020</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">Teresa Menezes</td>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">20240333</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔗 Table of Contents <a id='table-of-contents'></a>\n",
    "1. [Introduction](#introduction): Previous Notebook\n",
    "2. [Business Understanding](#business-understanding): Previous Notebook  \n",
    "3. [Data Understanding](#data-understanding): Previous Notebook\n",
    "4. [Data Preparation](#data-preparation): Previous Notebook + In this one we have the preparation pipeline  \n",
    "5. [Modeling](#modeling): \n",
    "6. [Evaluation](#evaluation)\n",
    "7. [Conclusion](#conclusion) \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"background-color:#000027; padding:5px; border-radius:5px;\"> 📌 Introduction <a id='introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project follows the **CRISP-DM** methodology to conduct a monthly sales forecast of the smart infrastructure business unit of Siemens. \n",
    "\n",
    "<p style=\"margin-bottom: 50px;\"> \n",
    "\n",
    "**Montlhy Sales Forecast**\n",
    "\n",
    "In an era where data-driven decision-making is transforming industries, artificial intelligence (AI) and machine learning (ML) have emerged as powerful tools for forecasting and strategic planning. This project presents a comprehensive approach to sales forecasting developed in response to a real-world challenge provided by Siemens Advanta Consulting—a digital transformation leader within the Siemens group.\n",
    "\n",
    "The objective of the challenge is to forecast the monthly sales performance of selected product groups from one of Siemens’ business units in Germany. The historical dataset consists of daily sales figures, enriched with relevant macroeconomic indicators, spanning from October 2018 to April 2022. The forecasting models are evaluated against actual sales data from May 2022 to February 2023, using root mean square error (RMSE) as the primary performance metric.\n",
    "\n",
    "By leveraging AI-based techniques, this project aims to demonstrate how machine learning models can enhance forecasting accuracy, minimize the need for manual intervention, and reduce the potential for human bias. The outcome not only serves as a valuable benchmark for predictive performance but also highlights the practical application of AI in solving real business challenges. \n",
    "</p>\n",
    "\n",
    "**Market Data** \n",
    "\n",
    "| Features                                      | Feature Description |\n",
    "|-----------------------------------------------|---------------------|\n",
    "| *date*                                       |  |\n",
    "| *China_Production*                            |  |\n",
    "| *China_Shipment*                              |  |\n",
    "| *France_Production*                           |  |\n",
    "| *France_Shipment*                             |  |\n",
    "| *Germany_Production*                          |  |\n",
    "| *Germany_Shipment*                            |  |\n",
    "| *Italy_Production*                            |  |\n",
    "| *Italy_Shipment*                              |  |\n",
    "| *Japan_Production*                            |  |\n",
    "| *Japan_Shipment*                              |  |\n",
    "| *Switzerland_Production*                      |  |\n",
    "| *Switzerland_Shipment*                        |  |\n",
    "| *UK_Production*                               |  |\n",
    "| *UK_Shipment*                                 |  |\n",
    "| *US_Production*                               |  |\n",
    "| *US_Shipment*                                 |  |\n",
    "| *Europe_Production*                           |  |\n",
    "| *Europe_Shipment*                             |  |\n",
    "| *Base_Metal_Price*                            |  |\n",
    "| *Energy_Price*                                |  |\n",
    "| *Metal_and_Minerals_Price*                    |  |\n",
    "| *Natural_Gas_Price*                           |  |\n",
    "| *Crude_oil_avg_Price*                         |  |\n",
    "| *Copper_price*                                |  |\n",
    "| *LCU_EUR*                                     |  |\n",
    "| *US_Producer_Price_Electrical_equip*          |  |\n",
    "| *UK_Producer_Price_Electrical_equip*          |  |\n",
    "| *Italy_Producer_Price_Electrical_equip*       |  |\n",
    "| *France_Producer_Price_Electrical_equip*      |  |\n",
    "| *Germany_Producer_Price_Electrical_equip*     |  |\n",
    "| *China_Producer_Price_Electrical_equip*       |  |\n",
    "| *US_Production_Index_Machinery_and_equipment* |  |\n",
    "| *World_Production_Index_Machinery_and_equip*  |  |\n",
    "| *Switzerland_Production_Index_Machinery_and_equip* |  |\n",
    "| *UK_Production_Index_Machinery_and_equip*     |  |\n",
    "| *Italy_Production_Index_Machinery_and_equip*  |  |\n",
    "| *Japan_Production_Index_Machinery_and_equip*  |  |\n",
    "| *France_Production_Index_Machinery_and_equip* |  |\n",
    "| *Germany_Production_Index_Machinery_and_equip* |  |\n",
    "| *US_Production_Index_Electrical_equip*        |  |\n",
    "| *World_Production_Index_Electrical_equip*     |  |\n",
    "| *Switzerland_Production_Index_Electrical_equip* |  |\n",
    "| *UK_Production_Index_Electrical_equip*        |  |\n",
    "| *Italy_Production_Index_Electrical_equip*     |  |\n",
    "| *Japan_Production_Index_Electrical_equip*     |  |\n",
    "| *France_Production_Index_Electrical_equip*    |  |\n",
    "| *Germany_Production_Index_Electrical_equip*   |  |\n",
    "\n",
    "\n",
    "**Sales Data**\n",
    "| Features                                      | Feature Description |\n",
    "|-----------------------------------------------|---------------------|\n",
    "| *DATE*                                       |   |\n",
    "| *Mapped_GCK*                                 |   |\n",
    "| *Sales_EUR*                                  |   |\n",
    "\n",
    "<b style=\"background-color:#A9A9A9; padding:5px; border-radius:5px; display: inline-block; margin-top: 50px;\">CRISP-DM</b>\n",
    "\n",
    "<ul style=\"margin-bottom: 30px;\">\n",
    "    <li><u>Business Understanding</u>: Defining objectives, assessing resources, and project planning.</li>\n",
    "    <li><u>Data Understanding</u>: Collecting, exploring, and verifying data quality.</li>\n",
    "    <li><u>Data Preparation</u>: Selecting, cleaning, constructing, integrating, and formatting data to ensure it is ready for analysis.</li>\n",
    "    <li><u>Modeling</u>: Selecting and applying various modeling techniques while calibrating their parameters to optimal values.</li>\n",
    "    <li><u>Evaluation</u>: Select the models which are the best performers and evaluate thoroughly if they align with the business objectives. </li>\n",
    "    <li><u>Deployment</u>: Bridge between data mining goals and the business application of the finalized model.</li>\n",
    "</ul>\n",
    "\n",
    "<hr style=\"margin-top: 30px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install prophet == 1.1.6\n",
    "# pip install keras == 3.9.0 tensorflow == 2.19.0\n",
    "# pip install neuralprophet == 0.8.0\n",
    "# pytorch-forecasting-1.3.0\n",
    "#pip install nixtla == 0.6.6\n",
    "#pip install pmdarima == 2.0.4\n",
    "#pip install scikeras == 0.13.0\n",
    "#pip install keras-tcn == 3.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:NP.plotly:Importing plotly failed. Interactive plots will not work.\n",
      "ERROR:NP.plotly:Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV, TimeSeriesSplit\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#timesgpt\n",
    "from nixtla import NixtlaClient\n",
    "#xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost.callback import EarlyStopping\n",
    "#lstm\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tcn import TCN\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from prophet import Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "\n",
    "#evaluation\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, \n",
    "    r2_score, \n",
    "    mean_absolute_percentage_error,\n",
    "    mean_absolute_error,\n",
    "    root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#Check if Y is stationary\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Modeling Pipeline (Feature selection, Scaling, Model testing)\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from pytorch_forecasting.data.timeseries import TimeSeriesDataSet\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', 1000)       # Set display width\n",
    "pd.set_option('display.max_colwidth', 100) # Show full feature lists\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)  # 4 decimal places\n",
    "\n",
    "# If you want to force standard notation (no scientific):\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x if abs(x) > 1e-4 else '%.4e' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"background-color:#000027; padding:5px; border-radius:5px;\"> 📌 Business Understanding <a id='business-understanding'></a>\n",
    "\n",
    "##### Click [here](#table-of-contents) ⬆️ to return to the Index.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Business Understanding** phase of the project entails the comprehension of the background leading to the project, as well as the business goals and requirements to be achieved. \n",
    "<br><br><br>\n",
    "Siemens is a global technology company that provides multi-industry solutions, with a strong focus on automation, digitalization, and sustainability. \n",
    "\n",
    "**Smart Infrastructure** division at Siemens\n",
    "\n",
    "(https://www.siemens.com/global/en/company/about/businesses/smart-infrastructure.html\n",
    "https://www.siemens.com/global/en/company/about/history/company/2007-2018.html)\n",
    "\n",
    "In October 2018, Siemens launched its Smart Infrastructure division, as part of the implementation of an optimized corporate structure. This new division emerged from the merger of former divisions, specifically the power distribution segment of the Energy Management division, the Building Technologies’ business, and the control products business of the Digital Factory division.\n",
    "Smart Infrastructure helps customers through their digital transformation journey by leveraging cutting-edge technology that enables clients to adapt to evolving environments and to seize new opportunities. It mostly provides B2B services, focusing on energy efficiency and resource optimization, which in turn improves clients’ asset performance, availability, reliability, and operational efficiency. All in all, this division future-proofs infrastructures, fostering collaborative ecosystems.\n",
    "\n",
    "<br><br>\n",
    "**Economic Environment 2018**\n",
    "\n",
    "(Siemens. (2018). Annual report 2018. Siemens AG. https://www.siemens.com/global/en/company/investor-relations/events-publications-ad-hoc/annualreports.html)\n",
    "\n",
    "`Overall economic conditions`\n",
    "In 2018, advanced countries saw GDP growth of 2.3%, mainly due to the U.S. economy benefiting from tax cuts. In contrast, emerging countries' GDP growth fell slightly from 4.7% to 4.6%, affected by capital outflows and currency depreciation, notably in Argentina and Turkey. This decline was worsened by U.S. monetary tightening and fears of a global trade war from new tariffs. Political tensions increased in the Middle East, particularly with U.S. sanctions on Iran. In Europe, uncertainties around the U.K.'s exit from the EU and worries about Italy’s budget led to negative investment sentiment. All in all, the economic acceleration at the beginning of 2018 lost steam towards the end of the year due to these adverse effects.\n",
    "\n",
    "`Energy Management`\n",
    "The Energy Management Division offers a wide spectrum of software, products, systems, solutions, and services for transmitting, distributing and managing electrical power and for providing intelligent power infrastructure.\n",
    "This sector faces competition from large multinational companies and fast-growing firms in emerging countries. It generally benefits from major trends, in particular decarbonization, decentralization and digitalization. Although Energy Management reported a double-digit order decline, due to a sharply lower volume of large orders in the transmission solutions business, revenue grew in most Division’s businesses, led by the power distribution businesses. For the latter, on a geographic basis, higher revenue in the region Asia, Australia was partially offset by a decline in the Americas strongly influenced by currency headwinds, while revenue in the region Europe, C. I. S., Africa, Middle East was flat year-over-year.\n",
    "Under the new organizational structure, transmission solutions will be assigned to the Operating Company Gas and Power, while the businesses for power distribution will be assigned to the Operating Company Smart Infrastructure.\n",
    "\n",
    "\n",
    "`Building Technologies`\n",
    "The Building Technologies Division is a leading provider of automation technologies and digital services for safe, secure and efficient buildings and infrastructures. The Division offers products, solutions, services and software for fire safety, security, building automation and energy management.\n",
    "The Division competes with multinational companies, system integrators, local firms, and IT startups. Strong competition is causing price pressure, especially in the solutions business. Economic changes affect the Division's activities with delay, and particularly in non-residential construction markets, there is a time lag of two to four quarters. Key trends include the demand for energy efficiency and smart space solutions to improve comfort and productivity. In fiscal 2018, the Building Technologies acquired three startups to strengthen its portfolio and expertise. Revenue increased, with the Division’s revenue growing faster than the market on increases in all reporting regions, with strongest market growth contributions came from the Asia, Australia region, particularly including India. Orders grew in the region Europe, C. I. S., Africa, Middle East, driven by double-digit growth in Germany including multiple multi-year service contracts. The Division won major orders in the U. S. in both periods under review. Profit and profitability remained strong, supported by economies of scale and improved productivity. The markets are expected to grow solidly in fiscal 2019, although U.S. growth may slow slightly.\n",
    "\n",
    "\n",
    "`Digital Factory`\n",
    "The Digital Factory Division provides a wide range of automation products and solutions for manufacturing, including software, control systems, motors, and integrated systems. It also offers lifecycle services and software for design and testing. Changes in customer demand are strongly driven by macroeconomic cycles, leading to variations in profitability. Competition is mainly from large multinational firms offering a relatively broad portfolio, and companies that are only active in certain geographic or product markets. Key trends include rising interest rates, which will limit investment but at the same time make it more focused on improving efficiency, a shift towards regionalization solutions, either to protect local economies or to better adapt solutions to local needs, and an increased focus on digitalization for competitiveness. The Division reported year-over-year growth in orders and revenue, especially in software. Growth was strongest in the Americas and Asia, notably China, and customer investments grew faster than their production, underlining a clear growth momentum relating to automation and digitalization. While the market is expected to continue growing, slower demand is anticipated for 2019 due to the high investment levels of 2018 and rising global trade tensions.\n",
    "\n",
    "<br><br>\n",
    "**Economic Environment 2019**\n",
    "\n",
    "(Siemens. (2019). Annual report 2019. Siemens AG. https://www.siemens.com/global/en/company/investor-relations/events-publications-ad-hoc/annualreports.html)\n",
    "\n",
    "`Overall economic conditions`\n",
    "After GDP growth of 3.2% in 2018, it is expected to drop to 2.6% in 2019, as to the U.S.-China trade dispute and geopolitical tensions in the Middle East contributed to uncertainty, which weighed on capital investments. Global exchange of goods started to decline from October 2018, leading to near-stagnation of industrial production afterwards. The decline affected regions reliant on trade and industry, particularly Germany and Italy in Europe, Mexico and Canada in the Americas, and India in Asia. In addition, European economies suffered from continued uncertainties regarding the U. K. leaving the European Union (Brexit) and the budget clash between the European Commission and Italy’s government, both weighing especially on business investment environment. Countries dependent on commodities and raw material exporting, notably Chile, Brazil and Argentina, saw declines in commodity prices in addition to other adverse factors including domestic political and financial instability. Advanced countries are expected to grow by 1.6%, 0.7 percentage points lower than 2018, while emerging countries will see a decline from 4.6% to 4.1%.\n",
    "\n",
    "`Smart Infrastructure`\n",
    "Smart Infrastructure brings together energy supply – from intelligent control across the grid and low- and medium-voltage electrification and control products – with building technology, targeting high-growth areas like energy storage, electric vehicle infrastructure, and microgrids at the grid edge. It reaches customers through multiple channels, including global sales, distributors, OEMs, resellers, installers, and direct sales via regional branch offices. Its diverse customer base encompasses infrastructure developers, construction firms, public and commercial buildings, utilities, and heavy industries. Smart Infrastructure faces competition from large multinationals, smaller manufacturers, local integrators, and facility management firms. Economic changes impact customer demand differently, with discrete manufacturing reacting quickly and strongly with macroeconomic cycles, while other sectors - infrastructure, construction, heavy industries and the utilities – have a slower response to economic cycles. Key trends include rising population and urbanization, the need for safe and sustainable environments, and decarbonization, growing decentralization and prosumers’ influence. Orders and revenue increased across all business areas and regions in fiscal 2019.  \n",
    "\n",
    "<br><br>\n",
    "**Economic Environment 2020**\n",
    "\n",
    "(Siemens. (2020). Annual report 2020. Siemens AG. https://www.siemens.com/global/en/company/investor-relations/events-publications-ad-hoc/annualreports.html)\n",
    "\n",
    "`Overall economic conditions`\n",
    "The fiscal year 2020 was heavily affected by the coronavirus pandemic and subsequent recession, the deepest since World War II. Global GDP is expected to fall by 4.5% in 2020, following a growth of 2.6% in 2019. Economic activity was already decelerating due to the U.S.-China trade conflict, but economic sentiment indicators were starting to improve in response to calming of the conflict ( “phase one deal”). Then COVID-19 emerged and started to spread globally, resulting in strict social distancing measures that limited operations, especially in contact-heavy sectors. Many other industries were directly affected by supply chain problems or indirectly by insufficient demand and stopped production.\n",
    "\n",
    "Governments and central banks responded with strong fiscal and monetary policies to support businesses and households, leading to a brief economic rebound in the summer. However, renewed virus outbreaks hindered full recovery and restrictions in high contact industries made the economy operate only at about 90% of its full potential, with advanced economies projected to see a 5.5% decline in GDP. Siemens experienced mixed impacts across its sectors, benefiting from growth in technology-related areas, while facing challenges in customer access and sales. While the pandemic significantly slowed our sales and service activities, this also resulted in cost reductions such as lower travel and marketing expenses. Furthermore, we were able to keep our production largely stable due to the use of our own technology in our factories and our diversified value chain.\n",
    "\n",
    "\n",
    "`Smart Infrastructure`\n",
    "Smart Infrastructure’s businesses are impacted by changes in the overall economic environment to varying degrees, depending on customer segment. Particularly in its solutions and service business, it is affected by changes in the non-residential building construction markets with a time lag of two to four quarters.\n",
    "Smart Infrastructure is experiencing a decline in orders, particularly in the solutions and services business, which previously saw a higher volume of orders. The products business showed only a slight decrease, while orders in the systems and software business stayed stable. Overall, revenue for the solutions and services business and for the systems and software business remained close to the prior- year levels. The drop in orders and revenue primarily came from Europe, Africa, the Middle East, and parts of Asia and Australia, but the Americas remained stable.\n",
    "Demand in Smart Infrastructure markets declined moderately due to COVID-19, especially in the automotive, oil and gas, and machine-building sectors. However, energy performance services and the data center market grew due to the increased focus on energy efficiency, digital services and remote work. \n",
    "Market development will be affected by lower demand from building construction, leading to a slight decline in volume of markets served by Smart Infrastructure year-over-year. Asia and Australia are expected return to normal growth, while Europe and the U.S. may see declines.\n",
    "\n",
    "<br><br>\n",
    "**Economic Environment 2021**\n",
    "\n",
    "(Siemens. (2021). Annual report 2021. Siemens AG. https://www.siemens.com/global/en/company/investor-relations/events-publications-ad-hoc/annualreports.html)\n",
    "\n",
    "`Overall economic conditions`\n",
    "In fiscal 2021, the global economy was heavily influenced by the COVID-19 pandemic and its many repercussions. After a GDP contraction in 2020, a strong recovery is expected in 2021. The economy grew rapidly in the third quarter of 2020 after the first wave of COVID-19. Despite fears of a new recession due to subsequent COVID-19 waves, economic activity had already adapted, supported by significant stimulus measures in Europe and the U.S.\n",
    "Central banks gave support with expansionary measures, while short-term interest rates were at or near zero. Accordingly, the global economy continued to expand also in the fourth quarter of calendar 2020 and the first quarter of calendar 2021, despite renewed outbreaks and lockdowns. In December 2020, the first countries approved new COVID-19 vaccines.\n",
    "However, momentum weakened in early 2021 due to rising infections and the more contagious Delta variant. Vaccination efforts lagged, especially in emerging countries, while supply disruptions affected many sectors, leading to logistics bottlenecks that disrupted value chains from raw materials to high-tech goods, especially semiconductors, and caused extraordinary disruptions in global logistics systems. High demand for goods, driven by consumer savings, contributed to increased producer and energy prices,  resulting in elevated rates of inflation. \n",
    "The Chinese economy – with the world’s largest manufacturing sector –  particularly benefited from global demand. However, tensions in the property sector and energy shortages weighed on economic activity in the second half of calendar 2021. \n",
    "Overall, major economies experienced strong rebounds, and GDP is expected to grow strongly.\n",
    "\n",
    "`Smart Infrastructure`\n",
    "Smart Infrastructure is benefitting from several positive trends, including urbanization, demographic changes, climate change, and digitalization. Urbanization and demographic shifts create a demand for smarter buildings, while climate change pushes for decarbonization and the development of flexible energy infrastructures. Digitalization enables the improvement of building efficiency and electricity management with more renewable energy sources.\n",
    "Orders for Smart Infrastructure improved across all sectors, with notable growth in the products and systems businesses, driven by demand from industrial customers and contracts from U.S. semiconductor manufacturers. Revenue also grew, although the solutions and services business saw a slight decline due to negative currency translation effects. Meanwhile, supply chain challenges were managed effectively, preventing major disruptions.\n",
    "Overall, markets served by Smart Infrastructure grew moderately in fiscal 2021, experiencing a recovery from COVID-19-related effects that had a strong impact on most customer industries a year earlier.\n",
    "Smart Infrastructure also experienced a number of supply chain constraints, especially in the areas of base metals (copper, aluminum, steel), plastics, semiconductors and transportation services. Whereas the management of these constraints required additional effort, Smart Infrastructure’s supply chains have proven to be resilient, so that major interruptions could be avoided, and delivery ability was maintained.\n",
    "Market growth is expected to accelerate, primarily fueled by demand in the pharmaceutical sector, data centers, and utilities. Growth will be strongest in Asia and Australia. Growth in the region Europe, C.I.S., Africa, and the Middle East is expected to accelerate and markets in the region Americas are expected to return to growth.\n",
    "\n",
    "<br><br>\n",
    "**Economic Environment 2022**\n",
    "\n",
    "(Siemens. (2022). Annual report 2022. Siemens AG. https://www.siemens.com/global/en/company/investor-relations/events-publications-ad-hoc/annualreports.html)\n",
    "\n",
    "`Overall economic conditions`\n",
    "In fiscal 2022, global economic growth faced major disruptions from the war in Ukraine, the effects of COVID-19, and the economic slowdown in China. After a strong recovery in 2021, GDP growth is expected to decline as the economic rebound ended abruptly. In late 2021, increased vaccinations and reduced restrictions boosted consumer spending, triggering inflationary pressures, especially in the U.S. and Europe. Supply chain issues, labor shortages, and heightened energy prices contributed to this inflation, while large stimulus packages and high household savings fueled it. \n",
    "The war in Ukraine further strained economies in early 2022, causing another significant rise in energy prices, which heavily impacted Europe and industrial sectors, especially energy-intensive industries such as chemicals. The war in Ukraine put further pressure on developing economies, especially in the Middle East, Africa, and Turkey, as both Russia and Ukraine were major exporters of grain and fertilizer before the war.\n",
    "China’s zero-COVID strategy became even more strict with the emergence of the Delta variant and the highly infectious Omicron variant, which hindered economic activity, along with regulations affecting growing sectors and a recession in real estate. Consequently, China's growth was predicted to slow. \n",
    "In response to rising inflation, the U.S. Federal Reserve raised interest rates and tightened monetary policy, followed by other central banks. This led to economic disruptions, resulting in slower-than-expected GDP growth for 2022.\n",
    "\n",
    "`Smart Infrastructure`\n",
    "In fiscal 2022, Smart Infrastructure acquired Brightly Software Inc., improving its position in software for asset and maintenance management. Smart Infrastructure’s businesses are impacted by changes in the overall economic environment to varying degrees. Especially, demand for service offerings shows only limited influence from macroeconomic cycles.\n",
    "Orders and revenue grew significantly across all businesses, especially in electrical products and electrification, driven by industrial customers, data centers, and proactive purchasing. Smart Infrastructure faced supply chain challenges but avoided major disruptions. The Americas region saw the strongest growth, while Asia and Australia were hindered by COVID-19 impacts, particularly in China. Both order and revenue development included positive currency translation effects. \n",
    "Overall, markets served by Smart Infrastructure grew clearly in fiscal 2022. Market growth is anticipated to be slightly slower due to ongoing inflation and supply chain issues, with solid demand expected in data centers and power distribution despite challenges like price increases and geopolitical tensions.\n",
    "Market development is expected to continue to be influenced by supply chain constraints and effects from the war in Ukraine, including on energy prices. Further impacts could arise from potential lockdown measures in China and geopolitical tensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"background-color:#000027; padding:5px; border-radius:5px;\"> 📌 Modeling <a id='modeling'></a>\n",
    "\n",
    "[1. Data Loading](#data-loading-and-description)\n",
    "\n",
    "[2. Usefull Functions](#functions)\n",
    "\n",
    "[3. Model Selection per Product](#model-selection)\n",
    "- [3.1. TimeGPT](#timegpt)\n",
    "- [3.2. XGBoost](#xgboost)\n",
    "- [3.3. TCN](#tcn) \n",
    "- [3.4. Neural Prophet](#neural-prophet) \n",
    "- [3.4. ARIMA](#arima) \n",
    "\n",
    "[4. Exogenous Variables Prediction](#market)\n",
    "\n",
    "[5. Final Modeling](#market)\n",
    "\n",
    "\n",
    "Click [here](#table-of-contents) ⬆️ to return to the Index.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"background-color:#000027; padding:5px; border-radius:5px;\">**1. Data Loading**</span> <a id='data-loading-and-description'></a>  \n",
    "\n",
    "Click [here](#table-of-contents) ⬆️ to return to the Index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded P1 from product_dfs_folder\\P1.pkl\n",
      "Loaded P11 from product_dfs_folder\\P11.pkl\n",
      "Loaded P12 from product_dfs_folder\\P12.pkl\n",
      "Loaded P13 from product_dfs_folder\\P13.pkl\n",
      "Loaded P14 from product_dfs_folder\\P14.pkl\n",
      "Loaded P16 from product_dfs_folder\\P16.pkl\n",
      "Loaded P20 from product_dfs_folder\\P20.pkl\n",
      "Loaded P3 from product_dfs_folder\\P3.pkl\n",
      "Loaded P36 from product_dfs_folder\\P36.pkl\n",
      "Loaded P4 from product_dfs_folder\\P4.pkl\n",
      "Loaded P5 from product_dfs_folder\\P5.pkl\n",
      "Loaded P6 from product_dfs_folder\\P6.pkl\n",
      "Loaded P8 from product_dfs_folder\\P8.pkl\n",
      "Loaded P9 from product_dfs_folder\\P9.pkl\n",
      "Loaded Sales_CPI from product_dfs_folder\\Sales_CPI.pkl\n",
      "Loaded P1 from lagged_product_dfs_folder\\P1.pkl\n",
      "Loaded P11 from lagged_product_dfs_folder\\P11.pkl\n",
      "Loaded P12 from lagged_product_dfs_folder\\P12.pkl\n",
      "Loaded P13 from lagged_product_dfs_folder\\P13.pkl\n",
      "Loaded P16 from lagged_product_dfs_folder\\P16.pkl\n",
      "Loaded P20 from lagged_product_dfs_folder\\P20.pkl\n",
      "Loaded P3 from lagged_product_dfs_folder\\P3.pkl\n",
      "Loaded P36 from lagged_product_dfs_folder\\P36.pkl\n",
      "Loaded P4 from lagged_product_dfs_folder\\P4.pkl\n",
      "Loaded P5 from lagged_product_dfs_folder\\P5.pkl\n",
      "Loaded P8 from lagged_product_dfs_folder\\P8.pkl\n",
      "Loaded P9 from lagged_product_dfs_folder\\P9.pkl\n"
     ]
    }
   ],
   "source": [
    "def load_dfs_from_folder(folder_path):\n",
    "    \"\"\"Loads DataFrames from files in a specified folder and returns a dictionary.\"\"\"\n",
    "    dfs = {}\n",
    "    # List all files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".pkl\"):\n",
    "            key = file_name.replace(\".pkl\", \"\")  # Extract key from the file name\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            \n",
    "            # Load the dataframe from the pickle file\n",
    "            with open(file_path, 'rb') as f:\n",
    "                dfs[key] = pickle.load(f)\n",
    "            print(f\"Loaded {key} from {file_path}\")\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "# Load both product_dfs and lagged_product_dfs from their respective folders\n",
    "product_dfs = load_dfs_from_folder(\"product_dfs_folder\")\n",
    "lagged_product_dfs = load_dfs_from_folder(\"lagged_product_dfs_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product_id in product_dfs.keys():\n",
    "    product_dfs[product_id] = product_dfs[product_id].rename(columns={product_id: \"Sales\"})\n",
    "\n",
    "for product_id in lagged_product_dfs.keys():\n",
    "    lagged_product_dfs[product_id] = lagged_product_dfs[product_id].rename(columns={product_id: \"Sales\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>MAB_ELE_SHP840</th>\n",
       "      <th>PRI27276_org</th>\n",
       "      <th>PRO27826_org</th>\n",
       "      <th>MAB_ELE_PRO276</th>\n",
       "      <th>MAB_ELE_SHP1100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>35774028.5209</td>\n",
       "      <td>127.8088</td>\n",
       "      <td>109.1196</td>\n",
       "      <td>118.6708</td>\n",
       "      <td>124.2279</td>\n",
       "      <td>130.9893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-01</th>\n",
       "      <td>5063648.6000</td>\n",
       "      <td>117.6759</td>\n",
       "      <td>109.2248</td>\n",
       "      <td>120.4670</td>\n",
       "      <td>127.4041</td>\n",
       "      <td>132.9341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01</th>\n",
       "      <td>37321267.9382</td>\n",
       "      <td>123.2801</td>\n",
       "      <td>109.3301</td>\n",
       "      <td>105.3787</td>\n",
       "      <td>120.5186</td>\n",
       "      <td>131.2613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>27090400.9380</td>\n",
       "      <td>111.0438</td>\n",
       "      <td>109.7510</td>\n",
       "      <td>107.1749</td>\n",
       "      <td>104.7763</td>\n",
       "      <td>113.0576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01</th>\n",
       "      <td>34132093.4229</td>\n",
       "      <td>116.7369</td>\n",
       "      <td>109.8562</td>\n",
       "      <td>110.6476</td>\n",
       "      <td>109.5970</td>\n",
       "      <td>117.7047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Sales  MAB_ELE_SHP840  PRI27276_org  PRO27826_org  MAB_ELE_PRO276  MAB_ELE_SHP1100\n",
       "month_year                                                                                           \n",
       "2018-10-01 35774028.5209        127.8088      109.1196      118.6708        124.2279         130.9893\n",
       "2018-11-01  5063648.6000        117.6759      109.2248      120.4670        127.4041         132.9341\n",
       "2018-12-01 37321267.9382        123.2801      109.3301      105.3787        120.5186         131.2613\n",
       "2019-01-01 27090400.9380        111.0438      109.7510      107.1749        104.7763         113.0576\n",
       "2019-02-01 34132093.4229        116.7369      109.8562      110.6476        109.5970         117.7047"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_dfs['P1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>PRI27840_org</th>\n",
       "      <th>RohCOPPER1000_org</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>P8_lag_1</th>\n",
       "      <th>P8_lag_2</th>\n",
       "      <th>P8_lag_5</th>\n",
       "      <th>P8_lag_6</th>\n",
       "      <th>P8_lag_10</th>\n",
       "      <th>P8_ma_1</th>\n",
       "      <th>P8_ma_2</th>\n",
       "      <th>P8_ma_5</th>\n",
       "      <th>P8_ma_6</th>\n",
       "      <th>P8_ma_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>398332.2744</td>\n",
       "      <td>110.6561</td>\n",
       "      <td>75.7745</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>368081.2008</td>\n",
       "      <td>420287.0223</td>\n",
       "      <td>582419.0346</td>\n",
       "      <td>361474.5342</td>\n",
       "      <td>580778.2653</td>\n",
       "      <td>398332.2744</td>\n",
       "      <td>383206.7376</td>\n",
       "      <td>380139.7221</td>\n",
       "      <td>413852.9409</td>\n",
       "      <td>400303.6854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-01</th>\n",
       "      <td>1086855.2918</td>\n",
       "      <td>111.0503</td>\n",
       "      <td>76.4355</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>398332.2744</td>\n",
       "      <td>368081.2008</td>\n",
       "      <td>416386.5006</td>\n",
       "      <td>582419.0346</td>\n",
       "      <td>518398.3785</td>\n",
       "      <td>1086855.2918</td>\n",
       "      <td>742593.7831</td>\n",
       "      <td>514233.4804</td>\n",
       "      <td>497925.6504</td>\n",
       "      <td>457149.3767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01</th>\n",
       "      <td>112014.9227</td>\n",
       "      <td>111.0322</td>\n",
       "      <td>76.4097</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>1086855.2918</td>\n",
       "      <td>398332.2744</td>\n",
       "      <td>297611.6126</td>\n",
       "      <td>416386.5006</td>\n",
       "      <td>267418.3494</td>\n",
       "      <td>112014.9227</td>\n",
       "      <td>599435.1073</td>\n",
       "      <td>477114.1424</td>\n",
       "      <td>447197.0541</td>\n",
       "      <td>441609.0341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01</th>\n",
       "      <td>540208.8029</td>\n",
       "      <td>111.0354</td>\n",
       "      <td>77.7720</td>\n",
       "      <td>13</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>112014.9227</td>\n",
       "      <td>1086855.2918</td>\n",
       "      <td>420287.0223</td>\n",
       "      <td>297611.6126</td>\n",
       "      <td>372627.9465</td>\n",
       "      <td>540208.8029</td>\n",
       "      <td>326111.8628</td>\n",
       "      <td>501098.4985</td>\n",
       "      <td>487629.9191</td>\n",
       "      <td>458367.1197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>491332.7200</td>\n",
       "      <td>111.2866</td>\n",
       "      <td>80.6535</td>\n",
       "      <td>14</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>540208.8029</td>\n",
       "      <td>112014.9227</td>\n",
       "      <td>368081.2008</td>\n",
       "      <td>420287.0223</td>\n",
       "      <td>361474.5342</td>\n",
       "      <td>491332.7200</td>\n",
       "      <td>515770.7614</td>\n",
       "      <td>525748.8024</td>\n",
       "      <td>499470.8688</td>\n",
       "      <td>471352.9383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Sales  PRI27840_org  RohCOPPER1000_org  time_idx  year  month     P8_lag_1     P8_lag_2    P8_lag_5    P8_lag_6   P8_lag_10      P8_ma_1     P8_ma_2     P8_ma_5     P8_ma_6    P8_ma_10\n",
       "month_year                                                                                                                                                                                                \n",
       "2019-08-01  398332.2744      110.6561            75.7745        10  2019      8  368081.2008  420287.0223 582419.0346 361474.5342 580778.2653  398332.2744 383206.7376 380139.7221 413852.9409 400303.6854\n",
       "2019-09-01 1086855.2918      111.0503            76.4355        11  2019      9  398332.2744  368081.2008 416386.5006 582419.0346 518398.3785 1086855.2918 742593.7831 514233.4804 497925.6504 457149.3767\n",
       "2019-10-01  112014.9227      111.0322            76.4097        12  2019     10 1086855.2918  398332.2744 297611.6126 416386.5006 267418.3494  112014.9227 599435.1073 477114.1424 447197.0541 441609.0341\n",
       "2019-11-01  540208.8029      111.0354            77.7720        13  2019     11  112014.9227 1086855.2918 420287.0223 297611.6126 372627.9465  540208.8029 326111.8628 501098.4985 487629.9191 458367.1197\n",
       "2019-12-01  491332.7200      111.2866            80.6535        14  2019     12  540208.8029  112014.9227 368081.2008 420287.0223 361474.5342  491332.7200 515770.7614 525748.8024 499470.8688 471352.9383"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lagged_product_dfs['P8'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"background-color:#000027; padding:5px; border-radius:5px;\">**2. Usefull Functions**</span> <a id='functions'></a>  \n",
    "\n",
    "Click [here](#table-of-contents) ⬆️ to return to the Index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipeline(train, val=None, test=None, outlier_treatment=True):\n",
    "\n",
    "    def winsorize_function(df, cols, lower_quantile=0.01, upper_quantile=0.99):\n",
    "        \"\"\"Apply Winsorization only to the product sales column\"\"\"\n",
    "        df = df.copy()\n",
    "        bounds = {}\n",
    "        for col in cols:\n",
    "            q1 = df[col].quantile(lower_quantile)\n",
    "            q3 = df[col].quantile(upper_quantile)\n",
    "            df[col] = df[col].clip(lower=q1, upper=q3)\n",
    "            bounds[col] = (q1, q3)  # Store actual percentile values\n",
    "            print(f\"{col}: Winsorized Bounds -> Lower = {q1:.2f}, Upper = {q3:.2f}\")\n",
    "\n",
    "        return df, bounds\n",
    "        \n",
    "    def process_dataset(df, cols, is_train=True, bounds=None):\n",
    "        df = df.copy() \n",
    "        if is_train:\n",
    "            if outlier_treatment:\n",
    "                df, bounds = winsorize_function(df, cols)\n",
    "            else:\n",
    "                bounds = {}  \n",
    "        else:\n",
    "            if outlier_treatment:\n",
    "                if bounds is None:\n",
    "                    raise ValueError(\"Bounds must be provided for validation and test datasets.\")\n",
    "                for col in cols: \n",
    "                    if col in bounds:\n",
    "                        lower, upper = bounds[col]\n",
    "                        df[col] = df[col].clip(lower, upper)  # Corrected clipping\n",
    "        return (df, bounds) if is_train else df\n",
    "\n",
    "    # Process the training dataset\n",
    "    train, bounds = process_dataset(train, cols = train.columns, is_train=True)\n",
    "\n",
    "    # Process validation and test datasets with correct bounds\n",
    "    if val is not None:\n",
    "        val = process_dataset(val, cols = val.columns, is_train=False, bounds=bounds)\n",
    "\n",
    "    if test is not None:\n",
    "        test = process_dataset(test, cols = test.columns, is_train=False, bounds=bounds)\n",
    "        \n",
    "    # Return the datasets \n",
    "    if test is not None and val is not None:\n",
    "        return train, val, test\n",
    "    elif val is not None:\n",
    "        return train, val\n",
    "    elif test is not None:\n",
    "        return train, test\n",
    "    else:\n",
    "        return train\n",
    "\n",
    "def time_series_train_test_split(X, y, test_size=10):\n",
    "    \"\"\"Split time series data maintaining temporal order\"\"\"\n",
    "    split_idx = len(X) - test_size\n",
    "    return (\n",
    "        X.iloc[:split_idx], X.iloc[split_idx:],\n",
    "        y.iloc[:split_idx], y.iloc[split_idx:])\n",
    "\n",
    "def prepare_time_series_data(df_train, feature_set, target_col=\"Sales\", horizon=10, winsorize=False, scaling=False):\n",
    "\n",
    "    # Extract product data\n",
    "    data = df_train.copy()\n",
    "    \n",
    "    y = data[[target_col]]  \n",
    "    X = data.drop(columns=[target_col])\n",
    "    \n",
    "    # Select features - handle empty feature_set case\n",
    "    if feature_set:\n",
    "        try:\n",
    "            # Convert feature_set to list if it's not already\n",
    "            if not isinstance(feature_set, list):\n",
    "                feature_set = [feature_set]\n",
    "            # Select only columns that exist in X\n",
    "            available_features = [f for f in feature_set if f in X.columns]\n",
    "            X = X[available_features]\n",
    "        except KeyError as e:\n",
    "            raise ValueError(f\"Some features not found in DataFrame: {e}\")\n",
    "    \n",
    "    # Train/Test Split\n",
    "    X_train, X_val, y_train, y_val = time_series_train_test_split(X, y, test_size=horizon)\n",
    "\n",
    "    # Apply preprocessing steps\n",
    "    y_train, y_val = preprocessing_pipeline(y_train, y_val, test=None, outlier_treatment=winsorize)\n",
    "\n",
    "    # Scaling\n",
    "    if scaling: \n",
    "        scaler_X = StandardScaler()\n",
    "        X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "        X_val_scaled = scaler_X.transform(X_val)\n",
    "        \n",
    "        scaler_y = StandardScaler()\n",
    "        y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "        y_val_scaled = scaler_y.transform(y_val)\n",
    "        \n",
    "        # Convert back to DataFrame for easier handling\n",
    "        X_train_scaled = pd.DataFrame(X_train_scaled, index=X_train.index, columns=X_train.columns)\n",
    "        X_val_scaled = pd.DataFrame(X_val_scaled, index=X_val.index, columns=X_val.columns)\n",
    "        y_train_scaled = pd.DataFrame(y_train_scaled, index=y_train.index, columns=y_train.columns)\n",
    "        y_val_scaled = pd.DataFrame(y_val_scaled, index=y_val.index, columns=y_val.columns)\n",
    "        \n",
    "        return X_train_scaled, X_val_scaled, y_train_scaled, y_val_scaled\n",
    "    else:\n",
    "        return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_combinations(features, max_features=None):\n",
    "    \"\"\"Generate all possible feature combinations\"\"\"\n",
    "    if max_features is None:\n",
    "        max_features = len(features)\n",
    "    \n",
    "    all_combinations = []\n",
    "    for r in range(1, max_features + 1):\n",
    "        all_combinations.extend(combinations(features, r))\n",
    "    \n",
    "    return [list(comb) for comb in all_combinations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_results_to_df(results):\n",
    "    if not results:\n",
    "        return pd.DataFrame()  # Retorna um DataFrame vazio se results estiver vazio\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # Itera sobre cada dicionário dentro da lista de resultados\n",
    "    for result in results:\n",
    "        product_id = result.get('product_id', None)\n",
    "        winsorize = result.get('winsorize', None)\n",
    "        \n",
    "        # Verifica se 'features' existe e se não está vazio\n",
    "        features = ', '.join(result.get('features', [])) if result.get('features') else 'all'\n",
    "        \n",
    "        metrics = result.get('metrics', {})\n",
    "\n",
    "        validation_predictions = result.get('validation_predictions', [])\n",
    "\n",
    "        # Adiciona uma linha para cada previsão de validação\n",
    "        for pred in validation_predictions:\n",
    "            data.append({\n",
    "                'product_id': product_id,\n",
    "                'winsorize': winsorize,\n",
    "                'features': features,\n",
    "                'RMSE': metrics.get('RMSE', np.nan),\n",
    "                'MAPE': metrics.get('MAPE', np.nan),\n",
    "                'Overfit_Score': metrics.get('Overfit Score', np.nan),\n",
    "                'validation_prediction': pred\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, y_train=None, y_train_pred=None, print_metrics=False):\n",
    "    metrics = {\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAPE': mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "    }\n",
    "    \n",
    "    if y_train is not None and y_train_pred is not None:\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "        metrics['Overfit Score'] = (metrics['RMSE'] - train_rmse) / max(train_rmse, 1e-10)\n",
    "    \n",
    "    if print_metrics:\n",
    "        print(\"\\n=== Metrics ===\")\n",
    "        print(f\"RMSE: {metrics['RMSE']:.3f}\")\n",
    "        print(f\"MAPE: {metrics['MAPE']:.2f}%\")\n",
    "        if 'Overfit Score' in metrics:\n",
    "            print(f\"Overfit Score: {metrics['Overfit Score']:.3f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def convert_results_to_df(results):\n",
    "    \"\"\"Convert results to DataFrame format\"\"\"\n",
    "    if results is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    return pd.DataFrame([{\n",
    "        'product_id': results['product_id'],\n",
    "        'winsorize': results['winsorize'],\n",
    "        'features': ', '.join(results['features']) if results['features'] else 'all',\n",
    "        'RMSE': results['metrics']['RMSE'],\n",
    "        'MAPE': results['metrics']['MAPE'],\n",
    "        'Overfit_Score': results['metrics'].get('Overfit Score', np.nan),\n",
    "        'method': results['method']\n",
    "    }])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"background-color:#000027; padding:5px; border-radius:5px;\">**3. Model Selection per Product**</span> <a id='model-selection'></a>  \n",
    "\n",
    "Click [here](#table-of-contents) ⬆️ to return to the Index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "➡️ Our pipeline is going to use:\n",
    "- **Walk-Forward Validation:** One-step forecasting where the model predicts the next step, and the validation window moves forward one step at a time.\n",
    "- In the cases we needed to use **GridSearch**, we use a PredefinedSplit method to ensure no cross validation and prevent messing up with the train/validation timeline.\n",
    "\n",
    "➡️ For Feature Combinations we will iterate over:\n",
    "\n",
    "- No macro/lags features (baseline model).\n",
    "- Single-feature models.\n",
    "- Multi-feature models.\n",
    "\n",
    "➡️ Models\n",
    "\n",
    "We will tune hyperparameters for all the models for each product, with the best features.\n",
    "\n",
    "\n",
    "**Time Series Model Comparison Table**\n",
    "\n",
    "| Feature               | TimeGPT (Zero-Shot) | XGBoost            | TCN                | ARIMA              | Neural Prophet     |\n",
    "|-----------------------|---------------------|--------------------|--------------------|--------------------|--------------------|\n",
    "| **Scaling Needed?**   | ❌ No               | ❌ No              | ✅ Yes             | ❌ No (if stationary) | ✅ Yes            |\n",
    "| **Handles Trends**    | ✅ Excellent        | ✅ (With features) | ✅ Excellent       | ✅ (With differencing) | ✅ Excellent     |\n",
    "| **Handles Seasonality** | ✅ Automatic       | ❌ (Requires manual lags) | ✅ (With large receptive field) | ✅ (SARIMA) | ✅ Automatic      |\n",
    "| **Multivariate Support** | ✅ Yes            | ✅ Yes             | ✅ Yes             | ❌ Univariate only | ✅ Yes             |\n",
    "| **Training Speed**    | ⚡ Instant (pre-trained) | 🏎️ Fast          | 🐢 Slow (GPU helps) | 🏃 Moderate        | 🐢 Slow           |\n",
    "| **Interpretability**  | ❌ Black box        | ✅ Feature importances | ❌ Black box     | ✅ Model coefficients | ✅ Component plots |\n",
    "| **Best For**          | Zero-shot forecasting | Tabular data with temporal features | Long-range dependencies | Simple univariate series | Hybrid (AR + NN) patterns |\n",
    "| **Weakness**          | Limited control     | Poor with long sequences | Computationally heavy | Linear assumptions only | Overfit risk       |\n",
    "\n",
    "\n",
    "1. **TimeGPT** (by Nixtla):\n",
    "   - Pros: No training needed, handles any frequency, great for quick benchmarks.\n",
    "   - Cons: Proprietary, limited customization.\n",
    "\n",
    "2. **XGBoost**:\n",
    "   - Best when you have:\n",
    "     - Easy and fast. \n",
    "\n",
    "3. **TCN** (Temporal Convolutional Networks):\n",
    "   - Pros: Captures long-range patterns better than LSTMs.\n",
    "   - Cons: Needs careful tuning of and is more computationaly expensive.\n",
    "\n",
    "4. **ARIMA**:\n",
    "   - Important:\n",
    "     - Data is stationary (or differenced) \n",
    "     - Short-term forecasts (≤12 steps)\n",
    "   - Warning: Fails miserably with:\n",
    "     - Non-linear trends\n",
    "     - High-frequency data, wich is ok, bc we are dealing with months.\n",
    "\n",
    "5. **Neural Prophet**:\n",
    "   - Hybrid of AR terms and neural nets.\n",
    "   - Best when: needed interpretable components (trend, seasonality)\n",
    "\n",
    "\n",
    "➡️ Summary:\n",
    "\n",
    "- **We will Scale**: TCN, Neural Prophet\n",
    "- **Optional Scaling**: XGBoost (for extreme values)\n",
    "- **We will not Scale**: ARIMA (but difference if non-stationary!), TimeGPT\n",
    "\n",
    "1. We will start with **TimeGPT** for a baseline.\n",
    "2. Then test **XGBoost** with lag features.\n",
    "3. Then **TCN** to see he effect for more complex patterns.\n",
    "4. **Neural Prophet** and **ARIMA** for interpretability.\n",
    "\n",
    "➡️ Evaluation Metrics: \n",
    "- RMSE → Measures error magnitude.\n",
    "- MAPE → Percentage-based error, useful for business impact.\n",
    "- R² → Measures how well the model explains variance.\n",
    "- Overfit Score →  \n",
    "\n",
    "$$\n",
    "\\text{Overfit Score} = \\frac{\\text{Test RMSE} - \\text{Train RMSE}}{\\text{Train RMSE}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "    - < 0.1 (Underfit)\n",
    "    - 0.1 - 0.5 (Good Fit)\n",
    "    - > 0.5 (Overfit Warning!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"background-color:#000027; padding:5px; border-radius:5px;\">**3.1. TimeGPT**</span> <a id='timegpt'></a>  \n",
    "\n",
    "Click [here](#table-of-contents) ⬆️ to return to the Index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nixtla.nixtla_client:Happy Forecasting! :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nixtla_client = NixtlaClient(\n",
    "    api_key = \"nixak-CIwSKQ0cRLIuFR1TYllLFVakTGx3WCY30YPEKfxG0lDQcE0akGo3GE4aMJO9XXbkKjdFaGDP5x6uSxQ6\"\n",
    ")\n",
    "nixtla_client.validate_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_parameters_timegpt(product_id, df_train, feature_set, target_col=\"Sales\", \n",
    "                              nixtla_client=None, winsorize=False, \n",
    "                              horizon=7):\n",
    "    \n",
    "    # --- Input Validation ---\n",
    "    if nixtla_client is None:\n",
    "        raise ValueError(\"NixtlaClient instance is required.\")\n",
    "    if len(df_train) < 12:\n",
    "        print(f\"⚠️ Skipping {product_id} - only {len(df_train)} observations\")\n",
    "        return None\n",
    "    \n",
    "    # --- Data Preparation ---\n",
    "    print('Preparing data...')\n",
    "    try:\n",
    "        X_train, X_val, y_train, y_val = prepare_time_series_data(df_train, feature_set, target_col, horizon, winsorize)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Data preparation failed: {str(e)}\")\n",
    "        return None\n",
    " \n",
    "    # --- Determine Feature Types ---\n",
    "    hist_exog = [f for f in feature_set if '_lag_' in f or '_ma_' in f] if feature_set else []\n",
    "    fut_exog = [f for f in feature_set if f not in hist_exog] if feature_set else []\n",
    "\n",
    "\n",
    "    # --- Prepare Future Exogenous Features ---\n",
    "    X_future = None\n",
    "    if fut_exog:\n",
    "        X_future = X_val[fut_exog].copy()\n",
    "        if not X_future.isnull().all().all():  \n",
    "            X_future.insert(0, 'month_year', X_val.index)\n",
    "        else:\n",
    "            X_future = None  # Avoid passing empty DataFrame\n",
    "\n",
    "    # --- Simple Forecast (12 ≤ obs < 36) ---\n",
    "    if len(X_train) < 36:\n",
    "        print(f\"Using simple forecast ({len(X_train)} < 36 obs)\")\n",
    "        try:\n",
    "            history = df_train.copy()\n",
    "            if feature_set:\n",
    "                history = history[feature_set + [target_col]]\n",
    "\n",
    "            forecast = nixtla_client.forecast(df=history.reset_index(),\n",
    "                                              time_col=\"month_year\", target_col=target_col, h=horizon,\n",
    "                                              X_df=X_future,  # Always pass X_future if available\n",
    "                                              hist_exog_list=hist_exog if hist_exog else None)\n",
    "            \n",
    "            # Get training predictions\n",
    "            train_pred = nixtla_client.forecast(df=history.reset_index(),time_col=\"month_year\",\n",
    "                                                target_col=target_col,h=1,hist_exog_list=hist_exog if hist_exog else None\n",
    "                                                ).iloc[0][\"TimeGPT\"]\n",
    "            \n",
    "            train_predictions = [train_pred] * len(history)\n",
    "            \n",
    "            return {\n",
    "                'product_id': product_id,'winsorize': winsorize,'features': feature_set,\n",
    "                'metrics': calculate_metrics(y_true=y_val,y_pred=forecast[\"TimeGPT\"],\n",
    "                                             y_train=history[target_col],y_train_pred=train_predictions),\n",
    "                'method': 'simple','validation_predictions': forecast[\"TimeGPT\"]}\n",
    "        except Exception as e:\n",
    "            print(f\"Simple forecast failed: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    # --- Walk-Forward (≥36 obs) ---\n",
    "    print(f\"Using walk-forward ({len(X_train)} ≥ 36 obs)\")\n",
    "    predictions = []\n",
    "    history = X_train.copy()\n",
    "    history[target_col] = y_train.values\n",
    "    history = history.reset_index()\n",
    "    \n",
    "    # Get training predictions\n",
    "    try:\n",
    "        train_fit = nixtla_client.forecast(df=history,time_col='month_year',target_col=target_col,h=1,\n",
    "                                           hist_exog_list=hist_exog if hist_exog else None)\n",
    "        train_predictions = [train_fit[\"TimeGPT\"].iloc[0]] * len(y_train)\n",
    "    except Exception as e:\n",
    "        print(f\"Training pred failed: {str(e)} - using last value\")\n",
    "        train_predictions = [y_train.iloc[-1]] * len(y_train)\n",
    "\n",
    "    for i in range(horizon):\n",
    "        try:\n",
    "            X_future_step = None\n",
    "            if fut_exog:\n",
    "                X_future_step = X_val.iloc[[i]][fut_exog].copy()\n",
    "                if not X_future_step.isnull().all().all():  \n",
    "                    X_future_step.insert(0, 'month_year', X_val.index[i])\n",
    "                else:\n",
    "                    X_future_step = None  \n",
    "\n",
    "            forecast = nixtla_client.forecast(df=history,time_col='month_year',target_col=target_col,\n",
    "                                              h=1, X_df=X_future_step if fut_exog else None, # FUTURE features (macro)\n",
    "                                              hist_exog_list=hist_exog if hist_exog else None)  # HISTORICAL features (lags, moving averages)\n",
    "            \n",
    "            pred = forecast[\"TimeGPT\"].iloc[0]\n",
    "            predictions.append(pred)\n",
    "            \n",
    "            new_row = X_val.iloc[i].copy()\n",
    "            new_row['month_year'] = X_val.index[i]\n",
    "            new_row[target_col] = pred\n",
    "            history = pd.concat([history, pd.DataFrame([new_row])])\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Iteration {i+1} failed: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    metrics = calculate_metrics(y_true=y_val,y_pred=predictions,y_train=y_train,y_train_pred=train_predictions)\n",
    "    \n",
    "    return {'product_id': product_id,'winsorize': winsorize,'features': feature_set,'metrics': metrics,\n",
    "            'method': 'walkforward','validation_predictions': predictions}\n",
    "\n",
    "\n",
    "def find_best_timegpt_config(product_id, df_train, nixtla_client, lagged_df=None, target_col=\"Sales\"):\n",
    "\n",
    "    # Validate input data\n",
    "    if not isinstance(df_train.index, pd.DatetimeIndex):\n",
    "        raise TypeError(\"❌ df_train index is not a DatetimeIndex!\")\n",
    "    if df_train.index.isnull().any():\n",
    "        raise ValueError(\"❌ Some index values could not be parsed into datetime!\")\n",
    "    \n",
    "    results = []\n",
    "    data = df_train.copy()\n",
    "    \n",
    "    # Feature groups for original data\n",
    "    normal_features = [col for col in data.columns if col != target_col]\n",
    "    normal_feature_combinations = generate_feature_combinations(normal_features, max_features=6)  \n",
    "    normal_feature_combinations = [[]] + normal_feature_combinations\n",
    "    print(normal_feature_combinations)\n",
    "    \n",
    "    # Test original data configurations\n",
    "    for winsorize in [True, False]:\n",
    "        for features in normal_feature_combinations:\n",
    "            try:\n",
    "                print(f\"\\nTesting - Winsorize: {winsorize}, Features: {features}\")\n",
    "\n",
    "                result = choose_parameters_timegpt(\n",
    "                    product_id=product_id,df_train=data, feature_set=features, target_col=target_col,\n",
    "                    nixtla_client=nixtla_client,winsorize=winsorize)\n",
    "                \n",
    "                if result:\n",
    "                    print(f\"✅ Success - RMSE: {result['metrics']['RMSE']:.2f}\")\n",
    "                    results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Configuration failed: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    # Test lagged data configurations if available\n",
    "    if lagged_df is not None:\n",
    "        lagged_data = lagged_df.copy()\n",
    "        lag_features = [col for col in lagged_data.columns if 'lag' in col]\n",
    "        ma_features = [col for col in lagged_data.columns if '_ma_' in col]\n",
    "        macro_features = [col for col in data.columns if col != target_col]\n",
    "        \n",
    "        # Generate lag feature combinations\n",
    "        lag_feature_combinations = generate_feature_combinations(lag_features, max_features=5)\n",
    "        \n",
    "        # Create combined feature sets\n",
    "        full_combinations = []\n",
    "        for lag_combo in lag_feature_combinations:\n",
    "            full_combinations.append(lag_combo)  # Just lags\n",
    "            full_combinations.append(lag_combo + macro_features)  # Lags + macros\n",
    "            full_combinations.append(lag_combo + ma_features)  # Lags + MAs\n",
    "            full_combinations.append(lag_combo + macro_features + ma_features)  # All\n",
    "        \n",
    "        # Remove duplicates\n",
    "        seen = set()\n",
    "        unique_combinations = []\n",
    "        for combo in full_combinations:\n",
    "            combo_tuple = tuple(sorted(combo))\n",
    "            if combo_tuple not in seen:\n",
    "                seen.add(combo_tuple)\n",
    "                unique_combinations.append(combo)\n",
    "        \n",
    "        # Test all unique combinations\n",
    "        for winsorize in [True, False]:\n",
    "            for features in unique_combinations:\n",
    "                try:\n",
    "                    print(f\"\\nTesting - Lagged Features: {features}\")\n",
    "\n",
    "                    result = choose_parameters_timegpt(product_id=product_id,df_train=lagged_data,feature_set=features,\n",
    "                                                       target_col=target_col,nixtla_client=nixtla_client,winsorize=winsorize)\n",
    "                    \n",
    "                    if result:\n",
    "                        print(f\"✅ Success - RMSE: {result['metrics']['RMSE']:.2f}\")\n",
    "                        results.append(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Lagged configuration failed: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    if not results:\n",
    "        raise ValueError(f\"No valid configurations for {product_id}\")\n",
    "    \n",
    "    # Select best configuration by RMSE\n",
    "    best_config = min(results, key=lambda x: x['metrics']['RMSE'])\n",
    "    \n",
    "    print(f\"\\n✅ Best configuration for {product_id}:\")\n",
    "    print(f\"- Winsorize: {best_config['winsorize']}\")\n",
    "    print(f\"- Features: {best_config['features']}\")\n",
    "    print(f\"- RMSE: {best_config['metrics']['RMSE']:.2f}\")\n",
    "    print(f\"- Method: {best_config.get('method', 'walkforward')}\")\n",
    "    \n",
    "    return best_config, results\n",
    "\n",
    "def process_product_parallel(product_id):\n",
    "    try:\n",
    "        df_train = product_dfs[product_id].rename(columns={product_id: \"Sales\"})\n",
    "        \n",
    "        # Ensure DatetimeIndex\n",
    "        if not isinstance(df_train.index, pd.DatetimeIndex):\n",
    "            df_train.index = pd.to_datetime(df_train.index, errors=\"coerce\")\n",
    "        \n",
    "        if df_train.index.isnull().any():\n",
    "            raise ValueError(\"❌ Some index values could not be parsed into datetime!\")\n",
    "\n",
    "        lagged_df = lagged_product_dfs.get(product_id, None)\n",
    "\n",
    "        best_config, results = find_best_timegpt_config(product_id=product_id,df_train=df_train,lagged_df=lagged_df,\n",
    "            nixtla_client=nixtla_client,target_col=\"Sales\")\n",
    "        \n",
    "        return best_config, results\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to process {product_id}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "all_product_ids = set(product_dfs.keys())\n",
    "\n",
    "all_results = []  # List to store all results\n",
    "best_configs = []  # List to store best configurations\n",
    "\n",
    "for product_id in all_product_ids:\n",
    "    print(f\"Processing product: {product_id}\")\n",
    "    \n",
    "    try:\n",
    "        best_config_timegpt, results_timegpt = process_product_parallel(product_id)\n",
    "        \n",
    "        if best_config_timegpt is not None:\n",
    "            best_configs.append(best_config_timegpt)  # Store best config\n",
    "        else:\n",
    "            print(f\"Warning: No best config returned for product {product_id}\")\n",
    "        \n",
    "        if results_timegpt is not None:\n",
    "            all_results.extend(results_timegpt)  # Store results\n",
    "        else:\n",
    "            print(f\"Warning: No results returned for product {product_id}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing product {product_id}: {str(e)}\")\n",
    "\n",
    "df_all_results = convert_results_to_df(all_results) if all_results else pd.DataFrame()\n",
    "df_best_configs = pd.DataFrame(best_configs) if best_configs else pd.DataFrame()\n",
    "\n",
    "df_all_results.to_csv(\"timegpt_best_configs.csv\", index=False)\n",
    "df_best_configs.to_csv(\"timegpt_best_configs_details.csv\", index=False)\n",
    "\n",
    "print(\"Processing completed! Results saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"background-color:#000027; padding:5px; border-radius:5px;\">**3.2. XGBoost**</span> <a id='xgboost'></a>  \n",
    "\n",
    "\n",
    "Click [here](#table-of-contents) ⬆️ to return to the Index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_parameters_xgboost(product_id, df_train, feature_set, target_col=\"Sales\", \n",
    "                            param_grid=None, n_jobs=-1, winsorize=False, horizon=7):\n",
    "    \"\"\"Optimized XGBoost forecasting with proper walk-forward validation\"\"\"\n",
    "    \n",
    "    # --- Input Validation ---\n",
    "    if len(df_train) < 12:\n",
    "        print(f\"⚠️ Skipping {product_id} - only {len(df_train)} observations\")\n",
    "        return None\n",
    "    \n",
    "    # --- Data Preparation ---\n",
    "    print('Preparing data...')\n",
    "    try:\n",
    "        X_train, X_val, y_train, y_val = prepare_time_series_data(\n",
    "            df_train, feature_set, target_col, horizon, winsorize)\n",
    "        # Verify temporal ordering\n",
    "        assert X_train.index[-1] < X_val.index[0], \"Validation data must be after training data\"\n",
    "    except Exception as e:\n",
    "        print(f\"Data preparation failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    # --- Optimized Parameter Grid for Small Data ---\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100],\n",
    "            'max_depth': [2, 3],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'subsample': [0.9, 1.0],\n",
    "            'colsample_bytree': [0.9, 1.0],\n",
    "            'min_child_weight': [1, 3]}\n",
    "\n",
    "    # --- Efficient Model Setup ---\n",
    "    base_model = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',random_state=42,n_jobs=1,tree_method='hist',  # Faster training\n",
    "        enable_categorical=False,gamma=0,reg_alpha=0,reg_lambda=1)\n",
    "\n",
    "    # --- Strict Temporal Validation ---\n",
    "    test_fold = np.array([-1] * len(X_train) + [0] * len(X_val))\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "\n",
    "    # --- Focused Grid Search ---\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=base_model,param_grid=param_grid,scoring='neg_root_mean_squared_error',cv=ps,n_jobs=n_jobs,verbose=1,refit=True)\n",
    "\n",
    "    # --- Training with Validation ---\n",
    "    X_combined = pd.concat([X_train, X_val])\n",
    "    y_combined = pd.concat([y_train, y_val])\n",
    "    \n",
    "    print(f\"Starting grid search for {product_id}...\")\n",
    "    try:\n",
    "        grid_search.fit(X_combined, y_combined)\n",
    "        best_model = grid_search.best_estimator_\n",
    "    except Exception as e:\n",
    "        print(f\"Grid search failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    # --- Robust Walk-forward Validation ---\n",
    "    predictions = []\n",
    "    print(f\"Using walk-forward (n_train={len(X_train)}, horizon={horizon})\")\n",
    "    \n",
    "    for i in range(horizon):\n",
    "        try:\n",
    "            # Create expanding window\n",
    "            window_X = pd.concat([X_train, X_val.iloc[:i]])\n",
    "            window_y = pd.concat([y_train, y_val.iloc[:i]])\n",
    "            \n",
    "            # Correct XGBoost 2.1.3+ fitting\n",
    "            best_model.fit(window_X, window_y, eval_set=[(X_val.iloc[[i]], y_val.iloc[[i]])], verbose=0)\n",
    "    \n",
    "            pred = best_model.predict(X_val.iloc[[i]]).item()\n",
    "            predictions.append(pred)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Iteration {i+1} failed: {str(e)} - using fallback\")\n",
    "            fallback = (predictions[-1] if len(predictions) > 0 else \n",
    "                       y_train.iloc[-1] if len(y_train) > 0 else np.nan)\n",
    "            predictions.append(fallback)\n",
    "\n",
    "    # --- Training Metrics ---\n",
    "    try:\n",
    "        train_predictions = best_model.predict(X_train).tolist()\n",
    "    except Exception as e:\n",
    "        print(f\"Training predictions failed: {str(e)} - using last value\")\n",
    "        train_predictions = [y_train.iloc[-1]] * len(y_train)\n",
    "\n",
    "    # --- Comprehensive Metrics ---\n",
    "    metrics = calculate_metrics(y_true=y_val,y_pred=predictions,y_train=y_train,y_train_pred=train_predictions)\n",
    "    \n",
    "    return {\n",
    "        'product_id': product_id,\n",
    "        'winsorize': winsorize,\n",
    "        'features': feature_set,\n",
    "        'metrics': metrics,\n",
    "        'method': 'walkforward',\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'validation_predictions': predictions,\n",
    "        'feature_importances': dict(zip(feature_set, best_model.feature_importances_))}\n",
    "\n",
    "\n",
    "def find_best_xgboost_config(product_id, df_train, lagged_df=None, target_col=\"Sales\", \n",
    "                            n_jobs=-1, custom_param_grids=None):\n",
    "    # Validate input data\n",
    "    if not isinstance(df_train.index, pd.DatetimeIndex):\n",
    "        raise TypeError(\"❌ df_train index is not a DatetimeIndex!\")\n",
    "    if df_train.index.isnull().any():\n",
    "        raise ValueError(\"❌ Some index values could not be parsed into datetime!\")\n",
    "    \n",
    "    results = []\n",
    "    data = df_train.copy()\n",
    "    \n",
    "    # Feature groups for original data\n",
    "    normal_features = [col for col in data.columns if col != target_col]\n",
    "    normal_feature_combinations = generate_feature_combinations(normal_features, max_features=6)  \n",
    "    normal_feature_combinations = [[]] + normal_feature_combinations\n",
    "    \n",
    "    # Test original data configurations\n",
    "    for winsorize in [True, False]:\n",
    "        for features in normal_feature_combinations:\n",
    "            try:\n",
    "                print(f\"\\nTesting - Winsorize: {winsorize}, Features: {features}\")\n",
    "\n",
    "                # Use custom param grid if provided for this feature set\n",
    "                param_grid = None\n",
    "                if custom_param_grids and tuple(features) in custom_param_grids:\n",
    "                    param_grid = custom_param_grids[tuple(features)]\n",
    "\n",
    "                result = choose_parameters_xgboost(product_id=product_id,df_train=data,feature_set=features,\n",
    "                    target_col=target_col,winsorize=winsorize,n_jobs=n_jobs,param_grid=param_grid)\n",
    "                \n",
    "                if result:\n",
    "                    print(f\"✅ Success - RMSE: {result['metrics']['RMSE']:.2f}\")\n",
    "                    results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Configuration failed: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    # Test lagged data configurations if available\n",
    "    if lagged_df is not None:\n",
    "        lagged_data = lagged_df.copy()\n",
    "        lag_features = [col for col in lagged_data.columns if 'lag' in col]\n",
    "        ma_features = [col for col in lagged_data.columns if '_ma_' in col]\n",
    "        macro_features = [col for col in data.columns if col != target_col]\n",
    "        \n",
    "        # Generate lag feature combinations\n",
    "        lag_feature_combinations = generate_feature_combinations(lag_features, max_features=5)\n",
    "        \n",
    "        # Create combined feature sets\n",
    "        full_combinations = []\n",
    "        for lag_combo in lag_feature_combinations:\n",
    "            full_combinations.append(lag_combo)  # Just lags\n",
    "            full_combinations.append(lag_combo + macro_features)  # Lags + macros\n",
    "            full_combinations.append(lag_combo + ma_features)  # Lags + MAs\n",
    "            full_combinations.append(lag_combo + macro_features + ma_features)  # All\n",
    "        \n",
    "        # Remove duplicates\n",
    "        seen = set()\n",
    "        unique_combinations = []\n",
    "        for combo in full_combinations:\n",
    "            combo_tuple = tuple(sorted(combo))\n",
    "            if combo_tuple not in seen:\n",
    "                seen.add(combo_tuple)\n",
    "                unique_combinations.append(combo)\n",
    "        \n",
    "        # Test all unique combinations\n",
    "        for winsorize in [True, False]:\n",
    "            for features in unique_combinations:\n",
    "                try:\n",
    "                    print(f\"\\nTesting - Lagged Features: {features}\")\n",
    "\n",
    "                    # Use custom param grid if provided for this feature set\n",
    "                    param_grid = None\n",
    "                    if custom_param_grids and tuple(features) in custom_param_grids:\n",
    "                        param_grid = custom_param_grids[tuple(features)]\n",
    "\n",
    "                    result = choose_parameters_xgboost(product_id=product_id,df_train=lagged_data,feature_set=features,\n",
    "                                                       target_col=target_col,winsorize=winsorize,n_jobs=n_jobs,param_grid=param_grid)\n",
    "                    \n",
    "                    if result:\n",
    "                        print(f\"✅ Success - RMSE: {result['metrics']['RMSE']:.2f}\")\n",
    "                        results.append(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Lagged configuration failed: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    if not results:\n",
    "        raise ValueError(f\"No valid configurations for {product_id}\")\n",
    "    \n",
    "    # Select best configuration by RMSE\n",
    "    best_config = min(results, key=lambda x: x['metrics']['RMSE'])\n",
    "    \n",
    "    print(f\"\\n✅ Best configuration for {product_id}:\")\n",
    "    print(f\"- Winsorize: {best_config['winsorize']}\")\n",
    "    print(f\"- Features: {best_config['features']}\")\n",
    "    print(f\"- Best params: {best_config['best_params']}\")\n",
    "    print(f\"- RMSE: {best_config['metrics']['RMSE']:.2f}\")\n",
    "    print(f\"- Method: {best_config.get('method', 'walkforward')}\")\n",
    "    \n",
    "    return best_config, results\n",
    "\n",
    "def process_product_parallel(product_id, custom_param_grids=None):\n",
    "    try:\n",
    "        df_train = product_dfs[product_id].rename(columns={product_id: \"Sales\"})\n",
    "        \n",
    "        # Ensure DatetimeIndex\n",
    "        if not isinstance(df_train.index, pd.DatetimeIndex):\n",
    "            df_train.index = pd.to_datetime(df_train.index, errors=\"coerce\")\n",
    "        \n",
    "        if df_train.index.isnull().any():\n",
    "            raise ValueError(\"❌ Some index values could not be parsed into datetime!\")\n",
    "\n",
    "        lagged_df = lagged_product_dfs.get(product_id, None)\n",
    "\n",
    "        best_config, results = find_best_xgboost_config(product_id=product_id,df_train=df_train,lagged_df=lagged_df,target_col=\"Sales\", custom_param_grids=custom_param_grids)\n",
    "        \n",
    "        return best_config, results\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to process {product_id}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing product: P5\n",
      "\n",
      "Testing - Winsorize: True, Features: []\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1789375.78, Upper = 19056280.70\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2125718.32\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27826_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1789375.78, Upper = 19056280.70\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 1413065.22\n",
      "\n",
      "Testing - Winsorize: True, Features: ['MAB_ELE_SHP840']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1789375.78, Upper = 19056280.70\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2430260.13\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO271000_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1789375.78, Upper = 19056280.70\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2519839.97\n",
      "\n",
      "Testing - Winsorize: True, Features: ['MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1789375.78, Upper = 19056280.70\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2349197.41\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27826_org', 'MAB_ELE_SHP840']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1789375.78, Upper = 19056280.70\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 1487484.89\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27826_org', 'PRO271000_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1789375.78, Upper = 19056280.70\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2083144.18\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27826_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1789375.78, Upper = 19056280.70\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 1939059.32\n",
      "\n",
      "Testing - Winsorize: True, Features: ['MAB_ELE_SHP840', 'PRO271000_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1789375.78, Upper = 19056280.70\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2364489.99\n",
      "\n",
      "Testing - Winsorize: True, Features: ['MAB_ELE_SHP840', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1789375.78, Upper = 19056280.70\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2498038.06\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1789375.78, Upper = 19056280.70\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2202237.91\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1789375.78, Upper = 19056280.70\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2302070.16\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27826_org', 'MAB_ELE_SHP840', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1789375.78, Upper = 19056280.70\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2414259.29\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27826_org', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1789375.78, Upper = 19056280.70\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 1999480.95\n",
      "\n",
      "Testing - Winsorize: True, Features: ['MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1789375.78, Upper = 19056280.70\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2429448.41\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1789375.78, Upper = 19056280.70\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2125718.32\n",
      "\n",
      "Testing - Winsorize: False, Features: []\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 1989788.48\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27826_org']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 1331522.07\n",
      "\n",
      "Testing - Winsorize: False, Features: ['MAB_ELE_SHP840']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2427323.29\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO271000_org']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2503312.35\n",
      "\n",
      "Testing - Winsorize: False, Features: ['MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2330456.14\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27826_org', 'MAB_ELE_SHP840']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 1544903.42\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27826_org', 'PRO271000_org']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2055348.75\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27826_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 1979618.19\n",
      "\n",
      "Testing - Winsorize: False, Features: ['MAB_ELE_SHP840', 'PRO271000_org']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2339493.68\n",
      "\n",
      "Testing - Winsorize: False, Features: ['MAB_ELE_SHP840', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2684772.67\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2212564.35\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2315832.61\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27826_org', 'MAB_ELE_SHP840', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2411074.92\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27826_org', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 1987395.79\n",
      "\n",
      "Testing - Winsorize: False, Features: ['MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 2432920.35\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 1989788.48\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2772577.80\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 3166254.47\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 3088499.03\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 3091055.90\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_7']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2154560.90\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_7', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2184444.37\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_7', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2851427.79\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_7', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2859963.93\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2426779.53\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_10', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2057063.72\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_10', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2723322.68\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_10', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2680536.84\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_7']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2101560.20\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_7', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2296357.18\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_7', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2867357.77\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_7', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2969262.89\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 1991603.98\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_10', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 1929731.61\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_10', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2510958.43\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_10', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2630676.19\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_7', 'P5_lag_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2083799.62\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_7', 'P5_lag_10', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2234443.30\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_7', 'P5_lag_10', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2445898.95\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_7', 'P5_lag_10', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2593427.89\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_7', 'P5_lag_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 1956127.77\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_7', 'P5_lag_10', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2222964.90\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_7', 'P5_lag_10', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2500900.49\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_7', 'P5_lag_10', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 1999525.90, Upper = 19615688.64\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2625596.39\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2749043.85\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2786017.94\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 3097674.94\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 3100674.16\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_7']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2136650.24\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_7', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2220352.03\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_7', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2819534.50\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_7', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2871958.15\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2458245.73\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_10', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2054463.06\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_10', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2713305.42\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_10', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2524479.25\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_7']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2152006.42\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_7', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2327747.33\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_7', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2915331.01\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_7', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2997109.58\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 1971115.18\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_10', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 1892132.52\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_10', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2451236.23\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_10', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2649317.24\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_7', 'P5_lag_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 1892873.67\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_7', 'P5_lag_10', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2233152.05\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_7', 'P5_lag_10', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2426939.84\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_7', 'P5_lag_10', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2645321.46\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_7', 'P5_lag_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 1820690.75\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_7', 'P5_lag_10', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2272065.14\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_7', 'P5_lag_10', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2425085.56\n",
      "\n",
      "Testing - Lagged Features: ['P5_lag_17', 'P5_lag_7', 'P5_lag_10', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org', 'MAB_ELE_PRO156', 'P5_ma_17', 'P5_ma_7', 'P5_ma_10']\n",
      "Preparing data...\n",
      "Starting grid search for P5...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 2647351.78\n",
      "\n",
      "✅ Best configuration for P5:\n",
      "- Winsorize: False\n",
      "- Features: ['PRO27826_org']\n",
      "- Best params: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 50, 'subsample': 0.9}\n",
      "- RMSE: 1331522.07\n",
      "- Method: walkforward\n",
      "Processing product: P13\n",
      "\n",
      "Testing - Winsorize: True, Features: []\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 2973.33, Upper = 66712.37\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 11514.92\n",
      "\n",
      "Testing - Winsorize: True, Features: ['MAB_ELE_PRO756']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 2973.33, Upper = 66712.37\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 11791.21\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27756_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 2973.33, Upper = 66712.37\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 11230.33\n",
      "\n",
      "Testing - Winsorize: True, Features: ['MAB_ELE_PRO276']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 2973.33, Upper = 66712.37\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 12099.10\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRI27840_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 2973.33, Upper = 66712.37\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 14105.72\n",
      "\n",
      "Testing - Winsorize: True, Features: ['MAB_ELE_PRO756', 'PRO27756_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 2973.33, Upper = 66712.37\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 11294.55\n",
      "\n",
      "Testing - Winsorize: True, Features: ['MAB_ELE_PRO756', 'MAB_ELE_PRO276']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 2973.33, Upper = 66712.37\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 10534.60\n",
      "\n",
      "Testing - Winsorize: True, Features: ['MAB_ELE_PRO756', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 2973.33, Upper = 66712.37\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 12006.89\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27756_org', 'MAB_ELE_PRO276']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 2973.33, Upper = 66712.37\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 11333.74\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27756_org', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 2973.33, Upper = 66712.37\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 12351.98\n",
      "\n",
      "Testing - Winsorize: True, Features: ['MAB_ELE_PRO276', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 2973.33, Upper = 66712.37\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 12493.59\n",
      "\n",
      "Testing - Winsorize: True, Features: ['MAB_ELE_PRO756', 'PRO27756_org', 'MAB_ELE_PRO276']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 2973.33, Upper = 66712.37\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 10669.35\n",
      "\n",
      "Testing - Winsorize: True, Features: ['MAB_ELE_PRO756', 'PRO27756_org', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 2973.33, Upper = 66712.37\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 12183.81\n",
      "\n",
      "Testing - Winsorize: True, Features: ['MAB_ELE_PRO756', 'MAB_ELE_PRO276', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 2973.33, Upper = 66712.37\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 10460.80\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27756_org', 'MAB_ELE_PRO276', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 2973.33, Upper = 66712.37\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 12493.72\n",
      "\n",
      "Testing - Winsorize: True, Features: ['MAB_ELE_PRO756', 'PRO27756_org', 'MAB_ELE_PRO276', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 2973.33, Upper = 66712.37\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 11514.92\n",
      "\n",
      "Testing - Winsorize: False, Features: []\n",
      "Preparing data...\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 11450.21\n",
      "\n",
      "Testing - Winsorize: False, Features: ['MAB_ELE_PRO756']\n",
      "Preparing data...\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 11964.38\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27756_org']\n",
      "Preparing data...\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 11232.16\n",
      "\n",
      "Testing - Winsorize: False, Features: ['MAB_ELE_PRO276']\n",
      "Preparing data...\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 12094.39\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRI27840_org']\n",
      "Preparing data...\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 14058.62\n",
      "\n",
      "Testing - Winsorize: False, Features: ['MAB_ELE_PRO756', 'PRO27756_org']\n",
      "Preparing data...\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 11285.33\n",
      "\n",
      "Testing - Winsorize: False, Features: ['MAB_ELE_PRO756', 'MAB_ELE_PRO276']\n",
      "Preparing data...\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 10540.05\n",
      "\n",
      "Testing - Winsorize: False, Features: ['MAB_ELE_PRO756', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 11966.95\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27756_org', 'MAB_ELE_PRO276']\n",
      "Preparing data...\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 11324.56\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27756_org', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 12405.51\n",
      "\n",
      "Testing - Winsorize: False, Features: ['MAB_ELE_PRO276', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 12473.88\n",
      "\n",
      "Testing - Winsorize: False, Features: ['MAB_ELE_PRO756', 'PRO27756_org', 'MAB_ELE_PRO276']\n",
      "Preparing data...\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 10643.68\n",
      "\n",
      "Testing - Winsorize: False, Features: ['MAB_ELE_PRO756', 'PRO27756_org', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 11958.43\n",
      "\n",
      "Testing - Winsorize: False, Features: ['MAB_ELE_PRO756', 'MAB_ELE_PRO276', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 11358.07\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27756_org', 'MAB_ELE_PRO276', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 11060.91\n",
      "\n",
      "Testing - Winsorize: False, Features: ['MAB_ELE_PRO756', 'PRO27756_org', 'MAB_ELE_PRO276', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=36, horizon=7)\n",
      "✅ Success - RMSE: 11450.21\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_17']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 13613.74\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_17', 'MAB_ELE_PRO756', 'PRO27756_org', 'MAB_ELE_PRO276', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 12624.49\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_17', 'P13_ma_17', 'P13_ma_5', 'P13_ma_8']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 12338.69\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_17', 'MAB_ELE_PRO756', 'PRO27756_org', 'MAB_ELE_PRO276', 'PRI27840_org', 'P13_ma_17', 'P13_ma_5', 'P13_ma_8']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 11263.04\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_5']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 13207.27\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_5', 'MAB_ELE_PRO756', 'PRO27756_org', 'MAB_ELE_PRO276', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 12356.42\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_5', 'P13_ma_17', 'P13_ma_5', 'P13_ma_8']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 11458.06\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_5', 'MAB_ELE_PRO756', 'PRO27756_org', 'MAB_ELE_PRO276', 'PRI27840_org', 'P13_ma_17', 'P13_ma_5', 'P13_ma_8']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 10529.02\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_8']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 12299.93\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_8', 'MAB_ELE_PRO756', 'PRO27756_org', 'MAB_ELE_PRO276', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 12480.28\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_8', 'P13_ma_17', 'P13_ma_5', 'P13_ma_8']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 10777.03\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_8', 'MAB_ELE_PRO756', 'PRO27756_org', 'MAB_ELE_PRO276', 'PRI27840_org', 'P13_ma_17', 'P13_ma_5', 'P13_ma_8']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 10529.02\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_17', 'P13_lag_5']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 13287.42\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_17', 'P13_lag_5', 'MAB_ELE_PRO756', 'PRO27756_org', 'MAB_ELE_PRO276', 'PRI27840_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 12624.49\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_17', 'P13_lag_5', 'P13_ma_17', 'P13_ma_5', 'P13_ma_8']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 12380.81\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_17', 'P13_lag_5', 'MAB_ELE_PRO756', 'PRO27756_org', 'MAB_ELE_PRO276', 'PRI27840_org', 'P13_ma_17', 'P13_ma_5', 'P13_ma_8']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n",
      "Using walk-forward (n_train=19, horizon=7)\n",
      "✅ Success - RMSE: 11288.28\n",
      "\n",
      "Testing - Lagged Features: ['P13_lag_17', 'P13_lag_8']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = 3860.58, Upper = 59849.75\n",
      "Starting grid search for P13...\n",
      "Fitting 1 folds for each of 96 candidates, totalling 96 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing product: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproduct_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 9\u001b[0m     best_config_xgboost, results_xgboost \u001b[38;5;241m=\u001b[39m process_product_parallel(product_id, custom_param_grids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m best_config_xgboost \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m         best_configs_xgboost\u001b[38;5;241m.\u001b[39mappend(best_config_xgboost)  \u001b[38;5;66;03m# Store best config\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[42], line 212\u001b[0m, in \u001b[0;36mprocess_product_parallel\u001b[1;34m(product_id, custom_param_grids)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ Some index values could not be parsed into datetime!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    210\u001b[0m     lagged_df \u001b[38;5;241m=\u001b[39m lagged_product_dfs\u001b[38;5;241m.\u001b[39mget(product_id, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 212\u001b[0m     best_config, results \u001b[38;5;241m=\u001b[39m find_best_xgboost_config(product_id\u001b[38;5;241m=\u001b[39mproduct_id,df_train\u001b[38;5;241m=\u001b[39mdf_train,lagged_df\u001b[38;5;241m=\u001b[39mlagged_df,target_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m\"\u001b[39m, custom_param_grids\u001b[38;5;241m=\u001b[39mcustom_param_grids)\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_config, results\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[42], line 174\u001b[0m, in \u001b[0;36mfind_best_xgboost_config\u001b[1;34m(product_id, df_train, lagged_df, target_col, n_jobs, custom_param_grids)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m custom_param_grids \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(features) \u001b[38;5;129;01min\u001b[39;00m custom_param_grids:\n\u001b[0;32m    172\u001b[0m     param_grid \u001b[38;5;241m=\u001b[39m custom_param_grids[\u001b[38;5;28mtuple\u001b[39m(features)]\n\u001b[1;32m--> 174\u001b[0m result \u001b[38;5;241m=\u001b[39m choose_parameters_xgboost(product_id\u001b[38;5;241m=\u001b[39mproduct_id,df_train\u001b[38;5;241m=\u001b[39mlagged_data,feature_set\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m    175\u001b[0m                                    target_col\u001b[38;5;241m=\u001b[39mtarget_col,winsorize\u001b[38;5;241m=\u001b[39mwinsorize,n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,param_grid\u001b[38;5;241m=\u001b[39mparam_grid)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Success - RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[42], line 50\u001b[0m, in \u001b[0;36mchoose_parameters_xgboost\u001b[1;34m(product_id, df_train, feature_set, target_col, param_grid, n_jobs, winsorize, horizon)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting grid search for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproduct_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     grid_search\u001b[38;5;241m.\u001b[39mfit(X_combined, y_combined)\n\u001b[0;32m     51\u001b[0m     best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\catar\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\catar\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\catar\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\catar\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\catar\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\catar\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\catar\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\catar\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_product_ids = set(product_dfs.keys())\n",
    "all_results_xgboost = []  # List to store all results\n",
    "best_configs_xgboost = []  # List to store best configurations\n",
    "\n",
    "for product_id in all_product_ids:\n",
    "    print(f\"Processing product: {product_id}\")\n",
    "    \n",
    "    try:\n",
    "        best_config_xgboost, results_xgboost = process_product_parallel(product_id, custom_param_grids=None)\n",
    "        \n",
    "        if best_config_xgboost is not None:\n",
    "            best_configs_xgboost.append(best_config_xgboost)  # Store best config\n",
    "        else:\n",
    "            print(f\"Warning: No best config returned for product {product_id}\")\n",
    "        \n",
    "        if results_xgboost is not None:\n",
    "            all_results_xgboost.extend(results_xgboost)  # Store results\n",
    "        else:\n",
    "            print(f\"Warning: No results returned for product {product_id}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing product {product_id}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed! Results saved.\n"
     ]
    }
   ],
   "source": [
    "df_all_results_xgboost = convert_results_to_df(all_results_xgboost) if all_results_xgboost else pd.DataFrame()\n",
    "df_best_configs_xgboost = pd.DataFrame(best_configs_xgboost) if best_configs_xgboost else pd.DataFrame()\n",
    "\n",
    "df_all_results_xgboost.to_csv(\"xgboost_results.csv\", index=False)\n",
    "df_best_configs_xgboost.to_csv(\"xgboost_best_configs_details.csv\", index=False)\n",
    "\n",
    "print(\"Processing completed! Results saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"background-color:#000027; padding:5px; border-radius:5px;\">**3.3. TCN**</span> <a id='tcn'></a>  \n",
    "\n",
    "Click [here](#table-of-contents) ⬆️ to return to the Index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_parameters_tcn(product_id, df_train, feature_set, target_col=\"Sales\", \n",
    "                         param_grid=None, n_jobs=-1, winsorize=False, horizon=7):\n",
    "    \"\"\"Optimized TCN forecasting with walk-forward validation\"\"\"\n",
    "    \n",
    "    if len(df_train) < 12:\n",
    "        print(f\"⚠️ Skipping {product_id} - only {len(df_train)} observations\")\n",
    "        return None\n",
    "    \n",
    "    print('Preparing data...')\n",
    "    try:\n",
    "        X_train, X_val, y_train, y_val = prepare_time_series_data(\n",
    "            df_train, feature_set, target_col, horizon, winsorize, scaling=True)\n",
    "        \n",
    "        assert X_train.index[-1] < X_val.index[0], \"Validation data must be after training data\"\n",
    "    except Exception as e:\n",
    "        print(f\"Data preparation failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    # Reshape data for TCN input (samples, timesteps, features)\n",
    "    X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_val = X_val.values.reshape((X_val.shape[0], 1, X_val.shape[1]))\n",
    "    y_train = y_train.values.reshape(-1, 1)\n",
    "    y_val = y_val.values.reshape(-1, 1)\n",
    "\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            'nb_filters': [16, 32],\n",
    "            'kernel_size': [2, 3],\n",
    "            'dilations': [[1, 2, 4], [1, 2, 4, 8]],\n",
    "            'dropout_rate': [0.1, 0.2],\n",
    "            'return_sequences': [False]  # single-step prediction\n",
    "}\n",
    "    \n",
    "    def build_tcn(nb_filters=32, kernel_size=2, dilations=[1, 2, 4], \n",
    "                 dropout_rate=0.1, return_sequences=False):\n",
    "        inputs = Input(shape=(1, X_train.shape[2]))\n",
    "        x = TCN(nb_filters=nb_filters, kernel_size=kernel_size, \n",
    "               dilations=dilations, dropout_rate=dropout_rate,\n",
    "               return_sequences=return_sequences)(inputs)\n",
    "        outputs = Dense(1)(x)\n",
    "        model = Model(inputs, outputs)\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "        return model\n",
    "    \n",
    "    best_params = None\n",
    "    best_rmse = float('inf')\n",
    "\n",
    "    for filters in param_grid['nb_filters']:\n",
    "        for kernel in param_grid['kernel_size']:\n",
    "            for dilations in param_grid['dilations']:\n",
    "                for dropout in param_grid['dropout_rate']:\n",
    "                    for return_seq in param_grid['return_sequences']:\n",
    "                        model = build_tcn(filters, kernel, dilations, dropout, return_seq)\n",
    "                        try:\n",
    "                            model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=0)\n",
    "                            \n",
    "                            # Walk-forward validation (predict one step at a time)\n",
    "                            predictions = []\n",
    "                            history_X = X_train.copy()\n",
    "                            history_y = y_train.copy()\n",
    "                            \n",
    "                            for i in range(len(X_val)):\n",
    "                                # Predict next step\n",
    "                                X_next = X_val[i].reshape(1, 1, -1)\n",
    "                                pred = model.predict(X_next, verbose=0).flatten()[0]\n",
    "                                predictions.append(pred)\n",
    "                                \n",
    "                            # Calculate RMSE\n",
    "                            if len(y_val) == len(predictions):\n",
    "                                rmse = np.sqrt(np.mean((y_val.flatten() - predictions) ** 2))\n",
    "                            else:\n",
    "                                print(f\"Shape mismatch: y_val ({y_val.shape}), preds ({len(predictions)})\")\n",
    "                                continue\n",
    "                            \n",
    "                            if rmse < best_rmse:\n",
    "                                best_rmse = rmse\n",
    "                                best_params = {\n",
    "                                    'nb_filters': filters,\n",
    "                                    'kernel_size': kernel,\n",
    "                                    'dilations': dilations,\n",
    "                                    'dropout_rate': dropout,\n",
    "                                    'return_sequences': return_seq\n",
    "                                }\n",
    "                        except Exception as e:\n",
    "                            print(f\"Hyperparameter set failed: {str(e)}\")\n",
    "\n",
    "    if best_params is None:\n",
    "        print(f\"❌ No valid models for {product_id}\")\n",
    "        return None\n",
    "\n",
    "    # Final model training and walk-forward prediction\n",
    "    final_model = build_tcn(**best_params)\n",
    "    final_model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=0)\n",
    "    predictions = []\n",
    "\n",
    "    # FIXED: Create DataFrame with both features and target\n",
    "    history_data = np.column_stack([X_train[:, 0, :], y_train.flatten()])\n",
    "    history = pd.DataFrame(history_data, columns=feature_set + [target_col])\n",
    "    history.index = range(len(history))\n",
    "    \n",
    "    for i in range(horizon):\n",
    "        try:\n",
    "            X_future_step = X_val[i].reshape(1, 1, -1)\n",
    "            pred = final_model.predict(X_future_step, verbose=0).flatten()[0]\n",
    "            predictions.append(pred)\n",
    "            \n",
    "            # Update training data\n",
    "            new_row = X_val[i, 0, :].tolist()\n",
    "            new_row.append(pred)\n",
    "            new_df = pd.DataFrame([new_row], columns=feature_set + [target_col])\n",
    "            history = pd.concat([history, new_df]).reset_index(drop=True)\n",
    "            \n",
    "            # Retrain on expanded window\n",
    "            rolling_window = 36 if len(history) > 36 else len(history)\n",
    "            train_subset = history.iloc[-rolling_window:]\n",
    "            \n",
    "            X_train_update = train_subset[feature_set].values.reshape(-1, 1, len(feature_set))\n",
    "            y_train_update = train_subset[target_col].values.reshape(-1, 1)\n",
    "            \n",
    "            final_model.fit(X_train_update, y_train_update, epochs=5, batch_size=16, verbose=0)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Iteration {i+1} failed: {str(e)}\")\n",
    "            predictions.append(predictions[-1] if predictions else y_train[-1][0])\n",
    "    \n",
    "    metrics = calculate_metrics(y_true=y_val.flatten(), y_pred=predictions, y_train=y_train.flatten())\n",
    "    \n",
    "    return {\n",
    "        'product_id': product_id,\n",
    "        'winsorize': winsorize,\n",
    "        'features': feature_set,\n",
    "        'metrics': metrics,\n",
    "        'method': 'walkforward',\n",
    "        'best_params': best_params,\n",
    "        'validation_predictions': predictions\n",
    "    }\n",
    "\n",
    "def find_best_tcn_config(product_id, df_train, lagged_df=None, target_col=\"Sales\", \n",
    "                            n_jobs=-1, custom_param_grids=None):\n",
    "    # Validate input data\n",
    "    if not isinstance(df_train.index, pd.DatetimeIndex):\n",
    "        raise TypeError(\"❌ df_train index is not a DatetimeIndex!\")\n",
    "    if df_train.index.isnull().any():\n",
    "        raise ValueError(\"❌ Some index values could not be parsed into datetime!\")\n",
    "    \n",
    "    results = []\n",
    "    data = df_train.copy()\n",
    "    \n",
    "    # Feature groups for original data\n",
    "    normal_features = [col for col in data.columns if col != target_col]\n",
    "    normal_feature_combinations = generate_feature_combinations(normal_features, max_features=6)  \n",
    "    normal_feature_combinations = normal_feature_combinations\n",
    "    \n",
    "    # Test original data configurations\n",
    "    for winsorize in [True, False]:\n",
    "        for features in normal_feature_combinations:\n",
    "            try:\n",
    "                print(f\"\\nTesting - Winsorize: {winsorize}, Features: {features}\")\n",
    "\n",
    "                # Use custom param grid if provided for this feature set\n",
    "                param_grid = None\n",
    "                if custom_param_grids and tuple(features) in custom_param_grids:\n",
    "                    param_grid = custom_param_grids[tuple(features)]\n",
    "\n",
    "                result = choose_parameters_tcn(product_id=product_id,df_train=data,feature_set=features,\n",
    "                    target_col=target_col,winsorize=winsorize,n_jobs=n_jobs,param_grid=param_grid)\n",
    "                \n",
    "                if result:\n",
    "                    print(f\"✅ Success - RMSE: {result['metrics']['RMSE']:.2f}\")\n",
    "                    results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Configuration failed: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    # Test lagged data configurations if available\n",
    "    if lagged_df is not None:\n",
    "        lagged_data = lagged_df.copy()\n",
    "        lag_features = [col for col in lagged_data.columns if 'lag' in col]\n",
    "        ma_features = [col for col in lagged_data.columns if '_ma_' in col]\n",
    "        macro_features = [col for col in data.columns if col != target_col]\n",
    "        \n",
    "        # Generate lag feature combinations\n",
    "        lag_feature_combinations = generate_feature_combinations(lag_features, max_features=5)\n",
    "        \n",
    "        # Create combined feature sets\n",
    "        full_combinations = []\n",
    "        for lag_combo in lag_feature_combinations:\n",
    "            full_combinations.append(lag_combo)  # Just lags\n",
    "            full_combinations.append(lag_combo + macro_features)  # Lags + macros\n",
    "            full_combinations.append(lag_combo + ma_features)  # Lags + MAs\n",
    "            full_combinations.append(lag_combo + macro_features + ma_features)  # All\n",
    "        \n",
    "        # Remove duplicates\n",
    "        seen = set()\n",
    "        unique_combinations = []\n",
    "        for combo in full_combinations:\n",
    "            combo_tuple = tuple(sorted(combo))\n",
    "            if combo_tuple not in seen:\n",
    "                seen.add(combo_tuple)\n",
    "                unique_combinations.append(combo)\n",
    "        \n",
    "        # Test all unique combinations\n",
    "        for winsorize in [True, False]:\n",
    "            for features in unique_combinations:\n",
    "                try:\n",
    "                    print(f\"\\nTesting - Lagged Features: {features}\")\n",
    "\n",
    "                    # Use custom param grid if provided for this feature set\n",
    "                    param_grid = None\n",
    "                    if custom_param_grids and tuple(features) in custom_param_grids:\n",
    "                        param_grid = custom_param_grids[tuple(features)]\n",
    "\n",
    "                    result = choose_parameters_tcn(product_id=product_id,df_train=lagged_data,feature_set=features,\n",
    "                                                       target_col=target_col,winsorize=winsorize,n_jobs=n_jobs,param_grid=param_grid)\n",
    "                    \n",
    "                    if result:\n",
    "                        print(f\"✅ Success - RMSE: {result['metrics']['RMSE']:.2f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Lagged configuration failed: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    if not results:\n",
    "        raise ValueError(f\"No valid configurations for {product_id}\")\n",
    "    \n",
    "    # Select best configuration by RMSE\n",
    "    best_config = min(results, key=lambda x: x['metrics']['RMSE'])\n",
    "    \n",
    "    print(f\"\\n✅ Best configuration for {product_id}:\")\n",
    "    print(f\"- Winsorize: {best_config['winsorize']}\")\n",
    "    print(f\"- Features: {best_config['features']}\")\n",
    "    print(f\"- Best params: {best_config['best_params']}\")\n",
    "    print(f\"- RMSE: {best_config['metrics']['RMSE']:.2f}\")\n",
    "    print(f\"- Method: {best_config.get('method', 'walkforward')}\")\n",
    "    \n",
    "    return best_config, results\n",
    "\n",
    "def process_product_parallel(product_id, custom_param_grids=None):\n",
    "    try:\n",
    "        df_train = product_dfs[product_id].rename(columns={product_id: \"Sales\"})\n",
    "        \n",
    "        # Ensure DatetimeIndex\n",
    "        if not isinstance(df_train.index, pd.DatetimeIndex):\n",
    "            df_train.index = pd.to_datetime(df_train.index, errors=\"coerce\")\n",
    "        \n",
    "        if df_train.index.isnull().any():\n",
    "            raise ValueError(\"❌ Some index values could not be parsed into datetime!\")\n",
    "\n",
    "        lagged_df = lagged_product_dfs.get(product_id, None)\n",
    "        best_config, results = find_best_tcn_config(product_id=product_id,df_train=df_train,lagged_df=lagged_df,target_col=\"Sales\", custom_param_grids=custom_param_grids)\n",
    "        \n",
    "        return best_config, results\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to process {product_id}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing product: P14\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27392_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = -2064.76, Upper = 73222.25\n",
      "✅ Success - RMSE: 14978.79\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO28380_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = -2064.76, Upper = 73222.25\n",
      "✅ Success - RMSE: 15484.21\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27756_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = -2064.76, Upper = 73222.25\n",
      "✅ Success - RMSE: 16197.10\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27392_org', 'PRO28380_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = -2064.76, Upper = 73222.25\n",
      "✅ Success - RMSE: 15385.45\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27392_org', 'PRO27756_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = -2064.76, Upper = 73222.25\n",
      "✅ Success - RMSE: 15505.44\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO28380_org', 'PRO27756_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = -2064.76, Upper = 73222.25\n",
      "✅ Success - RMSE: 15158.13\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27392_org', 'PRO28380_org', 'PRO27756_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = -2064.76, Upper = 73222.25\n",
      "✅ Success - RMSE: 15369.66\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27392_org']\n",
      "Preparing data...\n",
      "✅ Success - RMSE: 15358.70\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO28380_org']\n",
      "Preparing data...\n",
      "✅ Success - RMSE: 15123.52\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27756_org']\n",
      "Preparing data...\n",
      "✅ Success - RMSE: 16028.73\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27392_org', 'PRO28380_org']\n",
      "Preparing data...\n",
      "✅ Success - RMSE: 14890.75\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27392_org', 'PRO27756_org']\n",
      "Preparing data...\n",
      "✅ Success - RMSE: 14700.50\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO28380_org', 'PRO27756_org']\n",
      "Preparing data...\n",
      "✅ Success - RMSE: 14857.72\n",
      "\n",
      "Testing - Winsorize: False, Features: ['PRO27392_org', 'PRO28380_org', 'PRO27756_org']\n",
      "Preparing data...\n",
      "✅ Success - RMSE: 15557.06\n",
      "\n",
      "✅ Best configuration for P14:\n",
      "- Winsorize: False\n",
      "- Features: ['PRO27392_org', 'PRO27756_org']\n",
      "- Best params: {'nb_filters': 32, 'kernel_size': 3, 'dilations': [1, 2, 4, 8], 'dropout_rate': 0.1, 'return_sequences': False}\n",
      "- RMSE: 14700.50\n",
      "- Method: walkforward\n"
     ]
    }
   ],
   "source": [
    "all_product_ids = set(product_dfs.keys())\n",
    "all_results_tcn = []  # List to store all results\n",
    "best_configs_tcn = []  # List to store best configurations\n",
    "\n",
    "for product_id in all_product_ids:\n",
    "    print(f\"Processing product: {product_id}\")\n",
    "    \n",
    "    try:\n",
    "        best_config_tcn, results_tcn = process_product_parallel(product_id, custom_param_grids=None)\n",
    "        \n",
    "        if best_config_tcn is not None:\n",
    "            best_configs_tcn.append(best_config_tcn)  # Store best config\n",
    "        else:\n",
    "            print(f\"Warning: No best config returned for product {product_id}\")\n",
    "        \n",
    "        if results_tcn is not None:\n",
    "            all_results_tcn.extend(results_tcn)  # Store results\n",
    "        else:\n",
    "            print(f\"Warning: No results returned for product {product_id}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing product {product_id}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"background-color:#000027; padding:5px; border-radius:5px;\">**3.4. Neural Prophet**</span> <a id='neural-prophet'></a>  \n",
    "\n",
    "_NeuralProphet doesn't natively support sklearn's GridSearchCV, so we implement our own grid search._\n",
    "\n",
    "Click [here](#table-of-contents) ⬆️ to return to the Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_parameters_timegpt(product_id, df_train, feature_set, target_col=\"Sales\", \n",
    "                            nixtla_client=None, winsorize=False, horizon=7):\n",
    "    \"\"\"Optimized TimeGPT forecasting with resource management\"\"\"\n",
    "    \n",
    "    # --- Resource Management ---\n",
    "    import os\n",
    "    os.environ['OMP_NUM_THREADS'] = '1'  # Limit CPU threads\n",
    "    os.environ['MKL_NUM_THREADS'] = '1'\n",
    "    \n",
    "    # --- Input Validation ---\n",
    "    if nixtla_client is None:\n",
    "        raise ValueError(\"NixtlaClient instance is required.\")\n",
    "    \n",
    "    if len(df_train) < 12:\n",
    "        print(f\"⚠️ Skipping {product_id} - only {len(df_train)} observations\")\n",
    "        return None\n",
    "    \n",
    "    # --- Data Preparation ---\n",
    "    print('Preparing data...')\n",
    "    try:\n",
    "        X_train, X_val, y_train, y_val = prepare_time_series_data(\n",
    "            df_train, feature_set, target_col, horizon, winsorize)\n",
    "        \n",
    "        # Handle missing values\n",
    "        if X_train.isnull().any().any() or X_val.isnull().any().any():\n",
    "            print(\"⚠️ Missing values detected - filling with zeros\")\n",
    "            X_train = X_train.fillna(0)\n",
    "            X_val = X_val.fillna(0)\n",
    "            y_train = y_train.fillna(0)\n",
    "            y_val = y_val.fillna(0)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Data preparation failed: {str(e)}\")\n",
    "        return None\n",
    " \n",
    "    # --- Feature Processing ---\n",
    "    hist_exog = [f for f in feature_set if '_lag_' in f or '_ma_' in f] if feature_set else []\n",
    "    fut_exog = [f for f in feature_set if f not in hist_exog] if feature_set else []\n",
    "\n",
    "    # --- Future Features ---\n",
    "    X_future = None\n",
    "    if fut_exog:\n",
    "        X_future = X_val[fut_exog].copy().fillna(0)  # Ensure no NAs\n",
    "        if not X_future.empty:  \n",
    "            X_future.insert(0, 'month_year', X_val.index)\n",
    "    \n",
    "    # --- Simple Forecast (small dataset) ---\n",
    "    if len(X_train) < 36:\n",
    "        print(f\"Using simple forecast ({len(X_train)} < 36 obs)\")\n",
    "        try:\n",
    "            history = df_train[[target_col] + feature_set].copy().fillna(0)\n",
    "            \n",
    "            forecast = nixtla_client.forecast(\n",
    "                df=history.reset_index(),\n",
    "                time_col=\"month_year\", \n",
    "                target_col=target_col, \n",
    "                h=horizon,\n",
    "                X_df=X_future,\n",
    "                hist_exog_list=hist_exog if hist_exog else None\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'product_id': product_id,\n",
    "                'winsorize': winsorize,\n",
    "                'features': feature_set,\n",
    "                'metrics': calculate_metrics(\n",
    "                    y_true=y_val,\n",
    "                    y_pred=forecast[\"TimeGPT\"],\n",
    "                    y_train=history[target_col],\n",
    "                    y_train_pred=[forecast[\"TimeGPT\"].iloc[0]] * len(history)\n",
    "                ),\n",
    "                'method': 'simple',\n",
    "                'validation_predictions': forecast[\"TimeGPT\"].tolist()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Simple forecast failed: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    # --- Walk-Forward (large dataset) ---\n",
    "    print(f\"Using walk-forward ({len(X_train)} ≥ 36 obs)\")\n",
    "    predictions = []\n",
    "    history = X_train.copy()\n",
    "    history[target_col] = y_train\n",
    "    history = history.fillna(0).reset_index()\n",
    "    \n",
    "    try:\n",
    "        for i in range(horizon):\n",
    "            X_future_step = None\n",
    "            if fut_exog:\n",
    "                X_future_step = X_val.iloc[[i]][fut_exog].copy().fillna(0)\n",
    "                X_future_step.insert(0, 'month_year', X_val.index[i])\n",
    "\n",
    "            forecast = nixtla_client.forecast(\n",
    "                df=history,\n",
    "                time_col='month_year',\n",
    "                target_col=target_col,\n",
    "                h=1,\n",
    "                X_df=X_future_step,\n",
    "                hist_exog_list=hist_exog if hist_exog else None\n",
    "            )\n",
    "            \n",
    "            pred = forecast[\"TimeGPT\"].iloc[0]\n",
    "            predictions.append(pred)\n",
    "            \n",
    "            # Update history efficiently\n",
    "            new_row = X_val.iloc[i].copy().fillna(0)\n",
    "            new_row['month_year'] = X_val.index[i]\n",
    "            new_row[target_col] = pred\n",
    "            history = pd.concat([history, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            \n",
    "            # Early stopping check\n",
    "            if i % 5 == 0 and i > 0:  # Check every 5 iterations\n",
    "                print(f\"Progress: {i+1}/{horizon} - Current RMSE: {np.sqrt(np.mean((y_val[:i+1] - predictions)**2):.2f}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Forecast failed at step {i+1}: {str(e)}\")\n",
    "        if not predictions:  # If no predictions succeeded\n",
    "            return None\n",
    "    \n",
    "    metrics = calculate_metrics(y_true=val_df['y'].values,y_pred=best_predictions[:len(val_df)],y_train=train_df['y'].values,y_train_pred=train_predictions)\n",
    "    \n",
    "    return {'product_id': product_id,'winsorize': winsorize,'features': feature_set,'metrics': metrics,'method': 'walkforward','best_params': best_params,'validation_predictions': predictions}\n",
    "\n",
    "def find_best_neuralprophet_config(product_id, df_train, lagged_df=None, target_col=\"Sales\", \n",
    "                                 n_jobs=-1, custom_param_grids=None):\n",
    "    \"\"\"Find best NeuralProphet configuration for a product\"\"\"\n",
    "    \n",
    "    # Validate input data\n",
    "    if not isinstance(df_train.index, pd.DatetimeIndex):\n",
    "        raise TypeError(\"❌ df_train index is not a DatetimeIndex!\")\n",
    "    if df_train.index.isnull().any():\n",
    "        raise ValueError(\"❌ Some index values could not be parsed into datetime!\")\n",
    "    \n",
    "    results = []\n",
    "    data = df_train.copy()\n",
    "    \n",
    "    # Feature groups for original data\n",
    "    normal_features = [col for col in data.columns if col != target_col]\n",
    "    normal_feature_combinations = generate_feature_combinations(normal_features, max_features=6)  \n",
    "    \n",
    "    # Test original data configurations\n",
    "    for winsorize in [True, False]:\n",
    "        for features in normal_feature_combinations:\n",
    "            try:\n",
    "                print(f\"\\nTesting - Winsorize: {winsorize}, Features: {features}\")\n",
    "\n",
    "                # Use custom param grid if provided for this feature set\n",
    "                param_grid = None\n",
    "                if custom_param_grids and tuple(features) in custom_param_grids:\n",
    "                    param_grid = custom_param_grids[tuple(features)]\n",
    "\n",
    "                result = choose_parameters_neuralprophet(product_id=product_id, df_train=data,feature_set=features, target_col=target_col,\n",
    "                                                         winsorize=winsorize, n_jobs=n_jobs, param_grid=param_grid)\n",
    "                \n",
    "                if result:\n",
    "                    print(f\"✅ Success - RMSE: {result['metrics']['RMSE']:.2f}\")\n",
    "                    results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Configuration failed: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    # Test lagged data configurations if available\n",
    "    if lagged_df is not None:\n",
    "        lagged_data = lagged_df.copy()\n",
    "        lag_features = [col for col in lagged_data.columns if 'lag' in col]\n",
    "        ma_features = [col for col in lagged_data.columns if '_ma_' in col]\n",
    "        macro_features = [col for col in data.columns if col != target_col]\n",
    "        \n",
    "        # Generate lag feature combinations\n",
    "        lag_feature_combinations = generate_feature_combinations(lag_features, max_features=5)\n",
    "        \n",
    "        # Create combined feature sets\n",
    "        full_combinations = []\n",
    "        for lag_combo in lag_feature_combinations:\n",
    "            full_combinations.append(lag_combo)  # Just lags\n",
    "            full_combinations.append(lag_combo + macro_features)  # Lags + macros\n",
    "            full_combinations.append(lag_combo + ma_features)  # Lags + MAs\n",
    "            full_combinations.append(lag_combo + macro_features + ma_features)  # All\n",
    "        \n",
    "        # Remove duplicates\n",
    "        seen = set()\n",
    "        unique_combinations = []\n",
    "        for combo in full_combinations:\n",
    "            combo_tuple = tuple(sorted(combo))\n",
    "            if combo_tuple not in seen:\n",
    "                seen.add(combo_tuple)\n",
    "                unique_combinations.append(combo)\n",
    "        \n",
    "        # Test all unique combinations\n",
    "        for winsorize in [True, False]:\n",
    "            for features in unique_combinations:\n",
    "                try:\n",
    "                    print(f\"\\nTesting - Lagged Features: {features}\")\n",
    "\n",
    "                    # Use custom param grid if provided for this feature set\n",
    "                    param_grid = None\n",
    "                    if custom_param_grids and tuple(features) in custom_param_grids:\n",
    "                        param_grid = custom_param_grids[tuple(features)]\n",
    "\n",
    "                    result = choose_parameters_neuralprophet(product_id=product_id, df_train=lagged_data, feature_set=features, target_col=target_col,\n",
    "                                                             winsorize=winsorize, n_jobs=n_jobs, param_grid=param_grid)\n",
    "                    \n",
    "                    if result:\n",
    "                        print(f\"✅ Success - RMSE: {result['metrics']['RMSE']:.2f}\")\n",
    "                        results.append(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Lagged configuration failed: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    if not results:\n",
    "        raise ValueError(f\"No valid configurations for {product_id}\")\n",
    "    \n",
    "    # Select best configuration by RMSE\n",
    "    best_config = min(results, key=lambda x: x['metrics']['RMSE'])\n",
    "    \n",
    "    print(f\"\\n✅ Best configuration for {product_id}:\")\n",
    "    print(f\"- Winsorize: {best_config['winsorize']}\")\n",
    "    print(f\"- Features: {best_config['features']}\")\n",
    "    print(f\"- Best params: {best_config['best_params']}\")\n",
    "    print(f\"- RMSE: {best_config['metrics']['RMSE']:.2f}\")\n",
    "    print(f\"- Method: {best_config.get('method', 'walkforward')}\")\n",
    "    \n",
    "    return best_config, results\n",
    "\n",
    "def process_product_neuralprophet(product_id, custom_param_grids=None):\n",
    "    \"\"\"Parallel processing wrapper for NeuralProphet\"\"\"\n",
    "    try:\n",
    "        df_train = product_dfs[product_id].rename(columns={product_id: \"Sales\"})\n",
    "        \n",
    "        # Ensure DatetimeIndex\n",
    "        if not isinstance(df_train.index, pd.DatetimeIndex):\n",
    "            df_train.index = pd.to_datetime(df_train.index, errors=\"coerce\")\n",
    "        \n",
    "        if df_train.index.isnull().any():\n",
    "            raise ValueError(\"❌ Some index values could not be parsed into datetime!\")\n",
    "\n",
    "        lagged_df = lagged_product_dfs.get(product_id, None)\n",
    "        \n",
    "        best_config, results = find_best_neuralprophet_config(\n",
    "            product_id=product_id,\n",
    "            df_train=df_train,\n",
    "            lagged_df=lagged_df,\n",
    "            target_col=\"Sales\",\n",
    "            custom_param_grids=custom_param_grids\n",
    "        )\n",
    "        \n",
    "        return best_config, results\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to process {product_id}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing product: P14\n",
      "\n",
      "Testing - Winsorize: True, Features: ['PRO27392_org']\n",
      "Preparing data...\n",
      "Sales: Winsorized Bounds -> Lower = -2064.76, Upper = 73222.25\n",
      "Testing 288 parameter combinations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 30, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 30, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 30, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 7, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 30, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 7, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 30, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 14, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 30, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 14, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 30, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 30, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 30, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 7, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 30, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 7, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 30, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 14, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 30, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 14, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 50, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 50, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 50, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 7, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 50, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 7, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 50, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 14, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 50, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 14, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 50, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 50, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 50, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 7, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 50, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 7, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 50, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 14, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.8, 'epochs': 50, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 14, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 30, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 30, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 30, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 7, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 30, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 7, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 30, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 14, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 30, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 14, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 30, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 30, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 30, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 7, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 30, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 7, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 30, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 14, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 30, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 14, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 50, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 50, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 50, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 7, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 50, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 7, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 50, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 14, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 50, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 14, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (7)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 50, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 50, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 50, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 7, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (14)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 50, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 7, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 50, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 14, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n",
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 16, 'changepoints_range': 0.95, 'epochs': 50, 'learning_rate': 0.001, 'n_forecasts': 7, 'n_lags': 14, 'seasonality_reg': 1.0}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO:NP.config:Note: Fourier-based seasonality regularization is experimental.\n",
      "INFO - (NP.forecaster.add_lagged_regressor) - n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "INFO:NP.forecaster:n_lags = 'auto', number of lags for regressor is set to Autoregression number of lags (3)\n",
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING:NP.forecaster:When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency MS corresponds to [97.222]% of the data.\n",
      "INFO:NP.df_utils:Major frequency MS corresponds to [97.222]% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\catar\\anaconda3\\Lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (NP.df_utils._infer_frequency) - Defined frequency D is different than major frequency MS\n",
      "WARNING:NP.df_utils:Defined frequency D is different than major frequency MS\n",
      "INFO - (NP.data.processing._handle_missing_data) - Added 1031 missing dates.\n",
      "INFO:NP.data.processing:Added 1031 missing dates.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column y were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column y were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column y were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column y were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column y. 7 NA remain after auto-imputation. \n",
      "WARNING - (NP.data.processing._handle_missing_data) - 1031 missing values in column PRO27392_org were detected in total. \n",
      "WARNING:NP.data.processing:1031 missing values in column PRO27392_org were detected in total. \n",
      "INFO - (NP.data.processing._handle_missing_data) - 1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "INFO:NP.data.processing:1024 NaN values in column PRO27392_org were auto-imputed.\n",
      "WARNING - (NP.data.processing._handle_missing_data) - More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "WARNING:NP.data.processing:More than 30 consecutive                             missing values encountered in column PRO27392_org. 7 NA remain after auto-imputation. \n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO:NP.config:Setting normalization to global as only one dataframe provided for training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed with params {'ar_reg': 0.1, 'batch_size': 32, 'changepoints_range': 0.8, 'epochs': 30, 'learning_rate': 0.01, 'n_forecasts': 7, 'n_lags': 3, 'seasonality_reg': 0.1}: Inputs/targets with missing values detected. Please either adjust imputation parameters, or set 'drop_missing' to True to drop those samples.\n"
     ]
    }
   ],
   "source": [
    "all_product_ids = {'P14'}\n",
    "#set(product_dfs.keys())\n",
    "\n",
    "all_results_neuralp = []  # List to store all results\n",
    "best_configs_neuralp = []  # List to store best configurations\n",
    "\n",
    "for product_id in all_product_ids:\n",
    "    print(f\"Processing product: {product_id}\")\n",
    "    \n",
    "    try:\n",
    "        best_config_neuralp, results_neuralp = process_product_neuralprophet(product_id)\n",
    "        \n",
    "        if best_config_neuralp is not None:\n",
    "            best_configs_neuralp.append(best_config_neuralp)  # Store best config\n",
    "        else:\n",
    "            print(f\"Warning: No best config returned for product {product_id}\")\n",
    "        \n",
    "        if results_neuralp is not None:\n",
    "            all_results_neuralp.extend(results_neuralp)  # Store results\n",
    "        else:\n",
    "            print(f\"Warning: No results returned for product {product_id}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing product {product_id}: {str(e)}\")\n",
    "\n",
    "df_all_results = convert_results_to_df(all_results_neuralp) if all_results_neuralp else pd.DataFrame()\n",
    "df_best_configs = pd.DataFrame(best_configs_neuralp) if best_configs_neuralp else pd.DataFrame()\n",
    "\n",
    "df_all_results.to_csv(\"timegpt_best_configs.csv\", index=False)\n",
    "df_best_configs.to_csv(\"timegpt_best_configs_details.csv\", index=False)\n",
    "\n",
    "print(\"Processing completed! Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"background-color:#000027; padding:5px; border-radius:5px;\">**3.5. ARIMA**</span> <a id='arima'></a>  \n",
    "\n",
    "Click [here](#table-of-contents) ⬆️ to return to the Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_p1_lags' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[20], line 8\u001b[0m\n",
      "\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score, mean_absolute_percentage_error\n",
      "\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Ensure time-series data is sorted and complete\u001b[39;00m\n",
      "\u001b[1;32m----> 8\u001b[0m df_p1_lags \u001b[38;5;241m=\u001b[39m df_p1_lags\u001b[38;5;241m.\u001b[39msort_index()\n",
      "\u001b[0;32m      9\u001b[0m df_p1_lags \u001b[38;5;241m=\u001b[39m df_p1_lags\u001b[38;5;241m.\u001b[39masfreq(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39minterpolate()  \u001b[38;5;66;03m# Fill missing months\u001b[39;00m\n",
      "\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Fit Auto ARIMA Model (Using all data initially)\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_p1_lags' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "# Ensure time-series data is sorted and complete\n",
    "df_p1_lags = df_p1_lags.sort_index()\n",
    "df_p1_lags = df_p1_lags.asfreq('MS').interpolate()  # Fill missing months\n",
    "\n",
    "# Fit Auto ARIMA Model (Using all data initially)\n",
    "auto_model = auto_arima(\n",
    "    df_p1_lags['P1'].dropna(),  \n",
    "    exogenous=df_p1_lags[['P1_lag_1', 'P1_lag_2', 'P1_lag_3']].dropna(),  \n",
    "    seasonal=False, \n",
    "    trace=True,\n",
    "    stepwise=True,\n",
    "    suppress_warnings=True,\n",
    "    error_action='ignore',\n",
    "    max_p=5, \n",
    "    max_q=5,\n",
    "    d=None,  # Let ADF test decide differencing\n",
    "    test='adf',  \n",
    "    scoring='mse'\n",
    ")\n",
    "print(auto_model.summary())\n",
    "\n",
    "# Walk-Forward Forecasting with Expanding Window\n",
    "def walk_forward_forecast(model, df, horizon=10, initial_train_size=33):\n",
    "    \"\"\"\n",
    "    Walk-forward validation using an expanding window approach.\n",
    "    Predicts 'horizon' steps ahead at each iteration.\n",
    "    \"\"\"\n",
    "    predictions, true_values, lower_bounds, upper_bounds = [], [], [], []\n",
    "\n",
    "    for i in range(len(df) - initial_train_size - horizon + 1):\n",
    "        train = df.iloc[: i + initial_train_size]  # Expanding training set\n",
    "        test = df.iloc[i + initial_train_size : i + initial_train_size + horizon]\n",
    "\n",
    "        model.fit(train['P1'])\n",
    "        pred, conf_int = model.predict(n_periods=len(test), return_conf_int=True)\n",
    "\n",
    "        if len(pred) == len(test):  # Ensure consistent shape\n",
    "            predictions.append(pred)\n",
    "            true_values.append(test['P1'].values)\n",
    "            lower_bounds.append(conf_int[:, 0])\n",
    "            upper_bounds.append(conf_int[:, 1])\n",
    "\n",
    "    return np.array(true_values), np.array(predictions), np.array(lower_bounds), np.array(upper_bounds)\n",
    "\n",
    "# Perform Walk-Forward Forecasting\n",
    "true_values, predictions, lower_bounds, upper_bounds = walk_forward_forecast(auto_model, df_p1_lags, horizon=10)\n",
    "\n",
    "# Compute Errors\n",
    "def print_error(true, pred):\n",
    "    RMSE = mean_squared_error(true.flatten(), pred.flatten(), squared=False)\n",
    "    R2 = r2_score(true.flatten(), pred.flatten())\n",
    "    MAPE = mean_absolute_percentage_error(true.flatten(), pred.flatten())\n",
    "    print(\"RMSE:\", RMSE)\n",
    "    print(\"MAPE:\", round(MAPE * 100, 2), \"%\")\n",
    "    print(\"R2:\", R2)\n",
    "\n",
    "print_error(true_values, predictions)\n",
    "\n",
    "# ✅ Plot Full Dataset + Predictions + Confidence Intervals\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the real data (Training + Test)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_p1_lags.index,\n",
    "    y=df_p1_lags['P1'],\n",
    "    mode='lines',\n",
    "    name='Real Data',\n",
    "    line=dict(color='black', width=2)\n",
    "))\n",
    "\n",
    "# Add predictions over time\n",
    "for i in range(len(predictions)):\n",
    "    forecast_index = df_p1_lags.index[i + 33 : i + 33 + 10]\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=forecast_index, \n",
    "        y=predictions[i],\n",
    "        mode='lines',\n",
    "        name=f'Prediction {i+1}',\n",
    "        line=dict(dash='dash', width=1, color='blue')\n",
    "    ))\n",
    "\n",
    "    # Add confidence interval shading\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(forecast_index) + list(forecast_index[::-1]),\n",
    "        y=list(upper_bounds[i]) + list(lower_bounds[i][::-1]),\n",
    "        fill='toself',\n",
    "        fillcolor='rgba(0,255,0,0.2)',\n",
    "        line=dict(color='rgba(255,255,255,0)'),\n",
    "        name='Confidence Interval',\n",
    "        showlegend=(i == 0)\n",
    "    ))\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title=\"Walk-Forward Forecasting (10-month prediction horizon)\",\n",
    "    xaxis_title=\"Months\",\n",
    "    yaxis_title=\"P1 Values\",\n",
    "    legend_title=\"Legend\",\n",
    "    template=\"plotly\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "from pmdarima.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def choose_parameters_arima(product_id, df_train, target_col='Sales', winsorize=False, feature_set=None, horizon=10, seasonal=False, stationary=False):\n",
    "    \"\"\"\n",
    "    Optimized function to prepare data, run auto_arima, and evaluate performance.\n",
    "    \"\"\"\n",
    "    # Common Preprocessing\n",
    "    X_train, X_val, y_train, y_val = prepare_time_series_data(df_train, product_id, target_col, feature_set, horizon, winsorize)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    y_train, y_val = y_train.values, y_val.values\n",
    "    X_train, X_val = X_train.values if not X_train.empty else None, X_val.values if not X_val.empty else None\n",
    "\n",
    "    # Auto ARIMA Model\n",
    "    model = auto_arima(y=y_train, X=X_train, stationary=stationary, seasonal=seasonal, suppress_warnings=True, stepwise=True, error_action='ignore', trace=False)\n",
    "\n",
    "    # Walk-forward Validation\n",
    "    predictions = []\n",
    "    for i in range(len(y_val)):\n",
    "        new_x = X_val[i].reshape(1, -1) if X_val is not None else None\n",
    "        model.update([y_val[i]], X=new_x)\n",
    "        pred = model.predict(n_periods=1, X=new_x)[0] if new_x is not None else model.predict(n_periods=1)[0]\n",
    "        predictions.append(pred)\n",
    "\n",
    "    # Evaluate Model\n",
    "    metrics = calculate_metrics(y_val, predictions)\n",
    "\n",
    "    return {\n",
    "        'product_id': product_id,\n",
    "        'winsorize': winsorize,\n",
    "        'features': feature_set if feature_set else 'all',\n",
    "        'best_params': {'order': model.order, 'seasonal_order': model.seasonal_order if seasonal else None, 'aic': model.aic(), 'bic': model.bic()},\n",
    "        'metrics': metrics,\n",
    "        'model': model}\n",
    "\n",
    "\n",
    "def find_best_arima_config(product_id, df_train, target_col='Sales'):\n",
    "    \"\"\"\n",
    "    Find optimal ARIMA configuration matching original testing approach\n",
    "    \"\"\"\n",
    "    data = df_train[product_id].copy()\n",
    "    available_features = [col for col in data.columns if col != target_col]\n",
    "    \n",
    "    # Generate feature combinations (max 3 for ARIMAX stability)\n",
    "    feature_combinations = generate_feature_combinations(available_features, max_features=3)\n",
    "    \n",
    "    # Test all configurations - consistent with original approach\n",
    "    results = []\n",
    "    for winsorize in [True, False]:\n",
    "        for features in feature_combinations:\n",
    "            for seasonal in [False, True]:  # Test both seasonal and non-seasonal\n",
    "                print(f\"\\nTesting config - Winsorize: {winsorize}, Features: {features}, Seasonal: {seasonal}\")\n",
    "                \n",
    "                result = choose_parameters_arima(\n",
    "                    product_id=product_id,\n",
    "                    df_train=df_train,\n",
    "                    target_col=target_col,\n",
    "                    winsorize=winsorize,\n",
    "                    feature_set=features,\n",
    "                    seasonal=seasonal\n",
    "                )\n",
    "                results.append(result)\n",
    "    \n",
    "    # Find best configuration (lowest RMSE)\n",
    "    best_config = min(results, key=lambda x: x['metrics']['RMSE'])\n",
    "\n",
    "    print(f\"\\n✅ Best configuration for product {product_id}:\")\n",
    "    print(f\"- Winsorize: {best_config['winsorize']}\")\n",
    "    print(f\"- Features: {best_config['features']}\")\n",
    "    print(f\"- Seasonal: {best_config['best_params']['seasonal_order'] is not None}\")\n",
    "    print(f\"- Order (p,d,q): {best_config['best_params']['order']}\")\n",
    "    print(f\"- RMSE: {best_config['metrics']['RMSE']:.2f}\")\n",
    "    print(f\"- R²: {best_config['metrics']['R2']:.4f}\")\n",
    "    \n",
    "    return best_config\n",
    "\n",
    "def process_product_arima(product_id):\n",
    "    \"\"\"\n",
    "    Consistent wrapper function matching original format\n",
    "    \"\"\"\n",
    "    best_config = find_best_arima_config(\n",
    "        product_id=product_id,\n",
    "        df_train=df_train,\n",
    "        target_col='Sales'\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'Product_ID': product_id,\n",
    "        'Model': 'ARIMA',\n",
    "        'Winsorize': best_config['winsorize'],\n",
    "        'Features': best_config['features'],\n",
    "        'Order': best_config['best_params']['order'],\n",
    "        'Seasonal_Order': best_config['best_params']['seasonal_order'],\n",
    "        'RMSE': best_config['metrics']['RMSE'],\n",
    "        'R²': best_config['metrics']['R2']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction for he Macro Features used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to classify variables\n",
    "def classify_variable(series):\n",
    "    \"\"\"Classifies variable based on normality and stationarity tests.\"\"\"\n",
    "    \n",
    "    # Remove NaN values for testing\n",
    "    clean_series = series.dropna()\n",
    "\n",
    "    # Check for normality\n",
    "    if len(clean_series) > 3:\n",
    "        stat, p_value = shapiro(clean_series)\n",
    "        is_normal = p_value > 0.05  # p-value > 0.05 means normal\n",
    "    else:\n",
    "        is_normal = False  # Not enough data to test normality\n",
    "\n",
    "    # Check for stationarity\n",
    "    if len(clean_series) > 3:\n",
    "        adf_stat, adf_p_value, _, _, _, _ = adfuller(clean_series)\n",
    "        is_stationary = adf_p_value < 0.05  # p-value < 0.05 means stationary\n",
    "    else:\n",
    "        is_stationary = False  # Not enough data\n",
    "\n",
    "    return is_normal, is_stationary\n",
    "\n",
    "# Function to automatically fill missing values\n",
    "def auto_impute_missing_values(df_train, df_test):\n",
    "    \"\"\"Automatically selects the best imputation method for each missing variable.\"\"\"\n",
    "    \n",
    "    # Identify missing columns in test set\n",
    "    missing_columns = df_test.columns[df_test.isnull().any()]\n",
    "    \n",
    "    # Iterate through missing columns\n",
    "    for col in missing_columns:\n",
    "        print(f\"Processing: {col}\")\n",
    "\n",
    "        series = df_train[col]  # Use train data for imputation\n",
    "        is_normal, is_stationary = classify_variable(series)\n",
    "\n",
    "        if is_normal:\n",
    "            # Case 1: Normally distributed → Sample from normal distribution\n",
    "            print(f\" - {col} is normal → Using Mean & Std Sampling\")\n",
    "            mean_value, std_value = series.mean(), series.std()\n",
    "            num_missing = df_test[col].isnull().sum()\n",
    "            predictions = norm.rvs(loc=mean_value, scale=std_value, size=num_missing)\n",
    "        \n",
    "        elif is_stationary:\n",
    "            # Case 2: Stationary but non-normal → Simple Exponential Smoothing\n",
    "            print(f\" - {col} is stationary → Using Simple Exponential Smoothing\")\n",
    "            model = SimpleExpSmoothing(series.dropna()).fit()\n",
    "            predictions = model.forecast(steps=df_test[col].isnull().sum())\n",
    "\n",
    "        elif not is_stationary:\n",
    "            # Case 3: Non-Stationary → ARIMA\n",
    "            print(f\" - {col} is non-stationary → Using ARIMA\")\n",
    "            model = ARIMA(series.dropna(), order=(1, 1, 1))  # (p,d,q) chosen based on domain knowledge\n",
    "            fitted_model = model.fit()\n",
    "            predictions = fitted_model.forecast(steps=df_test[col].isnull().sum())\n",
    "\n",
    "        else:\n",
    "            # Case 4: If nothing works → Use XGBoost Regression\n",
    "            print(f\" - {col} is complex → Using XGBoost Regression\")\n",
    "            train_data = df_train.dropna(subset=[col])  # Drop missing values for training\n",
    "            X_train = train_data.drop(columns=[col])  # Exclude target column\n",
    "            y_train = train_data[col]  # Target column\n",
    "\n",
    "            X_test = df_test.loc[df_test[col].isnull(), X_train.columns]  # Only missing values\n",
    "\n",
    "            model = XGBRegressor(n_estimators=100, learning_rate=0.1)\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X_test)\n",
    "\n",
    "        # Assign predictions\n",
    "        missing_indexes = df_test[df_test[col].isnull()].index\n",
    "        df_test.loc[missing_indexes, col] = predictions\n",
    "\n",
    "    return df_test\n",
    "\n",
    "# Example usage\n",
    "df_train = remerged_data[1]  # Use remerged train data\n",
    "df_test = test_1.copy()  # Copy test set\n",
    "\n",
    "# Apply automatic imputation\n",
    "df_test_filled = auto_impute_missing_values(df_train, df_test)\n",
    "\n",
    "# Check results\n",
    "print(df_test_filled.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
