{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"header.png\" width=\"100%\">\n",
    "</p>\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <strong style=\"display: block; margin-bottom: 10px;\">Group P</strong> \n",
    "    <table style=\"margin: 0 auto; border-collapse: collapse; border: 1px solid black;\">\n",
    "        <tr>\n",
    "            <th style=\"border: 1px solid white; padding: 8px;\">Name</th>\n",
    "            <th style=\"border: 1px solid white; padding: 8px;\">Student ID</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">Beatriz Monteiro</td>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">20240591</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">Catarina Nunes</td>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">20230083</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">Margarida Raposo</td>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">20241020</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">Teresa Menezes</td>\n",
    "            <td style=\"border: 1px solid white; padding: 8px;\">20240333</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîó Table of Contents <a id='table-of-contents'></a>\n",
    "1. [Introduction](#introduction)  \n",
    "2. [Macro's Prediction](#business-understanding)  \n",
    "3. [Conclusion](#conclusion)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy.stats import norm\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import shap\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded P11 from product_dfs_folder/P11.pkl\n",
      "Loaded P13 from product_dfs_folder/P13.pkl\n",
      "Loaded P12 from product_dfs_folder/P12.pkl\n",
      "Loaded P16 from product_dfs_folder/P16.pkl\n",
      "Loaded P14 from product_dfs_folder/P14.pkl\n",
      "Loaded P8 from product_dfs_folder/P8.pkl\n",
      "Loaded P9 from product_dfs_folder/P9.pkl\n",
      "Loaded Sales_CPI from product_dfs_folder/Sales_CPI.pkl\n",
      "Loaded P1 from product_dfs_folder/P1.pkl\n",
      "Loaded P3 from product_dfs_folder/P3.pkl\n",
      "Loaded P6 from product_dfs_folder/P6.pkl\n",
      "Loaded P4 from product_dfs_folder/P4.pkl\n",
      "Loaded P5 from product_dfs_folder/P5.pkl\n",
      "Loaded P36 from product_dfs_folder/P36.pkl\n",
      "Loaded P20 from product_dfs_folder/P20.pkl\n",
      "Loaded P11 from lagged_product_dfs_folder/P11.pkl\n",
      "Loaded P13 from lagged_product_dfs_folder/P13.pkl\n",
      "Loaded P12 from lagged_product_dfs_folder/P12.pkl\n",
      "Loaded P16 from lagged_product_dfs_folder/P16.pkl\n",
      "Loaded P8 from lagged_product_dfs_folder/P8.pkl\n",
      "Loaded P9 from lagged_product_dfs_folder/P9.pkl\n",
      "Loaded P1 from lagged_product_dfs_folder/P1.pkl\n",
      "Loaded P3 from lagged_product_dfs_folder/P3.pkl\n",
      "Loaded P4 from lagged_product_dfs_folder/P4.pkl\n",
      "Loaded P5 from lagged_product_dfs_folder/P5.pkl\n",
      "Loaded P36 from lagged_product_dfs_folder/P36.pkl\n",
      "Loaded P20 from lagged_product_dfs_folder/P20.pkl\n"
     ]
    }
   ],
   "source": [
    "def load_dfs_from_folder(folder_path):\n",
    "    \"\"\"Loads DataFrames from files in a specified folder and returns a dictionary.\"\"\"\n",
    "    dfs = {}\n",
    "    # List all files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".pkl\"):\n",
    "            key = file_name.replace(\".pkl\", \"\")  # Extract key from the file name\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            \n",
    "            # Load the dataframe from the pickle file\n",
    "            with open(file_path, 'rb') as f:\n",
    "                dfs[key] = pickle.load(f)\n",
    "            print(f\"Loaded {key} from {file_path}\")\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "# Load both product_dfs and lagged_product_dfs from their respective folders\n",
    "product_dfs = load_dfs_from_folder(\"product_dfs_folder\")\n",
    "lagged_product_dfs = load_dfs_from_folder(\"lagged_product_dfs_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product_id in product_dfs.keys():\n",
    "    product_dfs[product_id] = product_dfs[product_id].rename(columns={product_id: \"Sales\"})\n",
    "\n",
    "for product_id in lagged_product_dfs.keys():\n",
    "    lagged_product_dfs[product_id] = lagged_product_dfs[product_id].rename(columns={product_id: \"Sales\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>MAB_ELE_SHP840</th>\n",
       "      <th>PRI27276_org</th>\n",
       "      <th>PRO27826_org</th>\n",
       "      <th>MAB_ELE_PRO276</th>\n",
       "      <th>MAB_ELE_SHP1100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>3.577403e+07</td>\n",
       "      <td>127.808839</td>\n",
       "      <td>109.119614</td>\n",
       "      <td>118.670791</td>\n",
       "      <td>124.227879</td>\n",
       "      <td>130.989253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-01</th>\n",
       "      <td>5.063649e+06</td>\n",
       "      <td>117.675874</td>\n",
       "      <td>109.224838</td>\n",
       "      <td>120.467019</td>\n",
       "      <td>127.404132</td>\n",
       "      <td>132.934130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01</th>\n",
       "      <td>3.732127e+07</td>\n",
       "      <td>123.280134</td>\n",
       "      <td>109.330063</td>\n",
       "      <td>105.378705</td>\n",
       "      <td>120.518565</td>\n",
       "      <td>131.261348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>2.709040e+07</td>\n",
       "      <td>111.043755</td>\n",
       "      <td>109.750961</td>\n",
       "      <td>107.174933</td>\n",
       "      <td>104.776326</td>\n",
       "      <td>113.057565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01</th>\n",
       "      <td>3.413209e+07</td>\n",
       "      <td>116.736921</td>\n",
       "      <td>109.856194</td>\n",
       "      <td>110.647640</td>\n",
       "      <td>109.597012</td>\n",
       "      <td>117.704727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Sales  MAB_ELE_SHP840  PRI27276_org  PRO27826_org  \\\n",
       "month_year                                                             \n",
       "2018-10-01  3.577403e+07      127.808839    109.119614    118.670791   \n",
       "2018-11-01  5.063649e+06      117.675874    109.224838    120.467019   \n",
       "2018-12-01  3.732127e+07      123.280134    109.330063    105.378705   \n",
       "2019-01-01  2.709040e+07      111.043755    109.750961    107.174933   \n",
       "2019-02-01  3.413209e+07      116.736921    109.856194    110.647640   \n",
       "\n",
       "            MAB_ELE_PRO276  MAB_ELE_SHP1100  \n",
       "month_year                                   \n",
       "2018-10-01      124.227879       130.989253  \n",
       "2018-11-01      127.404132       132.934130  \n",
       "2018-12-01      120.518565       131.261348  \n",
       "2019-01-01      104.776326       113.057565  \n",
       "2019-02-01      109.597012       117.704727  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_dfs['P1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAB_ELE_SHP840</th>\n",
       "      <th>PRI27276_org</th>\n",
       "      <th>PRO27826_org</th>\n",
       "      <th>MAB_ELE_PRO276</th>\n",
       "      <th>MAB_ELE_SHP1100</th>\n",
       "      <th>PRO271000_org</th>\n",
       "      <th>PRI27840_org</th>\n",
       "      <th>PRO27380_org</th>\n",
       "      <th>WKLWEUR840_org</th>\n",
       "      <th>PRO27276_org</th>\n",
       "      <th>...</th>\n",
       "      <th>MAB_ELE_SHP276</th>\n",
       "      <th>MAB_ELE_PRO756</th>\n",
       "      <th>PRO27756_org</th>\n",
       "      <th>PRO27392_org</th>\n",
       "      <th>PRO28380_org</th>\n",
       "      <th>PRO28276_org</th>\n",
       "      <th>PRO28826_org</th>\n",
       "      <th>MAB_ELE_SHP250</th>\n",
       "      <th>PRO27250_org</th>\n",
       "      <th>PRO28392_org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127.808839</td>\n",
       "      <td>109.119614</td>\n",
       "      <td>118.670791</td>\n",
       "      <td>124.227879</td>\n",
       "      <td>130.989253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117.675874</td>\n",
       "      <td>109.224838</td>\n",
       "      <td>120.467019</td>\n",
       "      <td>127.404132</td>\n",
       "      <td>132.934130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123.280134</td>\n",
       "      <td>109.330063</td>\n",
       "      <td>105.378705</td>\n",
       "      <td>120.518565</td>\n",
       "      <td>131.261348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111.043755</td>\n",
       "      <td>109.750961</td>\n",
       "      <td>107.174933</td>\n",
       "      <td>104.776326</td>\n",
       "      <td>113.057565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.736921</td>\n",
       "      <td>109.856194</td>\n",
       "      <td>110.647640</td>\n",
       "      <td>109.597012</td>\n",
       "      <td>117.704727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.704029</td>\n",
       "      <td>114.326241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.499260</td>\n",
       "      <td>108.999212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.294492</td>\n",
       "      <td>103.672183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.089723</td>\n",
       "      <td>98.345154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.871570</td>\n",
       "      <td>98.150484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>602 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAB_ELE_SHP840  PRI27276_org  PRO27826_org  MAB_ELE_PRO276  \\\n",
       "0        127.808839    109.119614    118.670791      124.227879   \n",
       "1        117.675874    109.224838    120.467019      127.404132   \n",
       "2        123.280134    109.330063    105.378705      120.518565   \n",
       "3        111.043755    109.750961    107.174933      104.776326   \n",
       "4        116.736921    109.856194    110.647640      109.597012   \n",
       "..              ...           ...           ...             ...   \n",
       "597             NaN           NaN           NaN             NaN   \n",
       "598             NaN           NaN           NaN             NaN   \n",
       "599             NaN           NaN           NaN             NaN   \n",
       "600             NaN           NaN           NaN             NaN   \n",
       "601             NaN           NaN           NaN             NaN   \n",
       "\n",
       "     MAB_ELE_SHP1100  PRO271000_org  PRI27840_org  PRO27380_org  \\\n",
       "0         130.989253            NaN           NaN           NaN   \n",
       "1         132.934130            NaN           NaN           NaN   \n",
       "2         131.261348            NaN           NaN           NaN   \n",
       "3         113.057565            NaN           NaN           NaN   \n",
       "4         117.704727            NaN           NaN           NaN   \n",
       "..               ...            ...           ...           ...   \n",
       "597              NaN            NaN           NaN           NaN   \n",
       "598              NaN            NaN           NaN           NaN   \n",
       "599              NaN            NaN           NaN           NaN   \n",
       "600              NaN            NaN           NaN           NaN   \n",
       "601              NaN            NaN           NaN           NaN   \n",
       "\n",
       "     WKLWEUR840_org  PRO27276_org  ...  MAB_ELE_SHP276  MAB_ELE_PRO756  \\\n",
       "0               NaN           NaN  ...             NaN             NaN   \n",
       "1               NaN           NaN  ...             NaN             NaN   \n",
       "2               NaN           NaN  ...             NaN             NaN   \n",
       "3               NaN           NaN  ...             NaN             NaN   \n",
       "4               NaN           NaN  ...             NaN             NaN   \n",
       "..              ...           ...  ...             ...             ...   \n",
       "597             NaN           NaN  ...             NaN      106.704029   \n",
       "598             NaN           NaN  ...             NaN      103.499260   \n",
       "599             NaN           NaN  ...             NaN      100.294492   \n",
       "600             NaN           NaN  ...             NaN       97.089723   \n",
       "601             NaN           NaN  ...             NaN       96.871570   \n",
       "\n",
       "     PRO27756_org  PRO27392_org  PRO28380_org  PRO28276_org  PRO28826_org  \\\n",
       "0             NaN           NaN           NaN           NaN           NaN   \n",
       "1             NaN           NaN           NaN           NaN           NaN   \n",
       "2             NaN           NaN           NaN           NaN           NaN   \n",
       "3             NaN           NaN           NaN           NaN           NaN   \n",
       "4             NaN           NaN           NaN           NaN           NaN   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "597    114.326241           NaN           NaN           NaN           NaN   \n",
       "598    108.999212           NaN           NaN           NaN           NaN   \n",
       "599    103.672183           NaN           NaN           NaN           NaN   \n",
       "600     98.345154           NaN           NaN           NaN           NaN   \n",
       "601     98.150484           NaN           NaN           NaN           NaN   \n",
       "\n",
       "     MAB_ELE_SHP250  PRO27250_org  PRO28392_org  \n",
       "0               NaN           NaN           NaN  \n",
       "1               NaN           NaN           NaN  \n",
       "2               NaN           NaN           NaN  \n",
       "3               NaN           NaN           NaN  \n",
       "4               NaN           NaN           NaN  \n",
       "..              ...           ...           ...  \n",
       "597             NaN           NaN           NaN  \n",
       "598             NaN           NaN           NaN  \n",
       "599             NaN           NaN           NaN  \n",
       "600             NaN           NaN           NaN  \n",
       "601             NaN           NaN           NaN  \n",
       "\n",
       "[602 rows x 27 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_ids = [1, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 20, 36]\n",
    "macros_list = []\n",
    "\n",
    "# Iterando sobre os IDs de produtos que voc√™ forneceu\n",
    "for prod_id in product_ids:\n",
    "    key = f'P{prod_id}'  # Construindo a chave do produto (ex: 'P1', 'P3', etc.)\n",
    "    \n",
    "    # Verificando se a chave do produto existe no dicion√°rio\n",
    "    if key in product_dfs:\n",
    "        df = product_dfs[key]\n",
    "        \n",
    "        # Excluindo a coluna 'sales'\n",
    "        df_without_sales = df.drop(columns=['Sales'])\n",
    "        \n",
    "        # Adicionando os dados de macros √† lista\n",
    "        macros_list.append(df_without_sales)\n",
    "\n",
    "# Concatenando todos os DataFrames em uma √∫nica tabela\n",
    "macros_combinations = pd.concat(macros_list, ignore_index=True)\n",
    "\n",
    "# Obtendo todas as combina√ß√µes √∫nicas de macros\n",
    "unique_combinations = macros_combinations.drop_duplicates()\n",
    "\n",
    "# Exibindo as combina√ß√µes √∫nicas\n",
    "unique_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAB_ELE_SHP840</th>\n",
       "      <th>PRI27276_org</th>\n",
       "      <th>PRO27826_org</th>\n",
       "      <th>MAB_ELE_PRO276</th>\n",
       "      <th>MAB_ELE_SHP1100</th>\n",
       "      <th>PRO271000_org</th>\n",
       "      <th>PRI27840_org</th>\n",
       "      <th>PRO27380_org</th>\n",
       "      <th>WKLWEUR840_org</th>\n",
       "      <th>PRO27276_org</th>\n",
       "      <th>...</th>\n",
       "      <th>MAB_ELE_SHP276</th>\n",
       "      <th>MAB_ELE_PRO756</th>\n",
       "      <th>PRO27756_org</th>\n",
       "      <th>PRO27392_org</th>\n",
       "      <th>PRO28380_org</th>\n",
       "      <th>PRO28276_org</th>\n",
       "      <th>PRO28826_org</th>\n",
       "      <th>MAB_ELE_SHP250</th>\n",
       "      <th>PRO27250_org</th>\n",
       "      <th>PRO28392_org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127.808839</td>\n",
       "      <td>109.119614</td>\n",
       "      <td>118.670791</td>\n",
       "      <td>124.227879</td>\n",
       "      <td>130.989253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117.675874</td>\n",
       "      <td>109.224838</td>\n",
       "      <td>120.467019</td>\n",
       "      <td>127.404132</td>\n",
       "      <td>132.934130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123.280134</td>\n",
       "      <td>109.330063</td>\n",
       "      <td>105.378705</td>\n",
       "      <td>120.518565</td>\n",
       "      <td>131.261348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111.043755</td>\n",
       "      <td>109.750961</td>\n",
       "      <td>107.174933</td>\n",
       "      <td>104.776326</td>\n",
       "      <td>113.057565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.736921</td>\n",
       "      <td>109.856194</td>\n",
       "      <td>110.647640</td>\n",
       "      <td>109.597012</td>\n",
       "      <td>117.704727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.704029</td>\n",
       "      <td>114.326241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.499260</td>\n",
       "      <td>108.999212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.294492</td>\n",
       "      <td>103.672183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.089723</td>\n",
       "      <td>98.345154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.871570</td>\n",
       "      <td>98.150484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>602 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAB_ELE_SHP840  PRI27276_org  PRO27826_org  MAB_ELE_PRO276  \\\n",
       "0        127.808839    109.119614    118.670791      124.227879   \n",
       "1        117.675874    109.224838    120.467019      127.404132   \n",
       "2        123.280134    109.330063    105.378705      120.518565   \n",
       "3        111.043755    109.750961    107.174933      104.776326   \n",
       "4        116.736921    109.856194    110.647640      109.597012   \n",
       "..              ...           ...           ...             ...   \n",
       "597             NaN           NaN           NaN             NaN   \n",
       "598             NaN           NaN           NaN             NaN   \n",
       "599             NaN           NaN           NaN             NaN   \n",
       "600             NaN           NaN           NaN             NaN   \n",
       "601             NaN           NaN           NaN             NaN   \n",
       "\n",
       "     MAB_ELE_SHP1100  PRO271000_org  PRI27840_org  PRO27380_org  \\\n",
       "0         130.989253            NaN           NaN           NaN   \n",
       "1         132.934130            NaN           NaN           NaN   \n",
       "2         131.261348            NaN           NaN           NaN   \n",
       "3         113.057565            NaN           NaN           NaN   \n",
       "4         117.704727            NaN           NaN           NaN   \n",
       "..               ...            ...           ...           ...   \n",
       "597              NaN            NaN           NaN           NaN   \n",
       "598              NaN            NaN           NaN           NaN   \n",
       "599              NaN            NaN           NaN           NaN   \n",
       "600              NaN            NaN           NaN           NaN   \n",
       "601              NaN            NaN           NaN           NaN   \n",
       "\n",
       "     WKLWEUR840_org  PRO27276_org  ...  MAB_ELE_SHP276  MAB_ELE_PRO756  \\\n",
       "0               NaN           NaN  ...             NaN             NaN   \n",
       "1               NaN           NaN  ...             NaN             NaN   \n",
       "2               NaN           NaN  ...             NaN             NaN   \n",
       "3               NaN           NaN  ...             NaN             NaN   \n",
       "4               NaN           NaN  ...             NaN             NaN   \n",
       "..              ...           ...  ...             ...             ...   \n",
       "597             NaN           NaN  ...             NaN      106.704029   \n",
       "598             NaN           NaN  ...             NaN      103.499260   \n",
       "599             NaN           NaN  ...             NaN      100.294492   \n",
       "600             NaN           NaN  ...             NaN       97.089723   \n",
       "601             NaN           NaN  ...             NaN       96.871570   \n",
       "\n",
       "     PRO27756_org  PRO27392_org  PRO28380_org  PRO28276_org  PRO28826_org  \\\n",
       "0             NaN           NaN           NaN           NaN           NaN   \n",
       "1             NaN           NaN           NaN           NaN           NaN   \n",
       "2             NaN           NaN           NaN           NaN           NaN   \n",
       "3             NaN           NaN           NaN           NaN           NaN   \n",
       "4             NaN           NaN           NaN           NaN           NaN   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "597    114.326241           NaN           NaN           NaN           NaN   \n",
       "598    108.999212           NaN           NaN           NaN           NaN   \n",
       "599    103.672183           NaN           NaN           NaN           NaN   \n",
       "600     98.345154           NaN           NaN           NaN           NaN   \n",
       "601     98.150484           NaN           NaN           NaN           NaN   \n",
       "\n",
       "     MAB_ELE_SHP250  PRO27250_org  PRO28392_org  \n",
       "0               NaN           NaN           NaN  \n",
       "1               NaN           NaN           NaN  \n",
       "2               NaN           NaN           NaN  \n",
       "3               NaN           NaN           NaN  \n",
       "4               NaN           NaN           NaN  \n",
       "..              ...           ...           ...  \n",
       "597             NaN           NaN           NaN  \n",
       "598             NaN           NaN           NaN  \n",
       "599             NaN           NaN           NaN  \n",
       "600             NaN           NaN           NaN  \n",
       "601             NaN           NaN           NaN  \n",
       "\n",
       "[602 rows x 27 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista dos n√∫meros dos produtos que voc√™ mencionou\n",
    "product_ids = [1, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 20, 36]\n",
    "\n",
    "# Lista para armazenar os dados de macros de todos os produtos\n",
    "macros_list = []\n",
    "\n",
    "# Iterando sobre os IDs de produtos que voc√™ forneceu\n",
    "for prod_id in product_ids:\n",
    "    key = f'P{prod_id}'  # Construindo a chave do produto (ex: 'P1', 'P3', etc.)\n",
    "    \n",
    "    # Verificando se a chave do produto existe no dicion√°rio\n",
    "    if key in product_dfs:\n",
    "        df = product_dfs[key]\n",
    "        \n",
    "        # Excluindo a coluna 'sales'\n",
    "        df_sem_sales = df.drop(columns=['Sales'])\n",
    "        \n",
    "        # Adicionando os dados de macros √† lista\n",
    "        macros_list.append(df_sem_sales)\n",
    "\n",
    "# Concatenando todos os DataFrames em uma √∫nica tabela\n",
    "macros_combinados = pd.concat(macros_list, ignore_index=True)\n",
    "\n",
    "# Obtendo todas as combina√ß√µes √∫nicas de macros\n",
    "combinacoes_unicas = macros_combinados.drop_duplicates()\n",
    "\n",
    "# Exibindo as combina√ß√µes √∫nicas\n",
    "combinacoes_unicas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combina√ß√£o de Macros</th>\n",
       "      <th>Produtos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(127.80883943812468, 109.1196136474609, 118.67...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(117.67587388309826, 109.2248382568359, 120.46...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(123.28013378640512, 109.3300628662109, 105.37...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(111.04375462185241, 109.7509613037109, 107.17...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(116.73692110885848, 109.8561935424805, 110.64...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>(106.70402895817061, 114.32624113475178, 310.7...</td>\n",
       "      <td>P36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>(103.49926026575272, 108.99921197793539, 235.9...</td>\n",
       "      <td>P36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>(100.29449157333487, 103.672182821119, 235.956...</td>\n",
       "      <td>P36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>(97.08972288091698, 98.3451536643026, 329.4133...</td>\n",
       "      <td>P36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>(96.87156966928907, 98.15048386266902, 267.373...</td>\n",
       "      <td>P36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>602 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Combina√ß√£o de Macros Produtos\n",
       "0    (127.80883943812468, 109.1196136474609, 118.67...       P1\n",
       "1    (117.67587388309826, 109.2248382568359, 120.46...       P1\n",
       "2    (123.28013378640512, 109.3300628662109, 105.37...       P1\n",
       "3    (111.04375462185241, 109.7509613037109, 107.17...       P1\n",
       "4    (116.73692110885848, 109.8561935424805, 110.64...       P1\n",
       "..                                                 ...      ...\n",
       "597  (106.70402895817061, 114.32624113475178, 310.7...      P36\n",
       "598  (103.49926026575272, 108.99921197793539, 235.9...      P36\n",
       "599  (100.29449157333487, 103.672182821119, 235.956...      P36\n",
       "600  (97.08972288091698, 98.3451536643026, 329.4133...      P36\n",
       "601  (96.87156966928907, 98.15048386266902, 267.373...      P36\n",
       "\n",
       "[602 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista dos n√∫meros dos produtos que voc√™ mencionou\n",
    "product_ids = [1, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 20, 36]\n",
    "\n",
    "# Dicion√°rio para armazenar as combina√ß√µes √∫nicas de macros e os produtos onde aparecem\n",
    "combinacoes_produtos = {}\n",
    "\n",
    "# Iterando sobre os IDs de produtos que voc√™ forneceu\n",
    "for prod_id in product_ids:\n",
    "    key = f'P{prod_id}'  # Construindo a chave do produto (ex: 'P1', 'P3', etc.)\n",
    "    \n",
    "    # Verificando se a chave do produto existe no dicion√°rio\n",
    "    if key in product_dfs:\n",
    "        df = product_dfs[key]\n",
    "        \n",
    "        # Iterando sobre cada linha do DataFrame, considerando todas as colunas, exceto 'Sales'\n",
    "        for idx, row in df.iterrows():\n",
    "            # Excluindo a coluna 'Sales' apenas para a combina√ß√£o de macros\n",
    "            combinacao_macros = tuple(row.drop('Sales', errors='ignore'))  # Usando 'errors=ignore' para evitar erro se 'Sales' n√£o existir\n",
    "            \n",
    "            # Adicionando o produto √† lista de produtos para essa combina√ß√£o de macros\n",
    "            if combinacao_macros not in combinacoes_produtos:\n",
    "                combinacoes_produtos[combinacao_macros] = []\n",
    "            \n",
    "            combinacoes_produtos[combinacao_macros].append(key)\n",
    "\n",
    "# Convertendo o dicion√°rio em um DataFrame para visualiza√ß√£o\n",
    "combinacoes_df = pd.DataFrame(list(combinacoes_produtos.items()), columns=['Combina√ß√£o de Macros', 'Produtos'])\n",
    "combinacoes_df['Produtos'] = combinacoes_df['Produtos'].apply(lambda x: ', '.join(x))  # Lista de produtos como string\n",
    "\n",
    "# Exibindo o DataFrame final\n",
    "combinacoes_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Macro, Produtos]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "product_ids = [1, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 20, 36]\n",
    "\n",
    "\n",
    "# Dicion√°rio para armazenar as macros e os produtos onde elas aparecem\n",
    "macros_produtos = {}\n",
    "\n",
    "# Iterando sobre os IDs de produtos que voc√™ forneceu\n",
    "for prod_id in product_ids:\n",
    "    key = f'P{prod_id}'  # Construindo a chave do produto (ex: 'P1', 'P3', etc.)\n",
    "    \n",
    "    # Verificando se a chave do produto existe no dicion√°rio\n",
    "    if key in product_dfs:\n",
    "        df = product_dfs[key]\n",
    "        \n",
    "        # Iterando sobre cada coluna de macros\n",
    "        for macro in ['proteinas', 'carboidratos', 'gorduras']:\n",
    "            # Se a macro estiver no DataFrame, vamos verificar se o valor existe\n",
    "            if macro in df.columns:\n",
    "                # Adicionando o produto √† lista de produtos para essa macro\n",
    "                for value in df[macro]:\n",
    "                    if key not in macros_produtos[macro]:\n",
    "                        macros_produtos[macro].append(key)\n",
    "\n",
    "# Convertendo o dicion√°rio em um DataFrame para visualiza√ß√£o\n",
    "macros_df = pd.DataFrame(list(macros_produtos.items()), columns=['Macro', 'Produtos'])\n",
    "macros_df['Produtos'] = macros_df['Produtos'].apply(lambda x: ', '.join(x))  # Lista de produtos como string\n",
    "\n",
    "# Exibindo o DataFrame final\n",
    "print(macros_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas do DataFrame P11:\n",
      "Index(['Sales', 'PRO27826_org', 'MAB_ELE_SHP392', 'MAB_ELE_SHP840',\n",
      "       'MAB_ELE_SHP276'],\n",
      "      dtype='object')\n",
      "\n",
      "Colunas do DataFrame P13:\n",
      "Index(['Sales', 'MAB_ELE_PRO756', 'PRO27756_org', 'MAB_ELE_PRO276',\n",
      "       'PRI27840_org'],\n",
      "      dtype='object')\n",
      "\n",
      "Colunas do DataFrame P12:\n",
      "Index(['Sales', 'PRI27840_org', 'RohCOPPER1000_org', 'MAB_ELE_PRO156'], dtype='object')\n",
      "\n",
      "Colunas do DataFrame P16:\n",
      "Index(['Sales', 'MAB_ELE_PRO756', 'PRO28276_org', 'PRI27276_org',\n",
      "       'PRO28826_org'],\n",
      "      dtype='object')\n",
      "\n",
      "Colunas do DataFrame P14:\n",
      "Index(['Sales', 'PRO27392_org', 'PRO28380_org', 'PRO27756_org'], dtype='object')\n",
      "\n",
      "Colunas do DataFrame P8:\n",
      "Index(['Sales', 'PRI27840_org', 'RohCOPPER1000_org'], dtype='object')\n",
      "\n",
      "Colunas do DataFrame P9:\n",
      "Index(['Sales', 'PRO27826_org', 'PRO271000_org', 'PRO28250_org',\n",
      "       'MAB_ELE_PRO156'],\n",
      "      dtype='object')\n",
      "\n",
      "Colunas do DataFrame Sales_CPI:\n",
      "Index(['Sales', 'MAB_ELE_SHP840', 'PRI27276_org', 'PRO271000_org',\n",
      "       'PRO27826_org'],\n",
      "      dtype='object')\n",
      "\n",
      "Colunas do DataFrame P1:\n",
      "Index(['Sales', 'MAB_ELE_SHP840', 'PRI27276_org', 'PRO27826_org',\n",
      "       'MAB_ELE_PRO276', 'MAB_ELE_SHP1100'],\n",
      "      dtype='object')\n",
      "\n",
      "Colunas do DataFrame P3:\n",
      "Index(['Sales', 'PRO27826_org', 'PRO271000_org', 'PRI27840_org'], dtype='object')\n",
      "\n",
      "Colunas do DataFrame P6:\n",
      "Index(['Sales', 'PRO27840_org', 'PRO27276_org', 'RohCRUDE_PETRO1000_org'], dtype='object')\n",
      "\n",
      "Colunas do DataFrame P4:\n",
      "Index(['Sales', 'PRO27380_org', 'WKLWEUR840_org', 'PRO27276_org',\n",
      "       'MAB_ELE_SHP380'],\n",
      "      dtype='object')\n",
      "\n",
      "Colunas do DataFrame P5:\n",
      "Index(['Sales', 'PRO27826_org', 'MAB_ELE_SHP840', 'PRO271000_org',\n",
      "       'MAB_ELE_PRO156'],\n",
      "      dtype='object')\n",
      "\n",
      "Colunas do DataFrame P36:\n",
      "Index(['Sales', 'MAB_ELE_PRO756', 'PRO27756_org', 'MAB_ELE_PRO156'], dtype='object')\n",
      "\n",
      "Colunas do DataFrame P20:\n",
      "Index(['Sales', 'MAB_ELE_SHP250', 'PRO271000_org', 'PRO27250_org',\n",
      "       'PRO28392_org'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre todos os DataFrames no dicion√°rio `product_dfs` e exibir as colunas\n",
    "for key, df in product_dfs.items():\n",
    "    print(f\"Colunas do DataFrame {key}:\")\n",
    "    print(df.columns)\n",
    "    print()  # Apenas para separar as sa√≠das de cada DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Macro</th>\n",
       "      <th>Produtos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAB_ELE_SHP840</td>\n",
       "      <td>P1, P5, P11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRI27276_org</td>\n",
       "      <td>P1, P16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRO27826_org</td>\n",
       "      <td>P1, P3, P5, P9, P11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAB_ELE_PRO276</td>\n",
       "      <td>P1, P13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAB_ELE_SHP1100</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PRO271000_org</td>\n",
       "      <td>P3, P5, P9, P20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRI27840_org</td>\n",
       "      <td>P3, P8, P12, P13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PRO27380_org</td>\n",
       "      <td>P4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WKLWEUR840_org</td>\n",
       "      <td>P4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PRO27276_org</td>\n",
       "      <td>P4, P6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MAB_ELE_SHP380</td>\n",
       "      <td>P4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MAB_ELE_PRO156</td>\n",
       "      <td>P5, P9, P12, P36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PRO27840_org</td>\n",
       "      <td>P6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RohCRUDE_PETRO1000_org</td>\n",
       "      <td>P6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RohCOPPER1000_org</td>\n",
       "      <td>P8, P12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PRO28250_org</td>\n",
       "      <td>P9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MAB_ELE_SHP392</td>\n",
       "      <td>P11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MAB_ELE_SHP276</td>\n",
       "      <td>P11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MAB_ELE_PRO756</td>\n",
       "      <td>P13, P16, P36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PRO27756_org</td>\n",
       "      <td>P13, P14, P36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PRO27392_org</td>\n",
       "      <td>P14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PRO28380_org</td>\n",
       "      <td>P14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PRO28276_org</td>\n",
       "      <td>P16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PRO28826_org</td>\n",
       "      <td>P16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MAB_ELE_SHP250</td>\n",
       "      <td>P20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PRO27250_org</td>\n",
       "      <td>P20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PRO28392_org</td>\n",
       "      <td>P20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Macro             Produtos\n",
       "0           MAB_ELE_SHP840          P1, P5, P11\n",
       "1             PRI27276_org              P1, P16\n",
       "2             PRO27826_org  P1, P3, P5, P9, P11\n",
       "3           MAB_ELE_PRO276              P1, P13\n",
       "4          MAB_ELE_SHP1100                   P1\n",
       "5            PRO271000_org      P3, P5, P9, P20\n",
       "6             PRI27840_org     P3, P8, P12, P13\n",
       "7             PRO27380_org                   P4\n",
       "8           WKLWEUR840_org                   P4\n",
       "9             PRO27276_org               P4, P6\n",
       "10          MAB_ELE_SHP380                   P4\n",
       "11          MAB_ELE_PRO156     P5, P9, P12, P36\n",
       "12            PRO27840_org                   P6\n",
       "13  RohCRUDE_PETRO1000_org                   P6\n",
       "14       RohCOPPER1000_org              P8, P12\n",
       "15            PRO28250_org                   P9\n",
       "16          MAB_ELE_SHP392                  P11\n",
       "17          MAB_ELE_SHP276                  P11\n",
       "18          MAB_ELE_PRO756        P13, P16, P36\n",
       "19            PRO27756_org        P13, P14, P36\n",
       "20            PRO27392_org                  P14\n",
       "21            PRO28380_org                  P14\n",
       "22            PRO28276_org                  P16\n",
       "23            PRO28826_org                  P16\n",
       "24          MAB_ELE_SHP250                  P20\n",
       "25            PRO27250_org                  P20\n",
       "26            PRO28392_org                  P20"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista de produtos para evitar na coluna 'Macro'\n",
    "produtos = {\"P1\", \"P3\", \"P4\", \"P5\", \"P6\", \"P8\", \"P9\", \"P11\", \"P12\", \"P13\", \"P14\", \"P16\", \"P20\", \"P36\"}\n",
    "\n",
    "# Dicion√°rio de DataFrames com os dados dos produtos\n",
    "product_dfs = {\n",
    "    'P1': pd.read_pickle('product_dfs_folder/P1.pkl'),\n",
    "    'P3': pd.read_pickle('product_dfs_folder/P3.pkl'),\n",
    "    'P4': pd.read_pickle('product_dfs_folder/P4.pkl'),\n",
    "    'P5': pd.read_pickle('product_dfs_folder/P5.pkl'),\n",
    "    'P6': pd.read_pickle('product_dfs_folder/P6.pkl'),\n",
    "    'P8': pd.read_pickle('product_dfs_folder/P8.pkl'),\n",
    "    'P9': pd.read_pickle('product_dfs_folder/P9.pkl'),\n",
    "    'P11': pd.read_pickle('product_dfs_folder/P11.pkl'),\n",
    "    'P12': pd.read_pickle('product_dfs_folder/P12.pkl'),\n",
    "    'P13': pd.read_pickle('product_dfs_folder/P13.pkl'),\n",
    "    'P14': pd.read_pickle('product_dfs_folder/P14.pkl'),\n",
    "    'P16': pd.read_pickle('product_dfs_folder/P16.pkl'),\n",
    "    'P20': pd.read_pickle('product_dfs_folder/P20.pkl'),\n",
    "    'P36': pd.read_pickle('product_dfs_folder/P36.pkl'),\n",
    "}\n",
    "\n",
    "# Dicion√°rio para armazenar as macros e os produtos correspondentes\n",
    "identificadores_produtos = {}\n",
    "\n",
    "# Iterando sobre os DataFrames\n",
    "for key, df in product_dfs.items():\n",
    "    # Iterando sobre as colunas (exceto 'Sales')\n",
    "    for col in df.columns:\n",
    "        if col != 'Sales' and col not in produtos:  # Ignora 'Sales' e produtos na coluna 'Macro'\n",
    "            if col not in identificadores_produtos:\n",
    "                identificadores_produtos[col] = []\n",
    "            identificadores_produtos[col].append(key)\n",
    "\n",
    "# Convertendo o dicion√°rio em um DataFrame para visualiza√ß√£o\n",
    "identificadores_df = pd.DataFrame(list(identificadores_produtos.items()), columns=['Macro', 'Produtos'])\n",
    "identificadores_df['Produtos'] = identificadores_df['Produtos'].apply(lambda x: ', '.join(x))  # Lista de produtos como string\n",
    "\n",
    "# Exibindo o DataFrame final\n",
    "identificadores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <span style=\"background-color:#000027; padding:5px; border-radius:5px;\">**Analyze Stationarity / Non-Stationarity per Macro**</span> <a id='Stationarity'></a>  \n",
    "\n",
    "Click [here](#table-of-contents) ‚¨ÜÔ∏è to return to the Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Macro: MAB_ELE_SHP840\n",
      "Testando estacionariedade da macro 'MAB_ELE_SHP840'...\n",
      "A s√©rie precisa ser unidimensional para o teste ADF.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x is required to have ndim 1 but has ndim 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stationarity_df\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Exemplo de execu√ß√£o:\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m stationarity_df \u001b[38;5;241m=\u001b[39m check_stationarity_for_macros(identificadores_df, product_dfs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Exibir os resultados\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResultados da Estacionariedade por Macro:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[82], line 57\u001b[0m, in \u001b[0;36mcheck_stationarity_for_macros\u001b[0;34m(identificadores_df, product_dfs)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTestando estacionariedade da macro \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmacro\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m         adf_test(final_series)  \u001b[38;5;66;03m# Aplicar o teste ADF na s√©rie concatenada\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m         stationarity_results\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMacro\u001b[39m\u001b[38;5;124m\"\u001b[39m: macro, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADF P-Value\u001b[39m\u001b[38;5;124m\"\u001b[39m: adfuller(final_series)[\u001b[38;5;241m1\u001b[39m]})\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Criar um DataFrame com os resultados das an√°lises\u001b[39;00m\n\u001b[1;32m     60\u001b[0m stationarity_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(stationarity_results)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:263\u001b[0m, in \u001b[0;36madfuller\u001b[0;34m(x, maxlag, regression, autolag, store, regresults)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madfuller\u001b[39m(\n\u001b[1;32m    169\u001b[0m     x,\n\u001b[1;32m    170\u001b[0m     maxlag: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m     regresults\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    175\u001b[0m ):\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    Augmented Dickey-Fuller unit root test.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m        http://ideas.repec.org/p/qed/wpaper/1227.html\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m     x \u001b[38;5;241m=\u001b[39m array_like(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    264\u001b[0m     maxlag \u001b[38;5;241m=\u001b[39m int_like(maxlag, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxlag\u001b[39m\u001b[38;5;124m\"\u001b[39m, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    265\u001b[0m     regression \u001b[38;5;241m=\u001b[39m string_like(\n\u001b[1;32m    266\u001b[0m         regression, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mct\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mctt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    267\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/statsmodels/tools/validation/validation.py:155\u001b[0m, in \u001b[0;36marray_like\u001b[0;34m(obj, name, dtype, ndim, maxdim, shape, order, contiguous, optional, writeable)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m ndim:\n\u001b[1;32m    154\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is required to have ndim \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m but has ndim \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(name, ndim, arr\u001b[38;5;241m.\u001b[39mndim))\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m actual, req \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(arr\u001b[38;5;241m.\u001b[39mshape, shape):\n",
      "\u001b[0;31mValueError\u001b[0m: x is required to have ndim 1 but has ndim 2"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "import pandas as pd\n",
    "\n",
    "# Fun√ß√£o para aplicar o teste Dickey-Fuller (ADF) em uma s√©rie\n",
    "def adf_test(series):\n",
    "    \"\"\"Realiza o teste Augmented Dickey-Fuller (ADF) para estacionariedade.\"\"\"\n",
    "    if isinstance(series, pd.Series):  # Verificar se a s√©rie √© uma pd.Series\n",
    "        series = series.dropna()  # Remover NaNs antes de realizar o teste\n",
    "    if series.ndim == 1:  # Verificar se a s√©rie √© unidimensional\n",
    "        result = adfuller(series)  # Realiza o teste ADF\n",
    "        print(\"Dickey-Fuller Test Results:\")\n",
    "        df_results = pd.Series(result[:4], index=[\"Test Statistic\", \"p-value\", \"# Lags Used\", \"# Observations Used\"])\n",
    "        for key, value in result[4].items():\n",
    "            df_results[f\"Critical Value ({key})\"] = value\n",
    "        print(df_results)\n",
    "        \n",
    "        # Interpreta√ß√£o\n",
    "        if result[1] <= 0.05:\n",
    "            print(\"‚úÖ A s√©rie √© estacion√°ria (p-valor < 0.05).\")\n",
    "        else:\n",
    "            print(\"‚ùå A s√©rie N√ÉO √© estacion√°ria (p-valor > 0.05). Considere transformar a s√©rie.\")\n",
    "    else:\n",
    "        print(\"A s√©rie precisa ser unidimensional para o teste ADF.\")\n",
    "\n",
    "# Fun√ß√£o para verificar a estacionariedade por macro\n",
    "def check_stationarity_for_macros(identificadores_df, product_dfs):\n",
    "    \"\"\"Verifica a estacionariedade das vari√°veis macro combinando as s√©ries dos produtos.\"\"\"\n",
    "    \n",
    "    # Criar lista para armazenar os resultados\n",
    "    stationarity_results = []\n",
    "\n",
    "    # Iterar pelas macross de produtos\n",
    "    for macro in identificadores_df[\"Macro\"]:\n",
    "        print(f\"\\nMacro: {macro}\")\n",
    "        \n",
    "        # Identificar os produtos da macro\n",
    "        produtos_macro = identificadores_df.loc[identificadores_df[\"Macro\"] == macro, \"Produtos\"].values[0]\n",
    "        produtos_lista = produtos_macro.split(\", \")\n",
    "\n",
    "        # Criar uma lista para as s√©ries dos produtos\n",
    "        combined_series = []\n",
    "\n",
    "        # Iterar sobre os produtos e coletar as s√©ries correspondentes\n",
    "        for produto in produtos_lista:\n",
    "            if produto in product_dfs:\n",
    "                # Coletar a s√©rie temporal de cada produto, sem depender da coluna 'Sales'\n",
    "                series = product_dfs[produto].dropna()  # Remover NaNs\n",
    "                combined_series.append(series)\n",
    "\n",
    "        # Concatenar as s√©ries de todos os produtos da macro\n",
    "        if combined_series:\n",
    "            final_series = pd.concat(combined_series, axis=0)  # Concatenar todas as s√©ries em uma √∫nica\n",
    "            final_series = final_series.dropna()  # Remover NaNs da s√©rie concatenada\n",
    "            final_series = final_series.squeeze()  # Garantir que a s√©rie seja unidimensional (squeeze)\n",
    "            print(f\"Testando estacionariedade da macro '{macro}'...\")\n",
    "            adf_test(final_series)  # Aplicar o teste ADF na s√©rie concatenada\n",
    "            stationarity_results.append({\"Macro\": macro, \"ADF P-Value\": adfuller(final_series)[1]})\n",
    "\n",
    "    # Criar um DataFrame com os resultados das an√°lises\n",
    "    stationarity_df = pd.DataFrame(stationarity_results)\n",
    "    return stationarity_df\n",
    "\n",
    "# Exemplo de execu√ß√£o:\n",
    "stationarity_df = check_stationarity_for_macros(identificadores_df, product_dfs)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"\\nResultados da Estacionariedade por Macro:\")\n",
    "print(stationarity_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Macro: MAB_ELE_SHP840\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P1\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P5\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P11\n",
      "\n",
      "Macro: PRI27276_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P1\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P16\n",
      "\n",
      "Macro: PRO27826_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P1\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P3\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P5\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P9\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P11\n",
      "\n",
      "Macro: MAB_ELE_PRO276\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P1\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P13\n",
      "\n",
      "Macro: MAB_ELE_SHP1100\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P1\n",
      "\n",
      "Macro: PRO271000_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P3\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P5\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P9\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P20\n",
      "\n",
      "Macro: PRI27840_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P3\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P8\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P12\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P13\n",
      "\n",
      "Macro: PRO27380_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P4\n",
      "\n",
      "Macro: WKLWEUR840_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P4\n",
      "\n",
      "Macro: PRO27276_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P4\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P6\n",
      "\n",
      "Macro: MAB_ELE_SHP380\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P4\n",
      "\n",
      "Macro: MAB_ELE_PRO156\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P5\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P9\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P12\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P36\n",
      "\n",
      "Macro: PRO27840_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P6\n",
      "\n",
      "Macro: RohCRUDE_PETRO1000_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P6\n",
      "\n",
      "Macro: RohCOPPER1000_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P8\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P12\n",
      "\n",
      "Macro: PRO28250_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P9\n",
      "\n",
      "Macro: MAB_ELE_SHP392\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P11\n",
      "\n",
      "Macro: MAB_ELE_SHP276\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P11\n",
      "\n",
      "Macro: MAB_ELE_PRO756\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P13\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P16\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P36\n",
      "\n",
      "Macro: PRO27756_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P13\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P14\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P36\n",
      "\n",
      "Macro: PRO27392_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P14\n",
      "\n",
      "Macro: PRO28380_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P14\n",
      "\n",
      "Macro: PRO28276_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P16\n",
      "\n",
      "Macro: PRO28826_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P16\n",
      "\n",
      "Macro: MAB_ELE_SHP250\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P20\n",
      "\n",
      "Macro: PRO27250_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P20\n",
      "\n",
      "Macro: PRO28392_org\n",
      "‚ùå Coluna 'Sales' n√£o encontrada no produto: P20\n",
      "\n",
      "Resultados da Estacionariedade por Macro:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o para aplicar o teste Dickey-Fuller (ADF) em uma s√©rie\n",
    "def adf_test(series):\n",
    "    \"\"\"Realiza o teste Augmented Dickey-Fuller (ADF) para estacionariedade.\"\"\"\n",
    "    result = adfuller(series.dropna())  # Remover NaNs antes de realizar o teste\n",
    "    print(\"Dickey-Fuller Test Results:\")\n",
    "    df_results = pd.Series(result[:4], index=[\"Test Statistic\", \"p-value\", \"# Lags Used\", \"# Observations Used\"])\n",
    "    for key, value in result[4].items():\n",
    "        df_results[f\"Critical Value ({key})\"] = value\n",
    "    print(df_results)\n",
    "    \n",
    "    # Interpreta√ß√£o\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"‚úÖ A s√©rie √© estacion√°ria (p-valor < 0.05).\")\n",
    "    else:\n",
    "        print(\"‚ùå A s√©rie N√ÉO √© estacion√°ria (p-valor > 0.05). Considere transformar a s√©rie.\")\n",
    "\n",
    "# Fun√ß√£o para verificar a estacionariedade por macro\n",
    "def check_stationarity_for_macros(identificadores_df, product_dfs):\n",
    "    \"\"\"Verifica a estacionariedade das vari√°veis macro combinando as s√©ries dos produtos.\"\"\"\n",
    "    \n",
    "    # Criar lista para armazenar os resultados\n",
    "    stationarity_results = []\n",
    "\n",
    "    # Iterar pelas macross de produtos\n",
    "    for macro in identificadores_df[\"Macro\"]:\n",
    "        print(f\"\\nMacro: {macro}\")\n",
    "        \n",
    "        # Identificar os produtos da macro\n",
    "        produtos_macro = identificadores_df.loc[identificadores_df[\"Macro\"] == macro, \"Produtos\"].values[0]\n",
    "        produtos_lista = produtos_macro.split(\", \")\n",
    "\n",
    "        # Criar uma lista para as s√©ries dos produtos\n",
    "        combined_series = []\n",
    "\n",
    "        # Iterar sobre os produtos e coletar as s√©ries correspondentes\n",
    "        for produto in produtos_lista:\n",
    "            if produto in product_dfs:\n",
    "                # Verificar se a coluna 'Sales' existe no DataFrame do produto\n",
    "                if 'Sales' in product_dfs[produto].columns:\n",
    "                    series = product_dfs[produto][\"Sales\"].dropna()\n",
    "                    combined_series.append(series)\n",
    "                else:\n",
    "                    print(f\"‚ùå Coluna 'Sales' n√£o encontrada no produto: {produto}\")\n",
    "                    continue  # Ignorar o produto se n√£o tiver a coluna 'Sales'\n",
    "\n",
    "        # Concatenar as s√©ries de todos os produtos da macro\n",
    "        if combined_series:\n",
    "            final_series = pd.concat(combined_series)\n",
    "            print(f\"Testando estacionariedade da macro '{macro}'...\")\n",
    "            adf_test(final_series)  # Aplicar o teste ADF na s√©rie concatenada\n",
    "            stationarity_results.append({\"Macro\": macro, \"ADF P-Value\": adfuller(final_series)[1]})\n",
    "\n",
    "    # Criar um DataFrame com os resultados das an√°lises\n",
    "    stationarity_df = pd.DataFrame(stationarity_results)\n",
    "    return stationarity_df\n",
    "\n",
    "# Exemplo de execu√ß√£o:\n",
    "stationarity_df = check_stationarity_for_macros(identificadores_df, product_dfs)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"\\nResultados da Estacionariedade por Macro:\")\n",
    "print(stationarity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Macro: MAB_ELE_SHP840\n",
      "Testando estacionariedade da macro 'MAB_ELE_SHP840'...\n",
      "A s√©rie precisa ser unidimensional para o teste ADF.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x is required to have ndim 1 but has ndim 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stationarity_df\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Exemplo de execu√ß√£o:\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m stationarity_df \u001b[38;5;241m=\u001b[39m check_stationarity_for_macros(identificadores_df, product_dfs)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Exibir os resultados\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResultados da Estacionariedade por Macro:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[67], line 51\u001b[0m, in \u001b[0;36mcheck_stationarity_for_macros\u001b[0;34m(identificadores_df, product_dfs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTestando estacionariedade da macro \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmacro\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m         adf_test(final_series)  \u001b[38;5;66;03m# Aplicar o teste ADF na s√©rie concatenada\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m         stationarity_results\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMacro\u001b[39m\u001b[38;5;124m\"\u001b[39m: macro, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADF P-Value\u001b[39m\u001b[38;5;124m\"\u001b[39m: adfuller(final_series)[\u001b[38;5;241m1\u001b[39m]})\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Criar um DataFrame com os resultados das an√°lises\u001b[39;00m\n\u001b[1;32m     54\u001b[0m stationarity_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(stationarity_results)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:263\u001b[0m, in \u001b[0;36madfuller\u001b[0;34m(x, maxlag, regression, autolag, store, regresults)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madfuller\u001b[39m(\n\u001b[1;32m    169\u001b[0m     x,\n\u001b[1;32m    170\u001b[0m     maxlag: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m     regresults\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    175\u001b[0m ):\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    Augmented Dickey-Fuller unit root test.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m        http://ideas.repec.org/p/qed/wpaper/1227.html\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m     x \u001b[38;5;241m=\u001b[39m array_like(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    264\u001b[0m     maxlag \u001b[38;5;241m=\u001b[39m int_like(maxlag, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxlag\u001b[39m\u001b[38;5;124m\"\u001b[39m, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    265\u001b[0m     regression \u001b[38;5;241m=\u001b[39m string_like(\n\u001b[1;32m    266\u001b[0m         regression, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mct\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mctt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    267\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/statsmodels/tools/validation/validation.py:155\u001b[0m, in \u001b[0;36marray_like\u001b[0;34m(obj, name, dtype, ndim, maxdim, shape, order, contiguous, optional, writeable)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m ndim:\n\u001b[1;32m    154\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is required to have ndim \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m but has ndim \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(name, ndim, arr\u001b[38;5;241m.\u001b[39mndim))\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m actual, req \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(arr\u001b[38;5;241m.\u001b[39mshape, shape):\n",
      "\u001b[0;31mValueError\u001b[0m: x is required to have ndim 1 but has ndim 2"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o para aplicar o teste Dickey-Fuller (ADF) em uma s√©rie\n",
    "def adf_test(series):\n",
    "    \"\"\"Realiza o teste Augmented Dickey-Fuller (ADF) para estacionariedade.\"\"\"\n",
    "    series = series.dropna()  # Remover NaNs antes de realizar o teste\n",
    "    if series.ndim == 1:  # Verificar se a s√©rie √© unidimensional\n",
    "        result = adfuller(series)  # Realiza o teste ADF\n",
    "        print(\"Dickey-Fuller Test Results:\")\n",
    "        df_results = pd.Series(result[:4], index=[\"Test Statistic\", \"p-value\", \"# Lags Used\", \"# Observations Used\"])\n",
    "        for key, value in result[4].items():\n",
    "            df_results[f\"Critical Value ({key})\"] = value\n",
    "        print(df_results)\n",
    "        \n",
    "        # Interpreta√ß√£o\n",
    "        if result[1] <= 0.05:\n",
    "            print(\"‚úÖ A s√©rie √© estacion√°ria (p-valor < 0.05).\")\n",
    "        else:\n",
    "            print(\"‚ùå A s√©rie N√ÉO √© estacion√°ria (p-valor > 0.05). Considere transformar a s√©rie.\")\n",
    "    else:\n",
    "        print(\"A s√©rie precisa ser unidimensional para o teste ADF.\")\n",
    "\n",
    "# Fun√ß√£o para verificar a estacionariedade por macro\n",
    "def check_stationarity_for_macros(identificadores_df, product_dfs):\n",
    "    \"\"\"Verifica a estacionariedade das vari√°veis macro combinando as s√©ries dos produtos.\"\"\"\n",
    "    \n",
    "    # Criar lista para armazenar os resultados\n",
    "    stationarity_results = []\n",
    "\n",
    "    # Iterar pelas macross de produtos\n",
    "    for macro in identificadores_df[\"Macro\"]:\n",
    "        print(f\"\\nMacro: {macro}\")\n",
    "        \n",
    "        # Identificar os produtos da macro\n",
    "        produtos_macro = identificadores_df.loc[identificadores_df[\"Macro\"] == macro, \"Produtos\"].values[0]\n",
    "        produtos_lista = produtos_macro.split(\", \")\n",
    "\n",
    "        # Criar uma lista para as s√©ries dos produtos\n",
    "        combined_series = []\n",
    "\n",
    "        # Iterar sobre os produtos e coletar as s√©ries correspondentes\n",
    "        for produto in produtos_lista:\n",
    "            if produto in product_dfs:\n",
    "                # Coletar a s√©rie temporal de cada produto, sem depender da coluna 'Sales'\n",
    "                series = product_dfs[produto].dropna()  # Remover NaNs\n",
    "                combined_series.append(series)\n",
    "\n",
    "        # Concatenar as s√©ries de todos os produtos da macro\n",
    "        if combined_series:\n",
    "            final_series = pd.concat(combined_series, axis=0)  # Concatenar todas as s√©ries em uma √∫nica (unidimensional)\n",
    "            print(f\"Testando estacionariedade da macro '{macro}'...\")\n",
    "            adf_test(final_series)  # Aplicar o teste ADF na s√©rie concatenada\n",
    "            stationarity_results.append({\"Macro\": macro, \"ADF P-Value\": adfuller(final_series)[1]})\n",
    "\n",
    "    # Criar um DataFrame com os resultados das an√°lises\n",
    "    stationarity_df = pd.DataFrame(stationarity_results)\n",
    "    return stationarity_df\n",
    "\n",
    "# Exemplo de execu√ß√£o:\n",
    "stationarity_df = check_stationarity_for_macros(identificadores_df, product_dfs)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"\\nResultados da Estacionariedade por Macro:\")\n",
    "print(stationarity_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <span style=\"background-color:#000027; padding:5px; border-radius:5px;font-size:13pt\">**Autocorrelation Function (ACF)**</span> <a id='Autocorrelation'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analisando a macro: MAB_ELE_SHP840\n",
      "\n",
      "Analisando a macro: PRI27276_org\n",
      "\n",
      "Analisando a macro: PRO27826_org\n",
      "\n",
      "Analisando a macro: MAB_ELE_PRO276\n",
      "\n",
      "Analisando a macro: MAB_ELE_SHP1100\n",
      "Testando estacionariedade da macro 'MAB_ELE_SHP1100'...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x is required to have ndim 1 but has ndim 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 113\u001b[0m\n\u001b[1;32m    109\u001b[0m     fig\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Exemplo de execu√ß√£o:\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Assumindo que 'identificadores_df' e 'product_dfs' j√° est√£o definidos, podemos chamar a fun√ß√£o para plotar as correla√ß√µes.\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m plot_correlation_for_macros(identificadores_df, product_dfs, lags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, plot_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[83], line 60\u001b[0m, in \u001b[0;36mplot_correlation_for_macros\u001b[0;34m(identificadores_df, product_dfs, lags, plot_type)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTestando estacionariedade da macro \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmacro\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plot_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 60\u001b[0m     corr_values \u001b[38;5;241m=\u001b[39m acf(final_series, nlags\u001b[38;5;241m=\u001b[39mlags, fft\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Erro padr√£o para ACF (f√≥rmula de Bartlett)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     se \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.24\u001b[39m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mlen\u001b[39m(final_series))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:686\u001b[0m, in \u001b[0;36macf\u001b[0;34m(x, adjusted, nlags, qstat, fft, alpha, bartlett_confint, missing)\u001b[0m\n\u001b[1;32m    682\u001b[0m alpha \u001b[38;5;241m=\u001b[39m float_like(alpha, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    683\u001b[0m missing \u001b[38;5;241m=\u001b[39m string_like(\n\u001b[1;32m    684\u001b[0m     missing, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconservative\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    685\u001b[0m )\n\u001b[0;32m--> 686\u001b[0m x \u001b[38;5;241m=\u001b[39m array_like(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    687\u001b[0m \u001b[38;5;66;03m# TODO: should this shrink for missing=\"drop\" and NaNs in x?\u001b[39;00m\n\u001b[1;32m    688\u001b[0m nobs \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/statsmodels/tools/validation/validation.py:155\u001b[0m, in \u001b[0;36marray_like\u001b[0;34m(obj, name, dtype, ndim, maxdim, shape, order, contiguous, optional, writeable)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m ndim:\n\u001b[1;32m    154\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is required to have ndim \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m but has ndim \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(name, ndim, arr\u001b[38;5;241m.\u001b[39mndim))\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m actual, req \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(arr\u001b[38;5;241m.\u001b[39mshape, shape):\n",
      "\u001b[0;31mValueError\u001b[0m: x is required to have ndim 1 but has ndim 2"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "# Fun√ß√£o para plotar a correla√ß√£o para produtos, adaptado para previs√£o estacion√°ria das macros\n",
    "def plot_correlation_for_macros(identificadores_df, product_dfs, lags=30, plot_type='acf'):\n",
    "    \"\"\"\n",
    "    Plots ACF or PACF for the combination of product series in each macro.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    identificadores_df : pd.DataFrame\n",
    "        DataFrame contendo a rela√ß√£o de produtos e suas macros.\n",
    "    product_dfs : dict\n",
    "        Dicion√°rio onde as chaves s√£o os produtos e os valores s√£o os DataFrames das s√©ries temporais de cada produto.\n",
    "    lags : int\n",
    "        N√∫mero de lags para computar\n",
    "    plot_type : str ('acf' ou 'pacf')\n",
    "        Tipo de gr√°fico de correla√ß√£o a ser exibido\n",
    "    \"\"\"\n",
    "    # Valida√ß√£o do tipo de gr√°fico\n",
    "    plot_type = plot_type.lower()\n",
    "    if plot_type not in ['acf', 'pacf']:\n",
    "        raise ValueError(\"plot_type must be either 'acf' or 'pacf'\")\n",
    "\n",
    "    # Inicializa o gr√°fico de subplots\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=len(identificadores_df[\"Macro\"].unique()),  # N√∫mero de colunas igual ao n√∫mero de macros √∫nicas\n",
    "        subplot_titles=[f\"{plot_type.upper()}: {macro}\" for macro in identificadores_df[\"Macro\"].unique()],\n",
    "        horizontal_spacing=0.01)\n",
    "\n",
    "    # Itera sobre cada macro\n",
    "    for i, macro in enumerate(identificadores_df[\"Macro\"].unique()):\n",
    "        print(f\"\\nAnalisando a macro: {macro}\")\n",
    "        \n",
    "        # Identifica os produtos da macro\n",
    "        produtos_macro = identificadores_df.loc[identificadores_df[\"Macro\"] == macro, \"Produtos\"].values[0]\n",
    "        produtos_lista = produtos_macro.split(\", \")\n",
    "\n",
    "        # Criar uma lista para as s√©ries dos produtos\n",
    "        combined_series = []\n",
    "\n",
    "        # Itera sobre os produtos e coleta as s√©ries temporais correspondentes\n",
    "        for produto in produtos_lista:\n",
    "            if produto in product_dfs:\n",
    "                series = product_dfs[produto].dropna()  # Remove NaNs\n",
    "                combined_series.append(series)\n",
    "\n",
    "        # Concatenar as s√©ries de todos os produtos da macro\n",
    "        if combined_series:\n",
    "            final_series = pd.concat(combined_series, axis=0)  # Concatena todas as s√©ries em uma √∫nica s√©rie\n",
    "            final_series = final_series.dropna()  # Remove NaNs da s√©rie concatenada\n",
    "            \n",
    "            if len(final_series) > 1:  # Garante que a s√©rie tenha mais de um ponto\n",
    "                print(f\"Testando estacionariedade da macro '{macro}'...\")\n",
    "                if plot_type == 'acf':\n",
    "                    corr_values = acf(final_series, nlags=lags, fft=True)\n",
    "                    # Erro padr√£o para ACF (f√≥rmula de Bartlett)\n",
    "                    se = 2.24 / np.sqrt(len(final_series))\n",
    "                else:\n",
    "                    corr_values = pacf(final_series, nlags=lags)\n",
    "                    # Erro padr√£o para PACF (1/sqrt(n))\n",
    "                    se = 2.24 / np.sqrt(len(final_series))\n",
    "                \n",
    "                lags_range = list(range(lags+1))\n",
    "                \n",
    "                # Cria o efeito \"stem\" (linha + marcador no topo)\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=lags_range, y=corr_values, mode='lines+markers', line=dict(color='blue', width=1),\n",
    "                        marker=dict(color='blue', size=5), name=macro,\n",
    "                        hovertemplate=f\"Lag %{{x}}<br>{plot_type.upper()}: %{{y:.2f}}<extra></extra>\"),\n",
    "                    row=1, col=i+1)\n",
    "                \n",
    "                # Adiciona linhas verticais finas de 0 at√© o valor da correla√ß√£o (efeito stem)\n",
    "                for lag, val in zip(lags_range, corr_values):\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=[lag, lag], y=[0, val], mode='lines', line=dict(color='blue', width=1),\n",
    "                            showlegend=False, hoverinfo='skip'), row=1, col=i+1)\n",
    "                \n",
    "                # Adiciona intervalos de confian√ßa constantes\n",
    "                fig.add_hline(y=se, line=dict(color='red', width=1, dash='dash'), \n",
    "                             row=1, col=i+1, opacity=0.7)\n",
    "                fig.add_hline(y=-se, line=dict(color='red', width=1, dash='dash'), \n",
    "                             row=1, col=i+1, opacity=0.7)\n",
    "                \n",
    "                # √Årea sombreada para o intervalo de confian√ßa\n",
    "                fig.add_hrect(y0=-se, y1=se, \n",
    "                             line_width=0, fillcolor='rgba(100,100,100,0.2)', \n",
    "                             row=1, col=i+1)\n",
    "\n",
    "    # Atualiza o layout do gr√°fico\n",
    "    fig.update_layout(\n",
    "        title_text=f\"{plot_type.upper()} por Macro (97.5% Confidence)\",\n",
    "        height=500,\n",
    "        width=500*len(identificadores_df[\"Macro\"].unique()),  # Ajusta o tamanho com base no n√∫mero de macros\n",
    "        showlegend=False,\n",
    "        margin=dict(l=20, r=20))\n",
    "    \n",
    "    # Configura√ß√µes uniformes dos eixos\n",
    "    fig.update_yaxes(range=[-1.1, 1.1], title_text=plot_type.upper())\n",
    "    fig.update_xaxes(title_text=\"Lag\")\n",
    "    \n",
    "    # Exibe o gr√°fico\n",
    "    fig.show()\n",
    "\n",
    "# Exemplo de execu√ß√£o:\n",
    "# Assumindo que 'identificadores_df' e 'product_dfs' j√° est√£o definidos, podemos chamar a fun√ß√£o para plotar as correla√ß√µes.\n",
    "plot_correlation_for_macros(identificadores_df, product_dfs, lags=30, plot_type='acf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_for_products(df_sales, plot_type='acf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <span style=\"background-color:#000027; padding:5px; border-radius:5px;font-size:13pt\">**Partial Autocorrelation Function (PACF)**</span> <a id='PACF'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sales'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Sales'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m produto \u001b[38;5;129;01min\u001b[39;00m produtos_lista:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m produto \u001b[38;5;129;01min\u001b[39;00m product_dfs:\n\u001b[0;32m---> 30\u001b[0m         series \u001b[38;5;241m=\u001b[39m product_dfs[produto][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m     31\u001b[0m         combined_series\u001b[38;5;241m.\u001b[39mappend(series)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Concatenar todas as s√©ries da macro\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Sales'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fun√ß√£o para classificar as vari√°veis\n",
    "def classify_variable(series):\n",
    "    \"\"\"Classifica a vari√°vel com base em testes de normalidade e estacionariedade.\"\"\"\n",
    "    \n",
    "    clean_series = series.dropna()\n",
    "    if len(clean_series) > 3:\n",
    "        stat, p_value = shapiro(clean_series)\n",
    "        is_normal = p_value > 0.05  # p-value > 0.05 significa normal\n",
    "        \n",
    "        adf_stat, adf_p_value, _, _, _, _ = adfuller(clean_series)\n",
    "        is_stationary = adf_p_value < 0.05  # p-value < 0.05 significa estacion√°ria\n",
    "    else:\n",
    "        is_normal = False\n",
    "        is_stationary = False\n",
    "\n",
    "    return is_normal, is_stationary, adf_p_value\n",
    "\n",
    "# Aplicar an√°lise de estacionariedade por macro\n",
    "stationarity_results = []\n",
    "\n",
    "for macro in identificadores_df[\"Macro\"]:\n",
    "    # Criar uma s√©rie temporal composta por produtos da macro\n",
    "    produtos_macro = identificadores_df.loc[identificadores_df[\"Macro\"] == macro, \"Produtos\"].values[0]\n",
    "    produtos_lista = produtos_macro.split(\", \")\n",
    "\n",
    "    combined_series = []\n",
    "    \n",
    "    for produto in produtos_lista:\n",
    "        if produto in product_dfs:\n",
    "            series = product_dfs[produto][\"Sales\"].dropna()\n",
    "            combined_series.append(series)\n",
    "\n",
    "    # Concatenar todas as s√©ries da macro\n",
    "    if combined_series:\n",
    "        final_series = pd.concat(combined_series)\n",
    "        _, _, adf_p_value = classify_variable(final_series)\n",
    "        stationarity_results.append({\"Macro\": macro, \"ADF P-Value\": adf_p_value})\n",
    "\n",
    "# Criar DataFrame com os resultados da an√°lise de estacionariedade\n",
    "stationarity_df = pd.DataFrame(stationarity_results)\n",
    "\n",
    "# Fun√ß√£o de imputa√ß√£o autom√°tica\n",
    "def auto_impute_missing_values(df_train, df_test):\n",
    "    \"\"\"Preenche valores ausentes automaticamente usando m√©todos adequados.\"\"\"\n",
    "\n",
    "    missing_columns = df_test.columns[df_test.isnull().any()]\n",
    "    \n",
    "    for col in missing_columns:\n",
    "        print(f\"Processando: {col}\")\n",
    "        series = df_train[col]  # Usar dados de treino para imputa√ß√£o\n",
    "\n",
    "        is_normal, is_stationary, _ = classify_variable(series)\n",
    "\n",
    "        if is_normal:\n",
    "            print(f\" - {col} √© normal ‚Üí Usando M√©dia & Desvio Padr√£o\")\n",
    "            mean_value, std_value = series.mean(), series.std()\n",
    "            num_missing = df_test[col].isnull().sum()\n",
    "            predictions = norm.rvs(loc=mean_value, scale=std_value, size=num_missing)\n",
    "        \n",
    "        elif is_stationary:\n",
    "            print(f\" - {col} √© estacion√°ria ‚Üí Usando Suaviza√ß√£o Exponencial Simples\")\n",
    "            model = SimpleExpSmoothing(series.dropna()).fit()\n",
    "            predictions = model.forecast(steps=df_test[col].isnull().sum())\n",
    "\n",
    "        else:\n",
    "            print(f\" - {col} √© n√£o-estacion√°ria ‚Üí Usando ARIMA\")\n",
    "            model = ARIMA(series.dropna(), order=(1, 1, 1))\n",
    "            fitted_model = model.fit()\n",
    "            predictions = fitted_model.forecast(steps=df_test[col].isnull().sum())\n",
    "\n",
    "        missing_indexes = df_test[df_test[col].isnull()].index\n",
    "        df_test.loc[missing_indexes, col] = predictions\n",
    "\n",
    "    return df_test\n",
    "\n",
    "# Aplicando imputa√ß√£o autom√°tica no conjunto de teste\n",
    "df_train = remerged_data[1]  \n",
    "df_test = test_1.copy()\n",
    "df_test_filled = auto_impute_missing_values(df_train, df_test)\n",
    "\n",
    "# Exibir resultados finais\n",
    "print(\"An√°lise de Estacionariedade por Macro:\")\n",
    "print(stationarity_df)\n",
    "print(\"\\nAmostra do Conjunto de Teste ap√≥s Imputa√ß√£o:\")\n",
    "print(df_test_filled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remerged_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 101\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_test\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Aplicando imputa√ß√£o autom√°tica no conjunto de teste\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m df_train \u001b[38;5;241m=\u001b[39m remerged_data[\u001b[38;5;241m1\u001b[39m]  \n\u001b[1;32m    102\u001b[0m df_test \u001b[38;5;241m=\u001b[39m test_1\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    103\u001b[0m df_test_filled \u001b[38;5;241m=\u001b[39m auto_impute_missing_values(df_train, df_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'remerged_data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Fun√ß√£o para classificar as vari√°veis\n",
    "def classify_variable(series):\n",
    "    \"\"\"Classifica a vari√°vel com base em testes de normalidade e estacionariedade.\"\"\"\n",
    "    \n",
    "    clean_series = series.dropna()\n",
    "    if len(clean_series) > 3:\n",
    "        stat, p_value = shapiro(clean_series)\n",
    "        is_normal = p_value > 0.05  # p-value > 0.05 significa normal\n",
    "        \n",
    "        adf_stat, adf_p_value, _, _, _, _ = adfuller(clean_series)\n",
    "        is_stationary = adf_p_value < 0.05  # p-value < 0.05 significa estacion√°ria\n",
    "    else:\n",
    "        is_normal = False\n",
    "        is_stationary = False\n",
    "        adf_p_value = None  # Valor nulo se n√£o houver dados suficientes\n",
    "\n",
    "    return is_normal, is_stationary, adf_p_value\n",
    "\n",
    "# Aplicar an√°lise de estacionariedade por macro\n",
    "stationarity_results = []\n",
    "\n",
    "for macro in identificadores_df[\"Macro\"]:\n",
    "    # Criar uma s√©rie temporal composta por produtos da macro\n",
    "    produtos_macro = identificadores_df.loc[identificadores_df[\"Macro\"] == macro, \"Produtos\"].values[0]\n",
    "    produtos_lista = produtos_macro.split(\", \")\n",
    "\n",
    "    combined_series = []\n",
    "    \n",
    "    for produto in produtos_lista:\n",
    "        if produto in product_dfs:\n",
    "            df = product_dfs[produto]\n",
    "\n",
    "            # Escolher a primeira coluna num√©rica dispon√≠vel para an√°lise\n",
    "            numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "            if not numeric_cols.empty:\n",
    "                series = df[numeric_cols[0]].dropna()\n",
    "                combined_series.append(series)\n",
    "\n",
    "    # Concatenar todas as s√©ries da macro\n",
    "    if combined_series:\n",
    "        final_series = pd.concat(combined_series)\n",
    "        _, _, adf_p_value = classify_variable(final_series)\n",
    "        stationarity_results.append({\"Macro\": macro, \"ADF P-Value\": adf_p_value})\n",
    "\n",
    "# Criar DataFrame com os resultados da an√°lise de estacionariedade\n",
    "stationarity_df = pd.DataFrame(stationarity_results)\n",
    "\n",
    "# Fun√ß√£o de imputa√ß√£o autom√°tica\n",
    "def auto_impute_missing_values(df_train, df_test):\n",
    "    \"\"\"Preenche valores ausentes automaticamente usando m√©todos adequados.\"\"\"\n",
    "\n",
    "    missing_columns = df_test.columns[df_test.isnull().any()]\n",
    "    \n",
    "    for col in missing_columns:\n",
    "        print(f\"Processando: {col}\")\n",
    "        \n",
    "        # Verifica se a coluna existe no conjunto de treino\n",
    "        if col not in df_train.columns:\n",
    "            print(f\" - {col} n√£o est√° presente no conjunto de treino. Pulando...\")\n",
    "            continue\n",
    "\n",
    "        series = df_train[col].dropna()  # Remover valores ausentes\n",
    "\n",
    "        if len(series) < 3:\n",
    "            print(f\" - {col} tem poucos dados para an√°lise. Pulando...\")\n",
    "            continue\n",
    "\n",
    "        is_normal, is_stationary, _ = classify_variable(series)\n",
    "\n",
    "        if is_normal:\n",
    "            print(f\" - {col} √© normal ‚Üí Usando M√©dia & Desvio Padr√£o\")\n",
    "            mean_value, std_value = series.mean(), series.std()\n",
    "            num_missing = df_test[col].isnull().sum()\n",
    "            predictions = norm.rvs(loc=mean_value, scale=std_value, size=num_missing)\n",
    "        \n",
    "        elif is_stationary:\n",
    "            print(f\" - {col} √© estacion√°ria ‚Üí Usando Suaviza√ß√£o Exponencial Simples\")\n",
    "            model = SimpleExpSmoothing(series).fit()\n",
    "            predictions = model.forecast(steps=df_test[col].isnull().sum())\n",
    "\n",
    "        else:\n",
    "            print(f\" - {col} √© n√£o-estacion√°ria ‚Üí Usando ARIMA\")\n",
    "            model = ARIMA(series, order=(1, 1, 1))\n",
    "            fitted_model = model.fit()\n",
    "            predictions = fitted_model.forecast(steps=df_test[col].isnull().sum())\n",
    "\n",
    "        # Preencher valores ausentes\n",
    "        missing_indexes = df_test[df_test[col].isnull()].index\n",
    "        df_test.loc[missing_indexes, col] = predictions\n",
    "\n",
    "    return df_test\n",
    "\n",
    "# Aplicando imputa√ß√£o autom√°tica no conjunto de teste\n",
    "df_train = remerged_data[1]  \n",
    "df_test = test_1.copy()\n",
    "df_test_filled = auto_impute_missing_values(df_train, df_test)\n",
    "\n",
    "# Exibir resultados finais\n",
    "print(\"An√°lise de Estacionariedade por Macro:\")\n",
    "print(stationarity_df)\n",
    "print(\"\\nAmostra do Conjunto de Teste ap√≥s Imputa√ß√£o:\")\n",
    "print(df_test_filled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"background-color:#000027; padding:5px; border-radius:5px;\"> üìå Prediction for the Macro Features used <a id='business-understanding'></a>\n",
    "\n",
    "##### Click [here](#table-of-contents) ‚¨ÜÔ∏è to return to the Index.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to classify variables\n",
    "def classify_variable(series):\n",
    "    \"\"\"Classifies variable based on normality and stationarity tests.\"\"\"\n",
    "    \n",
    "    # Remove NaN values for testing\n",
    "    clean_series = series.dropna()\n",
    "\n",
    "    # Check for normality\n",
    "    if len(clean_series) > 3:\n",
    "        stat, p_value = shapiro(clean_series)\n",
    "        is_normal = p_value > 0.05  # p-value > 0.05 means normal\n",
    "    else:\n",
    "        is_normal = False  # Not enough data to test normality\n",
    "\n",
    "    # Check for stationarity\n",
    "    if len(clean_series) > 3:\n",
    "        adf_stat, adf_p_value, _, _, _, _ = adfuller(clean_series)\n",
    "        is_stationary = adf_p_value < 0.05  # p-value < 0.05 means stationary\n",
    "    else:\n",
    "        is_stationary = False  # Not enough data\n",
    "\n",
    "    return is_normal, is_stationary\n",
    "\n",
    "# Function to automatically fill missing values\n",
    "def auto_impute_missing_values(df_train, df_test):\n",
    "    \"\"\"Automatically selects the best imputation method for each missing variable.\"\"\"\n",
    "    \n",
    "    # Identify missing columns in test set\n",
    "    missing_columns = df_test.columns[df_test.isnull().any()]\n",
    "    \n",
    "    # Iterate through missing columns\n",
    "    for col in missing_columns:\n",
    "        print(f\"Processing: {col}\")\n",
    "\n",
    "        series = df_train[col]  # Use train data for imputation\n",
    "        is_normal, is_stationary = classify_variable(series)\n",
    "\n",
    "        if is_normal:\n",
    "            # Case 1: Normally distributed ‚Üí Sample from normal distribution\n",
    "            print(f\" - {col} is normal ‚Üí Using Mean & Std Sampling\")\n",
    "            mean_value, std_value = series.mean(), series.std()\n",
    "            num_missing = df_test[col].isnull().sum()\n",
    "            predictions = norm.rvs(loc=mean_value, scale=std_value, size=num_missing)\n",
    "        \n",
    "        elif is_stationary:\n",
    "            # Case 2: Stationary but non-normal ‚Üí Simple Exponential Smoothing\n",
    "            print(f\" - {col} is stationary ‚Üí Using Simple Exponential Smoothing\")\n",
    "            model = SimpleExpSmoothing(series.dropna()).fit()\n",
    "            predictions = model.forecast(steps=df_test[col].isnull().sum())\n",
    "\n",
    "        elif not is_stationary:\n",
    "            # Case 3: Non-Stationary ‚Üí ARIMA\n",
    "            print(f\" - {col} is non-stationary ‚Üí Using ARIMA\")\n",
    "            model = ARIMA(series.dropna(), order=(1, 1, 1))  # (p,d,q) chosen based on domain knowledge\n",
    "            fitted_model = model.fit()\n",
    "            predictions = fitted_model.forecast(steps=df_test[col].isnull().sum())\n",
    "\n",
    "        else:\n",
    "            # Case 4: If nothing works ‚Üí Use XGBoost Regression\n",
    "            print(f\" - {col} is complex ‚Üí Using XGBoost Regression\")\n",
    "            train_data = df_train.dropna(subset=[col])  # Drop missing values for training\n",
    "            X_train = train_data.drop(columns=[col])  # Exclude target column\n",
    "            y_train = train_data[col]  # Target column\n",
    "\n",
    "            X_test = df_test.loc[df_test[col].isnull(), X_train.columns]  # Only missing values\n",
    "\n",
    "            model = XGBRegressor(n_estimators=100, learning_rate=0.1)\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X_test)\n",
    "\n",
    "        # Assign predictions\n",
    "        missing_indexes = df_test[df_test[col].isnull()].index\n",
    "        df_test.loc[missing_indexes, col] = predictions\n",
    "\n",
    "    return df_test\n",
    "\n",
    "# Example usage\n",
    "df_train = remerged_data[1]  # Use remerged train data\n",
    "df_test = test_1.copy()  # Copy test set\n",
    "\n",
    "# Apply automatic imputation\n",
    "df_test_filled = auto_impute_missing_values(df_train, df_test)\n",
    "\n",
    "# Check results\n",
    "print(df_test_filled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
